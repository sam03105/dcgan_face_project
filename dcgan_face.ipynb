{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCGAN\n",
    "- 整體網路架構：\n",
    "\n",
    "<img src=\"https://camo.githubusercontent.com/45e147fc9dfcf6a8e5df2c9b985078258b9974e3/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f313030302f312a33394e6e6e695f6e685044614c7539416e544c6f57772e706e67\" alt=\"dcgan\" style=\"width: 1000px;\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 程式 12.31 創建資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3318 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "dataset = keras.utils.image_dataset_from_directory(\n",
    "    \"../data/face\",\n",
    "    label_mode=None,\n",
    "    image_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    smart_resize=True)#去路徑取資料變dataset，不要標籤，因為只需要影像，取圖像後調整圖像大小的大小64*64的圖片，一次取32個，smart_resize會用裁減，避免臉部比例長寬扭曲"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 程式 12.32 調整像素值範圍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda x: x / 255.)#歸一化(-1~1之間)縮小他們的數值大小差距，且仍保有原始數據的意義，降低單位轉換或是區間對數據的影響"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 程式 12.33 顯示首張影像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for x in dataset:\n",
    "    plt.axis(\"off\")#關閉與軸相關的所有內容\n",
    "    plt.imshow((x.numpy() * 255).astype(\"int32\")[0])#顯示第一張，numpy()=>將tensor對象轉換為numpy.ndarray對象\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 判別器"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 程式 12.34 GAN辨別器網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(64, 64, 3)),#圖片為64*64 3是因為RGB\n",
    "\n",
    "        layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),# 64個filter(4*4) 一次滑動兩格 padding(做填補，不希望把圖片邊緣的特徵抹去)\n",
    "        layers.BatchNormalization(),#批次正規化=>作特徵縮放，(希望數值差距不要太大)，將前一層的Output標準化，防止梯度迷散，過擬合現象\n",
    "        layers.LeakyReLU(alpha=0.2),#使用LeakyReLU比ReLU多了輸入值小於0時，輸出值=alpha*輸入值，希望可以緩解稀疏性(避免梯度消失的程度)\n",
    "        \n",
    "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),#128個filter，通常以倍數成長\n",
    "        layers.BatchNormalization(),#批次正規化=>作特徵縮放，(希望數值差距不要太大)，將前一層的Output標準化，防止梯度迷散，過擬合現象\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        \n",
    "        layers.Conv2D(256, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.BatchNormalization(),#批次正規化=>作特徵縮放，(希望數值差距不要太大)，將前一層的Output標準化，防止梯度迷散，過擬合現象\n",
    "        \n",
    "        layers.Flatten(),#扁平化(將特徵圖拉為一維向量)\n",
    "        layers.Dropout(0.5),#放棄一些神經元，避免過度學習\n",
    "        layers.Dense(1, activation=\"sigmoid\"),#0~1之間\n",
    "    ],\n",
    "    name=\"discriminator\",#命名\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_293 (Conv2D)         (None, 32, 32, 64)        3136      \n",
      "                                                                 \n",
      " batch_normalization_321 (Ba  (None, 32, 32, 64)       256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_450 (LeakyReLU)  (None, 32, 32, 64)       0         \n",
      "                                                                 \n",
      " conv2d_294 (Conv2D)         (None, 16, 16, 128)       131200    \n",
      "                                                                 \n",
      " batch_normalization_322 (Ba  (None, 16, 16, 128)      512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_451 (LeakyReLU)  (None, 16, 16, 128)      0         \n",
      "                                                                 \n",
      " conv2d_295 (Conv2D)         (None, 8, 8, 256)         524544    \n",
      "                                                                 \n",
      " leaky_re_lu_452 (LeakyReLU)  (None, 8, 8, 256)        0         \n",
      "                                                                 \n",
      " batch_normalization_323 (Ba  (None, 8, 8, 256)        1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " flatten_73 (Flatten)        (None, 16384)             0         \n",
      "                                                                 \n",
      " dropout_73 (Dropout)        (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_147 (Dense)           (None, 1)                 16385     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 677,057\n",
      "Trainable params: 676,161\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 生成器"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 程式GAN生成器網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 128 #生成器第一個雜訊由128維的向量所組成\n",
    "\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(latent_dim,)),#生成器輸入雜訊\n",
    "        layers.Dense(8 * 8 * 256),#全連接層使用判別器扁平層的數量參數，因生成器生成的圖片會要傳入辨別器\n",
    "        #全連接就是把以前的局部特徵重新通過權值矩陣組裝成完整的圖。因爲用到了所有的局部特徵，所以叫全連接\n",
    "        layers.Reshape((8, 8, 256)),#轉成3維，自己設數值，但不要太大因為還要反卷積\n",
    "        \n",
    "        layers.Conv2DTranspose(256, kernel_size=5, strides=2, padding=\"same\"),#反卷積(小特徵變圖片) 寬和高會變大\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.BatchNormalization(),#批次正規化=>作特徵縮放，(希望數值差距不要太大)，將前一層的Output標準化，防止梯度迷散，過擬合現象\n",
    "        \n",
    "        layers.Conv2DTranspose(128, kernel_size=5, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.BatchNormalization(),#批次正規化=>作特徵縮放，(希望數值差距不要太大)，將前一層的Output標準化，防止梯度迷散，過擬合現象\n",
    "        \n",
    "        layers.Conv2DTranspose(64, kernel_size=5, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.BatchNormalization(),#批次正規化=>作特徵縮放，(希望數值差距不要太大)，將前一層的Output標準化，防止梯度迷散，過擬合現象\n",
    "        \n",
    "        layers.Conv2D(3, kernel_size=5, padding=\"same\", activation=\"sigmoid\"),#最後轉為輸出的shape(64,64,3)\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_148 (Dense)           (None, 16384)             2113536   \n",
      "                                                                 \n",
      " reshape_74 (Reshape)        (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_231 (Conv2  (None, 16, 16, 256)      1638656   \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " leaky_re_lu_453 (LeakyReLU)  (None, 16, 16, 256)      0         \n",
      "                                                                 \n",
      " batch_normalization_324 (Ba  (None, 16, 16, 256)      1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_transpose_232 (Conv2  (None, 32, 32, 128)      819328    \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " leaky_re_lu_454 (LeakyReLU)  (None, 32, 32, 128)      0         \n",
      "                                                                 \n",
      " batch_normalization_325 (Ba  (None, 32, 32, 128)      512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_transpose_233 (Conv2  (None, 64, 64, 64)       204864    \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " leaky_re_lu_455 (LeakyReLU)  (None, 64, 64, 64)       0         \n",
      "                                                                 \n",
      " batch_normalization_326 (Ba  (None, 64, 64, 64)       256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_296 (Conv2D)         (None, 64, 64, 3)         4803      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,782,979\n",
      "Trainable params: 4,782,083\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-6 對抗式網路"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GAN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "class GAN(keras.Model):#繼承Keras.Model\n",
    "    def __init__(self, discriminator, generator, latent_dim):#呼叫class會初始化\n",
    "        super().__init__()#呼叫父層的初始化\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        #評量指標物件設定\n",
    "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(GAN, self).compile()#呼叫父層compile()方法\n",
    "        #設定優化指標物件\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    @property#只能讀取\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric]#傳回評量指標物件\n",
    "\n",
    "    def train_step(self, real_images):#此function被fit()調用，fit() loops over the dataset and provide each batch to train_step\n",
    "        batch_size = tf.shape(real_images)[0]#查詢並設定批次的數量 tensor(None, 64, 64, 3)\n",
    "        #None維度意味著​​它可以是任何標量數，因此您可以使用此模型推斷任意長的輸入。這個維度不影響網絡的大小，它只是表示您可以在測試期間自由選擇輸入的長度（樣本數）\n",
    "        random_latent_vectors = tf.random.normal(\n",
    "            shape=(batch_size, self.latent_dim))#從常態分佈輸出隨機值生成shape為(數量,幾維)的向量\n",
    "        #print(f\"batch_size= {batch_size}\")\n",
    "        generated_images = self.generator(random_latent_vectors)#生成器最後輸出的圖=從上一行取隨機雜訊值去跑生成器序列後產生的圖\n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)#將假圖(生成)和真圖進行串接(沿著批次軸(上下))\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))],#(多少維(batch_size為一維)全部為一(生成的)和全部為零(真實的)，屬性都是tf.int32)\n",
    "            axis=0#沿著第一個維度對接(axis=0)\n",
    "        )\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))#產生一個shape為上行labels維度的隨機數再*0.05(跳脫局部解避免都生成同一張圖片)\n",
    "\n",
    "        #Train the discriminator\n",
    "        #計算模型中所有可训练變量的梯度\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)#將結合的圖像(假圖和真圖串接)放進判別器跑模型輸出特徵值\n",
    "            d_loss = self.loss_fn(labels, predictions)#loss function計算label和predictions特徵值差距\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        #從常態分佈輸出隨機值生成shape為(數量,幾維)的向量\n",
    "        random_latent_vectors = tf.random.normal(\n",
    "            shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        misleading_labels = tf.zeros((batch_size, 1))#生成器標籤希望可以騙過判別器所以給零值\n",
    "\n",
    "        #Train the generator\n",
    "        #計算模型中所有可训练變量的梯度\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(\n",
    "                self.generator(random_latent_vectors))#將結合的圖像(假圖)放進判別器跑模型輸出特徵值\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)#loss function計算生成器label和predictions特徵值差距\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(\n",
    "            zip(grads, self.generator.trainable_weights))#利用優化器改善梯度\n",
    "\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        return {\"d_loss\": self.d_loss_metric.result(),\n",
    "                \"g_loss\": self.g_loss_metric.result()}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 程式能在訓練過程中，取樣所生成影像的callback物件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=3, latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "        self.loss={}\n",
    "\n",
    "    def on_train_begin(self,logs):\n",
    "        self.per_epoch_d_loss=[]\n",
    "        self.per_epoch_g_loss=[]\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        X,Y=Counter(logs),Counter(self.loss)\n",
    "        self.loss=dict(X+Y)\n",
    "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        #path=\"./generate_face\"\n",
    "        for i in range(self.num_img):\n",
    "            img = keras.utils.array_to_img(generated_images[i])\n",
    "            img.save(f\"generated_img_{epoch:03d}_{i}.png\")\n",
    "        self.per_epoch_d_loss.append(logs.get(\"d_loss\"))\n",
    "        self.per_epoch_g_loss.append(logs.get(\"g_loss\"))\n",
    "\n",
    "    def on_train_end(self,epoch,logs=None):\n",
    "        \n",
    "        plt.clf()\n",
    "        plt.plot(range(len(self.per_epoch_d_loss)),\n",
    "        self.per_epoch_d_loss,\n",
    "        label=\"Training d_loss for each epoch\")\n",
    "\n",
    "        plt.plot(range(len(self.per_epoch_g_loss)),\n",
    "        self.per_epoch_g_loss,\n",
    "        label=\"Training g_loss for each epoch\")\n",
    "\n",
    "        plt.xlabel(f\"epoch{epoch}\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        self.per_epoch_d_loss=[]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 程式編譯並訓練GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000\n",
      "104/104 [==============================] - 13s 110ms/step - d_loss: 0.4701 - g_loss: 1.2906\n",
      "Epoch 2/3000\n",
      "104/104 [==============================] - 15s 140ms/step - d_loss: 0.5087 - g_loss: 2.4180\n",
      "Epoch 3/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: 0.4345 - g_loss: 2.5146\n",
      "Epoch 4/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.3298 - g_loss: 2.4756\n",
      "Epoch 5/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6267 - g_loss: 1.8375\n",
      "Epoch 6/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6483 - g_loss: 0.9991\n",
      "Epoch 7/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.7021 - g_loss: 1.1486\n",
      "Epoch 8/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6511 - g_loss: 1.0458\n",
      "Epoch 9/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.5941 - g_loss: 0.9666\n",
      "Epoch 10/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.7039 - g_loss: 0.9419\n",
      "Epoch 11/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.7117 - g_loss: 1.0062\n",
      "Epoch 12/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6691 - g_loss: 1.0108\n",
      "Epoch 13/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6472 - g_loss: 1.1347\n",
      "Epoch 14/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6635 - g_loss: 0.9096\n",
      "Epoch 15/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6387 - g_loss: 0.9530\n",
      "Epoch 16/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.7655 - g_loss: 1.2971\n",
      "Epoch 17/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6622 - g_loss: 1.0569\n",
      "Epoch 18/3000\n",
      "104/104 [==============================] - 12s 108ms/step - d_loss: 0.6059 - g_loss: 1.0411\n",
      "Epoch 19/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.7133 - g_loss: 0.8523\n",
      "Epoch 20/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.5756 - g_loss: 0.9352\n",
      "Epoch 21/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.6867 - g_loss: 1.0043\n",
      "Epoch 22/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.6283 - g_loss: 1.2204\n",
      "Epoch 23/3000\n",
      "104/104 [==============================] - 11s 108ms/step - d_loss: 0.6597 - g_loss: 0.9728\n",
      "Epoch 24/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.7208 - g_loss: 0.9103\n",
      "Epoch 25/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6708 - g_loss: 0.8649\n",
      "Epoch 26/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.7248 - g_loss: 0.9909\n",
      "Epoch 27/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.6991 - g_loss: 1.1106\n",
      "Epoch 28/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6622 - g_loss: 0.8456\n",
      "Epoch 29/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6910 - g_loss: 0.9199\n",
      "Epoch 30/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6640 - g_loss: 0.9385\n",
      "Epoch 31/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.7245 - g_loss: 1.0083\n",
      "Epoch 32/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.7404 - g_loss: 1.1656\n",
      "Epoch 33/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6541 - g_loss: 0.9719\n",
      "Epoch 34/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6610 - g_loss: 0.9223\n",
      "Epoch 35/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.7134 - g_loss: 0.8553\n",
      "Epoch 36/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6409 - g_loss: 0.9199\n",
      "Epoch 37/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6703 - g_loss: 0.8071\n",
      "Epoch 38/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6448 - g_loss: 0.9629\n",
      "Epoch 39/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.7544 - g_loss: 0.9049\n",
      "Epoch 40/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6861 - g_loss: 0.9066\n",
      "Epoch 41/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.7076 - g_loss: 0.9158\n",
      "Epoch 42/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.7651 - g_loss: 0.8732\n",
      "Epoch 43/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6624 - g_loss: 1.1690\n",
      "Epoch 44/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6944 - g_loss: 0.9250\n",
      "Epoch 45/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.7362 - g_loss: 0.8002\n",
      "Epoch 46/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.7228 - g_loss: 0.9726\n",
      "Epoch 47/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6998 - g_loss: 0.9561\n",
      "Epoch 48/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6605 - g_loss: 1.0322\n",
      "Epoch 49/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6626 - g_loss: 0.9112\n",
      "Epoch 50/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6923 - g_loss: 0.9536\n",
      "Epoch 51/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6932 - g_loss: 1.1522\n",
      "Epoch 52/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6998 - g_loss: 1.0802\n",
      "Epoch 53/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6965 - g_loss: 0.9769\n",
      "Epoch 54/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6578 - g_loss: 1.0183\n",
      "Epoch 55/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.7446 - g_loss: 0.9256\n",
      "Epoch 56/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6640 - g_loss: 0.8855\n",
      "Epoch 57/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.6710 - g_loss: 0.9030\n",
      "Epoch 58/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.7302 - g_loss: 0.9331\n",
      "Epoch 59/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.7184 - g_loss: 0.8580\n",
      "Epoch 60/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6916 - g_loss: 0.9586\n",
      "Epoch 61/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.6849 - g_loss: 0.9263\n",
      "Epoch 62/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.7047 - g_loss: 0.9976\n",
      "Epoch 63/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.7529 - g_loss: 0.9510\n",
      "Epoch 64/3000\n",
      "104/104 [==============================] - 12s 108ms/step - d_loss: 0.7025 - g_loss: 0.7619\n",
      "Epoch 65/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6872 - g_loss: 0.8537\n",
      "Epoch 66/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6989 - g_loss: 0.8277\n",
      "Epoch 67/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.7025 - g_loss: 0.8405\n",
      "Epoch 68/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6499 - g_loss: 0.9371\n",
      "Epoch 69/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.7253 - g_loss: 1.2432\n",
      "Epoch 70/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6619 - g_loss: 0.9192\n",
      "Epoch 71/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6966 - g_loss: 0.9041\n",
      "Epoch 72/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6870 - g_loss: 0.8719\n",
      "Epoch 73/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6672 - g_loss: 0.9035\n",
      "Epoch 74/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.7290 - g_loss: 1.0301\n",
      "Epoch 75/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6583 - g_loss: 0.9471\n",
      "Epoch 76/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6831 - g_loss: 1.0422\n",
      "Epoch 77/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.7111 - g_loss: 0.8652\n",
      "Epoch 78/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.7174 - g_loss: 0.9770\n",
      "Epoch 79/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6994 - g_loss: 0.9862\n",
      "Epoch 80/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6944 - g_loss: 0.9114\n",
      "Epoch 81/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.6632 - g_loss: 1.0694\n",
      "Epoch 82/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.7490 - g_loss: 1.0036\n",
      "Epoch 83/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.6913 - g_loss: 1.0191\n",
      "Epoch 84/3000\n",
      "104/104 [==============================] - 11s 107ms/step - d_loss: 0.6787 - g_loss: 0.8742\n",
      "Epoch 85/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.7026 - g_loss: 0.8715\n",
      "Epoch 86/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6871 - g_loss: 0.8730\n",
      "Epoch 87/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6951 - g_loss: 0.9353\n",
      "Epoch 88/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.7031 - g_loss: 0.9648\n",
      "Epoch 89/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6902 - g_loss: 0.8765\n",
      "Epoch 90/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6948 - g_loss: 0.8910\n",
      "Epoch 91/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6764 - g_loss: 1.1393\n",
      "Epoch 92/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6892 - g_loss: 1.1294\n",
      "Epoch 93/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6768 - g_loss: 0.9754\n",
      "Epoch 94/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6484 - g_loss: 1.3685\n",
      "Epoch 95/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6939 - g_loss: 0.8222\n",
      "Epoch 96/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6517 - g_loss: 0.8791\n",
      "Epoch 97/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6576 - g_loss: 0.9591\n",
      "Epoch 98/3000\n",
      "104/104 [==============================] - 11s 108ms/step - d_loss: 0.6761 - g_loss: 0.9738\n",
      "Epoch 99/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6497 - g_loss: 0.9712\n",
      "Epoch 100/3000\n",
      "104/104 [==============================] - 11s 108ms/step - d_loss: 0.6727 - g_loss: 1.0337\n",
      "Epoch 101/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.6869 - g_loss: 0.9823\n",
      "Epoch 102/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6242 - g_loss: 1.0384\n",
      "Epoch 103/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.7101 - g_loss: 0.8790\n",
      "Epoch 104/3000\n",
      "104/104 [==============================] - 11s 107ms/step - d_loss: 0.6494 - g_loss: 0.9701\n",
      "Epoch 105/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.6844 - g_loss: 0.9291\n",
      "Epoch 106/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6836 - g_loss: 1.0318\n",
      "Epoch 107/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.7283 - g_loss: 1.0468\n",
      "Epoch 108/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.6662 - g_loss: 0.9052\n",
      "Epoch 109/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.6628 - g_loss: 1.0656\n",
      "Epoch 110/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.7110 - g_loss: 0.9883\n",
      "Epoch 111/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6700 - g_loss: 0.9427\n",
      "Epoch 112/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6334 - g_loss: 1.0394\n",
      "Epoch 113/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6600 - g_loss: 1.1175\n",
      "Epoch 114/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.7156 - g_loss: 1.1053\n",
      "Epoch 115/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6803 - g_loss: 0.9985\n",
      "Epoch 116/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6836 - g_loss: 1.3835\n",
      "Epoch 117/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6493 - g_loss: 1.0295\n",
      "Epoch 118/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6268 - g_loss: 1.0482\n",
      "Epoch 119/3000\n",
      "104/104 [==============================] - 11s 108ms/step - d_loss: 0.6722 - g_loss: 1.0043\n",
      "Epoch 120/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6210 - g_loss: 1.0870\n",
      "Epoch 121/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6199 - g_loss: 1.0268\n",
      "Epoch 122/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6583 - g_loss: 0.9316\n",
      "Epoch 123/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.6468 - g_loss: 0.9542\n",
      "Epoch 124/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.7180 - g_loss: 1.1037\n",
      "Epoch 125/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6244 - g_loss: 1.1124\n",
      "Epoch 126/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6334 - g_loss: 1.0018\n",
      "Epoch 127/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6909 - g_loss: 0.9351\n",
      "Epoch 128/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6549 - g_loss: 1.0057\n",
      "Epoch 129/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6650 - g_loss: 1.0998\n",
      "Epoch 130/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.7286 - g_loss: 1.1818\n",
      "Epoch 131/3000\n",
      "104/104 [==============================] - 11s 108ms/step - d_loss: 0.6521 - g_loss: 1.0895\n",
      "Epoch 132/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6523 - g_loss: 1.1272\n",
      "Epoch 133/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.5980 - g_loss: 1.0891\n",
      "Epoch 134/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.7233 - g_loss: 0.9005\n",
      "Epoch 135/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6837 - g_loss: 1.2230\n",
      "Epoch 136/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.7092 - g_loss: 1.0856\n",
      "Epoch 137/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6473 - g_loss: 0.9213\n",
      "Epoch 138/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6314 - g_loss: 0.9696\n",
      "Epoch 139/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6462 - g_loss: 1.0179\n",
      "Epoch 140/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6794 - g_loss: 0.9559\n",
      "Epoch 141/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.7035 - g_loss: 0.8675\n",
      "Epoch 142/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6342 - g_loss: 0.9524\n",
      "Epoch 143/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6138 - g_loss: 1.0777\n",
      "Epoch 144/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6875 - g_loss: 1.0365\n",
      "Epoch 145/3000\n",
      "104/104 [==============================] - 11s 108ms/step - d_loss: 0.6523 - g_loss: 1.2121\n",
      "Epoch 146/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6774 - g_loss: 0.9989\n",
      "Epoch 147/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6596 - g_loss: 0.9847\n",
      "Epoch 148/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6591 - g_loss: 1.0029\n",
      "Epoch 149/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.7240 - g_loss: 1.1939\n",
      "Epoch 150/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.7004 - g_loss: 0.9549\n",
      "Epoch 151/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6492 - g_loss: 0.9165\n",
      "Epoch 152/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6722 - g_loss: 0.9198\n",
      "Epoch 153/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6854 - g_loss: 0.9217\n",
      "Epoch 154/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6686 - g_loss: 0.9453\n",
      "Epoch 155/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6241 - g_loss: 1.0068\n",
      "Epoch 156/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6222 - g_loss: 1.0890\n",
      "Epoch 157/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6523 - g_loss: 0.9229\n",
      "Epoch 158/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6529 - g_loss: 0.9793\n",
      "Epoch 159/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6552 - g_loss: 0.9931\n",
      "Epoch 160/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.7024 - g_loss: 1.7536\n",
      "Epoch 161/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.6556 - g_loss: 1.0005\n",
      "Epoch 162/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6896 - g_loss: 0.8315\n",
      "Epoch 163/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6765 - g_loss: 0.9371\n",
      "Epoch 164/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6919 - g_loss: 1.0405\n",
      "Epoch 165/3000\n",
      "104/104 [==============================] - 11s 108ms/step - d_loss: 0.7169 - g_loss: 0.9674\n",
      "Epoch 166/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6869 - g_loss: 1.1085\n",
      "Epoch 167/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6616 - g_loss: 0.8974\n",
      "Epoch 168/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6638 - g_loss: 0.9756\n",
      "Epoch 169/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6819 - g_loss: 1.1631\n",
      "Epoch 170/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6730 - g_loss: 0.9515\n",
      "Epoch 171/3000\n",
      "104/104 [==============================] - 12s 108ms/step - d_loss: 0.6747 - g_loss: 1.0497\n",
      "Epoch 172/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.7257 - g_loss: 1.1351\n",
      "Epoch 173/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.7098 - g_loss: 1.0893\n",
      "Epoch 174/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6476 - g_loss: 0.9588\n",
      "Epoch 175/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6574 - g_loss: 0.9101\n",
      "Epoch 176/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6234 - g_loss: 0.9980\n",
      "Epoch 177/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6271 - g_loss: 1.0410\n",
      "Epoch 178/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6772 - g_loss: 0.9962\n",
      "Epoch 179/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6751 - g_loss: 1.0042\n",
      "Epoch 180/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6482 - g_loss: 0.9573\n",
      "Epoch 181/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.6728 - g_loss: 1.0062\n",
      "Epoch 182/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6549 - g_loss: 0.8946\n",
      "Epoch 183/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.6209 - g_loss: 0.9672\n",
      "Epoch 184/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.7073 - g_loss: 0.9909\n",
      "Epoch 185/3000\n",
      "104/104 [==============================] - 11s 108ms/step - d_loss: 0.7022 - g_loss: 1.1626\n",
      "Epoch 186/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.7459 - g_loss: 1.0331\n",
      "Epoch 187/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6733 - g_loss: 0.9950\n",
      "Epoch 188/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.7071 - g_loss: 0.9464\n",
      "Epoch 189/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6274 - g_loss: 0.9521\n",
      "Epoch 190/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.7113 - g_loss: 0.9239\n",
      "Epoch 191/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6452 - g_loss: 0.9704\n",
      "Epoch 192/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6754 - g_loss: 0.9716\n",
      "Epoch 193/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.6131 - g_loss: 1.0528\n",
      "Epoch 194/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6709 - g_loss: 0.8963\n",
      "Epoch 195/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6558 - g_loss: 0.9927\n",
      "Epoch 196/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.6657 - g_loss: 1.0123\n",
      "Epoch 197/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6690 - g_loss: 1.0570\n",
      "Epoch 198/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5938 - g_loss: 1.3458\n",
      "Epoch 199/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.7046 - g_loss: 1.0087\n",
      "Epoch 200/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6384 - g_loss: 0.9275\n",
      "Epoch 201/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.7119 - g_loss: 0.8779\n",
      "Epoch 202/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6648 - g_loss: 1.0496\n",
      "Epoch 203/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6567 - g_loss: 0.9235\n",
      "Epoch 204/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.6658 - g_loss: 0.9420\n",
      "Epoch 205/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.7061 - g_loss: 0.8933\n",
      "Epoch 206/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6918 - g_loss: 0.9283\n",
      "Epoch 207/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6780 - g_loss: 0.8470\n",
      "Epoch 208/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6590 - g_loss: 0.9333\n",
      "Epoch 209/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6621 - g_loss: 0.9266\n",
      "Epoch 210/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6805 - g_loss: 1.0199\n",
      "Epoch 211/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6513 - g_loss: 1.0753\n",
      "Epoch 212/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.7329 - g_loss: 1.0350\n",
      "Epoch 213/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6618 - g_loss: 1.3110\n",
      "Epoch 214/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6472 - g_loss: 1.1126\n",
      "Epoch 215/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.6640 - g_loss: 1.0130\n",
      "Epoch 216/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6269 - g_loss: 1.0827\n",
      "Epoch 217/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6613 - g_loss: 1.1748\n",
      "Epoch 218/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.7042 - g_loss: 1.0833\n",
      "Epoch 219/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6986 - g_loss: 1.0137\n",
      "Epoch 220/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6615 - g_loss: 0.9546\n",
      "Epoch 221/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6704 - g_loss: 0.9235\n",
      "Epoch 222/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6783 - g_loss: 0.9199\n",
      "Epoch 223/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6311 - g_loss: 0.9616\n",
      "Epoch 224/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6911 - g_loss: 1.0042\n",
      "Epoch 225/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6797 - g_loss: 1.1193\n",
      "Epoch 226/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6348 - g_loss: 1.0758\n",
      "Epoch 227/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6166 - g_loss: 1.0997\n",
      "Epoch 228/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6011 - g_loss: 1.1811\n",
      "Epoch 229/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6319 - g_loss: 1.3083\n",
      "Epoch 230/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6571 - g_loss: 0.9483\n",
      "Epoch 231/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6465 - g_loss: 1.0156\n",
      "Epoch 232/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6402 - g_loss: 1.0868\n",
      "Epoch 233/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6707 - g_loss: 1.2964\n",
      "Epoch 234/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6305 - g_loss: 1.0339\n",
      "Epoch 235/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6804 - g_loss: 1.0422\n",
      "Epoch 236/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6843 - g_loss: 0.9949\n",
      "Epoch 237/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6882 - g_loss: 0.9308\n",
      "Epoch 238/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6365 - g_loss: 0.9715\n",
      "Epoch 239/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6421 - g_loss: 1.0189\n",
      "Epoch 240/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6935 - g_loss: 1.0640\n",
      "Epoch 241/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.7282 - g_loss: 1.1175\n",
      "Epoch 242/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6892 - g_loss: 1.0957\n",
      "Epoch 243/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.6827 - g_loss: 0.9788\n",
      "Epoch 244/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6523 - g_loss: 1.0251\n",
      "Epoch 245/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.6647 - g_loss: 1.0474\n",
      "Epoch 246/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.6738 - g_loss: 1.0343\n",
      "Epoch 247/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6794 - g_loss: 1.0844\n",
      "Epoch 248/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6473 - g_loss: 1.3290\n",
      "Epoch 249/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.6732 - g_loss: 1.0109\n",
      "Epoch 250/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6212 - g_loss: 0.9312\n",
      "Epoch 251/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6420 - g_loss: 0.9329\n",
      "Epoch 252/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6373 - g_loss: 0.9324\n",
      "Epoch 253/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6672 - g_loss: 0.9359\n",
      "Epoch 254/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6353 - g_loss: 0.9931\n",
      "Epoch 255/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.6284 - g_loss: 0.9437\n",
      "Epoch 256/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.6195 - g_loss: 1.0553\n",
      "Epoch 257/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6635 - g_loss: 1.1181\n",
      "Epoch 258/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6626 - g_loss: 1.0506\n",
      "Epoch 259/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6433 - g_loss: 1.0620\n",
      "Epoch 260/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6162 - g_loss: 1.1255\n",
      "Epoch 261/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6453 - g_loss: 1.0324\n",
      "Epoch 262/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6473 - g_loss: 1.1495\n",
      "Epoch 263/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6821 - g_loss: 1.1123\n",
      "Epoch 264/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6508 - g_loss: 0.9865\n",
      "Epoch 265/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6487 - g_loss: 0.9717\n",
      "Epoch 266/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5986 - g_loss: 1.0229\n",
      "Epoch 267/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6869 - g_loss: 1.0561\n",
      "Epoch 268/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.6634 - g_loss: 1.0208\n",
      "Epoch 269/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.6243 - g_loss: 1.0117\n",
      "Epoch 270/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.6525 - g_loss: 1.0648\n",
      "Epoch 271/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6599 - g_loss: 1.3374\n",
      "Epoch 272/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6581 - g_loss: 1.1618\n",
      "Epoch 273/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6871 - g_loss: 0.9610\n",
      "Epoch 274/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6385 - g_loss: 0.9823\n",
      "Epoch 275/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6167 - g_loss: 1.0678\n",
      "Epoch 276/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6388 - g_loss: 1.0557\n",
      "Epoch 277/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6199 - g_loss: 1.0051\n",
      "Epoch 278/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6709 - g_loss: 1.0313\n",
      "Epoch 279/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6494 - g_loss: 1.2082\n",
      "Epoch 280/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6342 - g_loss: 1.0886\n",
      "Epoch 281/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6132 - g_loss: 1.0333\n",
      "Epoch 282/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6415 - g_loss: 0.9839\n",
      "Epoch 283/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6070 - g_loss: 1.0597\n",
      "Epoch 284/3000\n",
      "104/104 [==============================] - 11s 108ms/step - d_loss: 0.6899 - g_loss: 1.2409\n",
      "Epoch 285/3000\n",
      "104/104 [==============================] - 11s 107ms/step - d_loss: 0.6149 - g_loss: 1.4557\n",
      "Epoch 286/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.6766 - g_loss: 1.0812\n",
      "Epoch 287/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6600 - g_loss: 1.1326\n",
      "Epoch 288/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6823 - g_loss: 1.0051\n",
      "Epoch 289/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.6183 - g_loss: 1.0272\n",
      "Epoch 290/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.5982 - g_loss: 1.0814\n",
      "Epoch 291/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.7424 - g_loss: 1.1694\n",
      "Epoch 292/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6106 - g_loss: 1.1939\n",
      "Epoch 293/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6748 - g_loss: 0.9131\n",
      "Epoch 294/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6514 - g_loss: 1.1053\n",
      "Epoch 295/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6525 - g_loss: 1.0579\n",
      "Epoch 296/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6198 - g_loss: 1.1919\n",
      "Epoch 297/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6286 - g_loss: 1.0068\n",
      "Epoch 298/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6179 - g_loss: 0.9883\n",
      "Epoch 299/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6495 - g_loss: 1.1315\n",
      "Epoch 300/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6801 - g_loss: 1.3036\n",
      "Epoch 301/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6797 - g_loss: 1.0414\n",
      "Epoch 302/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6379 - g_loss: 0.9613\n",
      "Epoch 303/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.5919 - g_loss: 1.0800\n",
      "Epoch 304/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6522 - g_loss: 1.0267\n",
      "Epoch 305/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6795 - g_loss: 1.1112\n",
      "Epoch 306/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6167 - g_loss: 1.0087\n",
      "Epoch 307/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6292 - g_loss: 1.0774\n",
      "Epoch 308/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6433 - g_loss: 1.1370\n",
      "Epoch 309/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6222 - g_loss: 1.0548\n",
      "Epoch 310/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6441 - g_loss: 1.0053\n",
      "Epoch 311/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6505 - g_loss: 1.2309\n",
      "Epoch 312/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6552 - g_loss: 1.0424\n",
      "Epoch 313/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.5968 - g_loss: 1.0697\n",
      "Epoch 314/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5674 - g_loss: 1.1817\n",
      "Epoch 315/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6082 - g_loss: 1.1857\n",
      "Epoch 316/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6393 - g_loss: 1.4906\n",
      "Epoch 317/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.7149 - g_loss: 1.1683\n",
      "Epoch 318/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6345 - g_loss: 1.0760\n",
      "Epoch 319/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5900 - g_loss: 1.2128\n",
      "Epoch 320/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.5705 - g_loss: 1.2244\n",
      "Epoch 321/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.6664 - g_loss: 1.0955\n",
      "Epoch 322/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6313 - g_loss: 1.0400\n",
      "Epoch 323/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.5980 - g_loss: 1.2195\n",
      "Epoch 324/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.6306 - g_loss: 1.3086\n",
      "Epoch 325/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6249 - g_loss: 1.0392\n",
      "Epoch 326/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6399 - g_loss: 1.0295\n",
      "Epoch 327/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.7051 - g_loss: 1.3171\n",
      "Epoch 328/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6254 - g_loss: 1.0108\n",
      "Epoch 329/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6582 - g_loss: 0.9746\n",
      "Epoch 330/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6081 - g_loss: 1.0320\n",
      "Epoch 331/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6520 - g_loss: 1.0238\n",
      "Epoch 332/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6101 - g_loss: 1.0490\n",
      "Epoch 333/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5807 - g_loss: 1.1333\n",
      "Epoch 334/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6585 - g_loss: 1.0344\n",
      "Epoch 335/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6137 - g_loss: 0.9994\n",
      "Epoch 336/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6294 - g_loss: 1.1717\n",
      "Epoch 337/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6748 - g_loss: 1.0938\n",
      "Epoch 338/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.7023 - g_loss: 1.0505\n",
      "Epoch 339/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.6171 - g_loss: 1.1256\n",
      "Epoch 340/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.5839 - g_loss: 1.1062\n",
      "Epoch 341/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5796 - g_loss: 1.3430\n",
      "Epoch 342/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6496 - g_loss: 1.1522\n",
      "Epoch 343/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.5853 - g_loss: 1.1398\n",
      "Epoch 344/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.7371 - g_loss: 1.0898\n",
      "Epoch 345/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.5803 - g_loss: 1.1945\n",
      "Epoch 346/3000\n",
      "104/104 [==============================] - 11s 108ms/step - d_loss: 0.6763 - g_loss: 1.0274\n",
      "Epoch 347/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6094 - g_loss: 1.1473\n",
      "Epoch 348/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5927 - g_loss: 1.1200\n",
      "Epoch 349/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6730 - g_loss: 1.0443\n",
      "Epoch 350/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6174 - g_loss: 1.0670\n",
      "Epoch 351/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6610 - g_loss: 1.0148\n",
      "Epoch 352/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6590 - g_loss: 1.1551\n",
      "Epoch 353/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6295 - g_loss: 1.0986\n",
      "Epoch 354/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6075 - g_loss: 1.1567\n",
      "Epoch 355/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5973 - g_loss: 1.1357\n",
      "Epoch 356/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6633 - g_loss: 0.9860\n",
      "Epoch 357/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6125 - g_loss: 1.0719\n",
      "Epoch 358/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5881 - g_loss: 1.1193\n",
      "Epoch 359/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6016 - g_loss: 1.1196\n",
      "Epoch 360/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6361 - g_loss: 1.1436\n",
      "Epoch 361/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.5999 - g_loss: 1.1367\n",
      "Epoch 362/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6450 - g_loss: 1.1100\n",
      "Epoch 363/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.7380 - g_loss: 1.1464\n",
      "Epoch 364/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6949 - g_loss: 1.1329\n",
      "Epoch 365/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6976 - g_loss: 1.0704\n",
      "Epoch 366/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.6925 - g_loss: 1.1137\n",
      "Epoch 367/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.5825 - g_loss: 1.1310\n",
      "Epoch 368/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6216 - g_loss: 1.0636\n",
      "Epoch 369/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.5925 - g_loss: 1.0461\n",
      "Epoch 370/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5924 - g_loss: 1.1975\n",
      "Epoch 371/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6048 - g_loss: 1.0316\n",
      "Epoch 372/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6729 - g_loss: 1.1124\n",
      "Epoch 373/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6052 - g_loss: 1.0834\n",
      "Epoch 374/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6327 - g_loss: 1.1174\n",
      "Epoch 375/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6553 - g_loss: 1.0599\n",
      "Epoch 376/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6285 - g_loss: 1.1948\n",
      "Epoch 377/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6048 - g_loss: 1.2205\n",
      "Epoch 378/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6778 - g_loss: 0.9157\n",
      "Epoch 379/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6235 - g_loss: 0.9988\n",
      "Epoch 380/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5982 - g_loss: 1.1249\n",
      "Epoch 381/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6314 - g_loss: 1.0001\n",
      "Epoch 382/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6061 - g_loss: 1.0821\n",
      "Epoch 383/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6239 - g_loss: 1.1307\n",
      "Epoch 384/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6774 - g_loss: 1.0059\n",
      "Epoch 385/3000\n",
      "104/104 [==============================] - 11s 108ms/step - d_loss: 0.6164 - g_loss: 1.1089\n",
      "Epoch 386/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6818 - g_loss: 0.9772\n",
      "Epoch 387/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6423 - g_loss: 1.1567\n",
      "Epoch 388/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6180 - g_loss: 1.2289\n",
      "Epoch 389/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6281 - g_loss: 1.1679\n",
      "Epoch 390/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.6160 - g_loss: 1.0380\n",
      "Epoch 391/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.6388 - g_loss: 1.0188\n",
      "Epoch 392/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5994 - g_loss: 1.1666\n",
      "Epoch 393/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6837 - g_loss: 0.9681\n",
      "Epoch 394/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6100 - g_loss: 1.0280\n",
      "Epoch 395/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6626 - g_loss: 1.0957\n",
      "Epoch 396/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5916 - g_loss: 1.0795\n",
      "Epoch 397/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.5988 - g_loss: 1.0971\n",
      "Epoch 398/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.6497 - g_loss: 1.0864\n",
      "Epoch 399/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6305 - g_loss: 1.0906\n",
      "Epoch 400/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6555 - g_loss: 1.0390\n",
      "Epoch 401/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6091 - g_loss: 1.0855\n",
      "Epoch 402/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6260 - g_loss: 1.1553\n",
      "Epoch 403/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6360 - g_loss: 1.2427\n",
      "Epoch 404/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6643 - g_loss: 1.0707\n",
      "Epoch 405/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.6075 - g_loss: 1.0594\n",
      "Epoch 406/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6002 - g_loss: 1.1223\n",
      "Epoch 407/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6717 - g_loss: 1.0167\n",
      "Epoch 408/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6644 - g_loss: 1.0158\n",
      "Epoch 409/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6002 - g_loss: 1.0942\n",
      "Epoch 410/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.6277 - g_loss: 1.2201\n",
      "Epoch 411/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5783 - g_loss: 1.1683\n",
      "Epoch 412/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6499 - g_loss: 0.9606\n",
      "Epoch 413/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.5777 - g_loss: 1.0702\n",
      "Epoch 414/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6483 - g_loss: 1.1508\n",
      "Epoch 415/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6312 - g_loss: 1.0021\n",
      "Epoch 416/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6256 - g_loss: 0.9627\n",
      "Epoch 417/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6986 - g_loss: 0.9326\n",
      "Epoch 418/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5950 - g_loss: 1.0653\n",
      "Epoch 419/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6654 - g_loss: 1.0034\n",
      "Epoch 420/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6214 - g_loss: 1.0339\n",
      "Epoch 421/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6332 - g_loss: 0.9910\n",
      "Epoch 422/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6207 - g_loss: 1.0545\n",
      "Epoch 423/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6555 - g_loss: 1.0078\n",
      "Epoch 424/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6794 - g_loss: 1.1055\n",
      "Epoch 425/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.5972 - g_loss: 1.3030\n",
      "Epoch 426/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.7040 - g_loss: 0.9326\n",
      "Epoch 427/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6358 - g_loss: 1.1102\n",
      "Epoch 428/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6755 - g_loss: 0.9872\n",
      "Epoch 429/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.6408 - g_loss: 1.0084\n",
      "Epoch 430/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.6867 - g_loss: 1.0078\n",
      "Epoch 431/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6549 - g_loss: 1.0705\n",
      "Epoch 432/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6763 - g_loss: 0.9024\n",
      "Epoch 433/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6249 - g_loss: 1.0141\n",
      "Epoch 434/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6307 - g_loss: 1.0947\n",
      "Epoch 435/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6666 - g_loss: 1.0240\n",
      "Epoch 436/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5902 - g_loss: 1.1035\n",
      "Epoch 437/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6042 - g_loss: 1.1223\n",
      "Epoch 438/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6275 - g_loss: 1.1233\n",
      "Epoch 439/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6454 - g_loss: 1.0786\n",
      "Epoch 440/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6800 - g_loss: 1.1299\n",
      "Epoch 441/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6667 - g_loss: 1.4172\n",
      "Epoch 442/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6377 - g_loss: 1.0461\n",
      "Epoch 443/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6136 - g_loss: 1.0489\n",
      "Epoch 444/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6474 - g_loss: 1.0102\n",
      "Epoch 445/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6161 - g_loss: 0.9862\n",
      "Epoch 446/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6218 - g_loss: 1.0450\n",
      "Epoch 447/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.6126 - g_loss: 1.1637\n",
      "Epoch 448/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6258 - g_loss: 0.9881\n",
      "Epoch 449/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6225 - g_loss: 1.1043\n",
      "Epoch 450/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6744 - g_loss: 1.0388\n",
      "Epoch 451/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6776 - g_loss: 0.8708\n",
      "Epoch 452/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5840 - g_loss: 1.0687\n",
      "Epoch 453/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6737 - g_loss: 1.1031\n",
      "Epoch 454/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6860 - g_loss: 0.9183\n",
      "Epoch 455/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6828 - g_loss: 0.9369\n",
      "Epoch 456/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6913 - g_loss: 0.9435\n",
      "Epoch 457/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.6275 - g_loss: 1.1497\n",
      "Epoch 458/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6554 - g_loss: 1.1707\n",
      "Epoch 459/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6554 - g_loss: 1.1998\n",
      "Epoch 460/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6008 - g_loss: 1.1183\n",
      "Epoch 461/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6280 - g_loss: 1.1315\n",
      "Epoch 462/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6787 - g_loss: 1.1226\n",
      "Epoch 463/3000\n",
      "104/104 [==============================] - 11s 107ms/step - d_loss: 0.6394 - g_loss: 1.0694\n",
      "Epoch 464/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6580 - g_loss: 1.1817\n",
      "Epoch 465/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.5939 - g_loss: 1.1021\n",
      "Epoch 466/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.7034 - g_loss: 1.0267\n",
      "Epoch 467/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.5839 - g_loss: 1.0217\n",
      "Epoch 468/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.6564 - g_loss: 0.9794\n",
      "Epoch 469/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6587 - g_loss: 1.0519\n",
      "Epoch 470/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6368 - g_loss: 0.9521\n",
      "Epoch 471/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6360 - g_loss: 0.9450\n",
      "Epoch 472/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6692 - g_loss: 0.9458\n",
      "Epoch 473/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6297 - g_loss: 0.9628\n",
      "Epoch 474/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6421 - g_loss: 0.9399\n",
      "Epoch 475/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6517 - g_loss: 0.9959\n",
      "Epoch 476/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6463 - g_loss: 0.9379\n",
      "Epoch 477/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.6376 - g_loss: 0.9660\n",
      "Epoch 478/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6276 - g_loss: 0.9610\n",
      "Epoch 479/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6480 - g_loss: 0.9701\n",
      "Epoch 480/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6448 - g_loss: 0.9821\n",
      "Epoch 481/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6340 - g_loss: 0.9511\n",
      "Epoch 482/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6170 - g_loss: 0.9834\n",
      "Epoch 483/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6622 - g_loss: 0.9955\n",
      "Epoch 484/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6684 - g_loss: 1.2710\n",
      "Epoch 485/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6524 - g_loss: 1.0789\n",
      "Epoch 486/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.6367 - g_loss: 1.0156\n",
      "Epoch 487/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.6696 - g_loss: 1.0456\n",
      "Epoch 488/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6806 - g_loss: 1.0046\n",
      "Epoch 489/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5725 - g_loss: 1.1012\n",
      "Epoch 490/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.6202 - g_loss: 1.1384\n",
      "Epoch 491/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6069 - g_loss: 1.0884\n",
      "Epoch 492/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6383 - g_loss: 1.0207\n",
      "Epoch 493/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6292 - g_loss: 0.9947\n",
      "Epoch 494/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6647 - g_loss: 0.9242\n",
      "Epoch 495/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6309 - g_loss: 1.1218\n",
      "Epoch 496/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6152 - g_loss: 1.1021\n",
      "Epoch 497/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6379 - g_loss: 0.9774\n",
      "Epoch 498/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6576 - g_loss: 1.0756\n",
      "Epoch 499/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6430 - g_loss: 1.1478\n",
      "Epoch 500/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6485 - g_loss: 0.9067\n",
      "Epoch 501/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.5929 - g_loss: 1.0629\n",
      "Epoch 502/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6400 - g_loss: 1.1366\n",
      "Epoch 503/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6502 - g_loss: 1.1709\n",
      "Epoch 504/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.5694 - g_loss: 1.1632\n",
      "Epoch 505/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6330 - g_loss: 1.0175\n",
      "Epoch 506/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6252 - g_loss: 1.0400\n",
      "Epoch 507/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6186 - g_loss: 1.1495\n",
      "Epoch 508/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.6642 - g_loss: 1.0368\n",
      "Epoch 509/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.6157 - g_loss: 1.0418\n",
      "Epoch 510/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.7278 - g_loss: 1.4649\n",
      "Epoch 511/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.6093 - g_loss: 1.0833\n",
      "Epoch 512/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.6097 - g_loss: 1.0664\n",
      "Epoch 513/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.5828 - g_loss: 1.1175\n",
      "Epoch 514/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6091 - g_loss: 1.0073\n",
      "Epoch 515/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6302 - g_loss: 0.9773\n",
      "Epoch 516/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5895 - g_loss: 1.0600\n",
      "Epoch 517/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.6051 - g_loss: 1.0559\n",
      "Epoch 518/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6334 - g_loss: 1.0099\n",
      "Epoch 519/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.6250 - g_loss: 1.0063\n",
      "Epoch 520/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6113 - g_loss: 1.0165\n",
      "Epoch 521/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6188 - g_loss: 1.0261\n",
      "Epoch 522/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6081 - g_loss: 1.0733\n",
      "Epoch 523/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6342 - g_loss: 1.1384\n",
      "Epoch 524/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.5834 - g_loss: 1.0338\n",
      "Epoch 525/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6226 - g_loss: 0.9752\n",
      "Epoch 526/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.5876 - g_loss: 1.1658\n",
      "Epoch 527/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6165 - g_loss: 1.0720\n",
      "Epoch 528/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6571 - g_loss: 1.0507\n",
      "Epoch 529/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5901 - g_loss: 1.0754\n",
      "Epoch 530/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5929 - g_loss: 1.1078\n",
      "Epoch 531/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6365 - g_loss: 1.1965\n",
      "Epoch 532/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6717 - g_loss: 1.2517\n",
      "Epoch 533/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5890 - g_loss: 1.2558\n",
      "Epoch 534/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.5878 - g_loss: 1.1136\n",
      "Epoch 535/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6468 - g_loss: 1.1344\n",
      "Epoch 536/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6217 - g_loss: 1.1138\n",
      "Epoch 537/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6269 - g_loss: 1.0009\n",
      "Epoch 538/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.6238 - g_loss: 1.0362\n",
      "Epoch 539/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6391 - g_loss: 1.0043\n",
      "Epoch 540/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6043 - g_loss: 0.9909\n",
      "Epoch 541/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6363 - g_loss: 1.0418\n",
      "Epoch 542/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.6284 - g_loss: 0.9971\n",
      "Epoch 543/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.6312 - g_loss: 0.9853\n",
      "Epoch 544/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6017 - g_loss: 1.0735\n",
      "Epoch 545/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6578 - g_loss: 0.9853\n",
      "Epoch 546/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6220 - g_loss: 1.0844\n",
      "Epoch 547/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6968 - g_loss: 1.2295\n",
      "Epoch 548/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6810 - g_loss: 1.0267\n",
      "Epoch 549/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6131 - g_loss: 1.1537\n",
      "Epoch 550/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.6717 - g_loss: 1.0900\n",
      "Epoch 551/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6044 - g_loss: 1.0921\n",
      "Epoch 552/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6005 - g_loss: 1.0268\n",
      "Epoch 553/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6256 - g_loss: 0.9937\n",
      "Epoch 554/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6016 - g_loss: 1.0114\n",
      "Epoch 555/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6125 - g_loss: 0.9987\n",
      "Epoch 556/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6166 - g_loss: 0.9940\n",
      "Epoch 557/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6414 - g_loss: 1.0274\n",
      "Epoch 558/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6108 - g_loss: 1.0225\n",
      "Epoch 559/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6016 - g_loss: 1.1268\n",
      "Epoch 560/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6513 - g_loss: 1.2920\n",
      "Epoch 561/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6400 - g_loss: 1.2667\n",
      "Epoch 562/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.6768 - g_loss: 1.0382\n",
      "Epoch 563/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6281 - g_loss: 1.1258\n",
      "Epoch 564/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5990 - g_loss: 1.1538\n",
      "Epoch 565/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6189 - g_loss: 1.2319\n",
      "Epoch 566/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6180 - g_loss: 0.9870\n",
      "Epoch 567/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6057 - g_loss: 0.9842\n",
      "Epoch 568/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5943 - g_loss: 1.0778\n",
      "Epoch 569/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5841 - g_loss: 1.0284\n",
      "Epoch 570/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6356 - g_loss: 0.9848\n",
      "Epoch 571/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6082 - g_loss: 1.0279\n",
      "Epoch 572/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.6216 - g_loss: 0.9973\n",
      "Epoch 573/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6545 - g_loss: 1.0001\n",
      "Epoch 574/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6183 - g_loss: 0.9950\n",
      "Epoch 575/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6190 - g_loss: 1.0271\n",
      "Epoch 576/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6268 - g_loss: 1.0500\n",
      "Epoch 577/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5979 - g_loss: 1.0066\n",
      "Epoch 578/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6007 - g_loss: 1.0817\n",
      "Epoch 579/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6195 - g_loss: 1.0592\n",
      "Epoch 580/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6287 - g_loss: 1.1769\n",
      "Epoch 581/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6331 - g_loss: 1.0321\n",
      "Epoch 582/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6395 - g_loss: 0.9910\n",
      "Epoch 583/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6075 - g_loss: 1.1484\n",
      "Epoch 584/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6260 - g_loss: 1.0118\n",
      "Epoch 585/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6143 - g_loss: 1.1298\n",
      "Epoch 586/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6590 - g_loss: 1.0527\n",
      "Epoch 587/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6113 - g_loss: 1.0486\n",
      "Epoch 588/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.6126 - g_loss: 1.1020\n",
      "Epoch 589/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.6021 - g_loss: 1.1485\n",
      "Epoch 590/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.6460 - g_loss: 1.0141\n",
      "Epoch 591/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5929 - g_loss: 1.1648\n",
      "Epoch 592/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6196 - g_loss: 1.0352\n",
      "Epoch 593/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6230 - g_loss: 1.0407\n",
      "Epoch 594/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6115 - g_loss: 0.9985\n",
      "Epoch 595/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6168 - g_loss: 0.9641\n",
      "Epoch 596/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6313 - g_loss: 0.9942\n",
      "Epoch 597/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.6073 - g_loss: 0.9913\n",
      "Epoch 598/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6153 - g_loss: 1.0145\n",
      "Epoch 599/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.5901 - g_loss: 1.2122\n",
      "Epoch 600/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.5988 - g_loss: 1.0988\n",
      "Epoch 601/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6164 - g_loss: 1.1334\n",
      "Epoch 602/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6574 - g_loss: 0.9611\n",
      "Epoch 603/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6185 - g_loss: 0.9946\n",
      "Epoch 604/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.5910 - g_loss: 1.0701\n",
      "Epoch 605/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6166 - g_loss: 1.1214\n",
      "Epoch 606/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5933 - g_loss: 1.1289\n",
      "Epoch 607/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6231 - g_loss: 1.0960\n",
      "Epoch 608/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5793 - g_loss: 1.0922\n",
      "Epoch 609/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5894 - g_loss: 1.1699\n",
      "Epoch 610/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.6596 - g_loss: 1.0674\n",
      "Epoch 611/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5601 - g_loss: 1.1250\n",
      "Epoch 612/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5975 - g_loss: 1.1853\n",
      "Epoch 613/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6870 - g_loss: 1.1149\n",
      "Epoch 614/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.6278 - g_loss: 1.3203\n",
      "Epoch 615/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.6157 - g_loss: 1.0254\n",
      "Epoch 616/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6805 - g_loss: 1.2748\n",
      "Epoch 617/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.6064 - g_loss: 1.3683\n",
      "Epoch 618/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.5632 - g_loss: 1.1506\n",
      "Epoch 619/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.5993 - g_loss: 1.1248\n",
      "Epoch 620/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5872 - g_loss: 1.0998\n",
      "Epoch 621/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5944 - g_loss: 1.0605\n",
      "Epoch 622/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.5900 - g_loss: 1.0255\n",
      "Epoch 623/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.6148 - g_loss: 1.0163\n",
      "Epoch 624/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6049 - g_loss: 1.0025\n",
      "Epoch 625/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.5971 - g_loss: 1.0506\n",
      "Epoch 626/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.6113 - g_loss: 1.0128\n",
      "Epoch 627/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.5990 - g_loss: 1.2060\n",
      "Epoch 628/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6324 - g_loss: 1.0892\n",
      "Epoch 629/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5875 - g_loss: 1.1744\n",
      "Epoch 630/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6058 - g_loss: 1.1072\n",
      "Epoch 631/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5750 - g_loss: 1.1542\n",
      "Epoch 632/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5770 - g_loss: 1.1895\n",
      "Epoch 633/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5993 - g_loss: 1.0853\n",
      "Epoch 634/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.6104 - g_loss: 1.0880\n",
      "Epoch 635/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5812 - g_loss: 1.1474\n",
      "Epoch 636/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6305 - g_loss: 1.0428\n",
      "Epoch 637/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6013 - g_loss: 1.1060\n",
      "Epoch 638/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6103 - g_loss: 1.1119\n",
      "Epoch 639/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5983 - g_loss: 1.1257\n",
      "Epoch 640/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.5667 - g_loss: 1.1214\n",
      "Epoch 641/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6153 - g_loss: 1.0419\n",
      "Epoch 642/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.6304 - g_loss: 1.1416\n",
      "Epoch 643/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.6156 - g_loss: 1.0274\n",
      "Epoch 644/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6015 - g_loss: 1.0500\n",
      "Epoch 645/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.5925 - g_loss: 1.0349\n",
      "Epoch 646/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6019 - g_loss: 1.0313\n",
      "Epoch 647/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.6290 - g_loss: 0.9837\n",
      "Epoch 648/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5925 - g_loss: 1.0981\n",
      "Epoch 649/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5605 - g_loss: 1.1417\n",
      "Epoch 650/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.6056 - g_loss: 1.0449\n",
      "Epoch 651/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5894 - g_loss: 1.1247\n",
      "Epoch 652/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5680 - g_loss: 1.1756\n",
      "Epoch 653/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6043 - g_loss: 1.1246\n",
      "Epoch 654/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.6066 - g_loss: 1.1015\n",
      "Epoch 655/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5912 - g_loss: 1.0812\n",
      "Epoch 656/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5802 - g_loss: 1.0880\n",
      "Epoch 657/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5943 - g_loss: 1.0589\n",
      "Epoch 658/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5753 - g_loss: 1.1664\n",
      "Epoch 659/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5765 - g_loss: 1.0959\n",
      "Epoch 660/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6049 - g_loss: 1.0753\n",
      "Epoch 661/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6005 - g_loss: 1.0516\n",
      "Epoch 662/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5744 - g_loss: 1.1051\n",
      "Epoch 663/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5633 - g_loss: 1.0981\n",
      "Epoch 664/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.5772 - g_loss: 1.2172\n",
      "Epoch 665/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6042 - g_loss: 1.1772\n",
      "Epoch 666/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.5858 - g_loss: 1.1672\n",
      "Epoch 667/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.5874 - g_loss: 1.1606\n",
      "Epoch 668/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.5990 - g_loss: 1.0945\n",
      "Epoch 669/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.5837 - g_loss: 1.1073\n",
      "Epoch 670/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5857 - g_loss: 1.0684\n",
      "Epoch 671/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.5778 - g_loss: 1.1263\n",
      "Epoch 672/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.6067 - g_loss: 1.1306\n",
      "Epoch 673/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5823 - g_loss: 1.1491\n",
      "Epoch 674/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5900 - g_loss: 1.1166\n",
      "Epoch 675/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5746 - g_loss: 1.1049\n",
      "Epoch 676/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5720 - g_loss: 1.0848\n",
      "Epoch 677/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5783 - g_loss: 1.1290\n",
      "Epoch 678/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5637 - g_loss: 1.1403\n",
      "Epoch 679/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5684 - g_loss: 1.1591\n",
      "Epoch 680/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.6061 - g_loss: 1.2011\n",
      "Epoch 681/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.5823 - g_loss: 1.0435\n",
      "Epoch 682/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.5826 - g_loss: 1.2199\n",
      "Epoch 683/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5816 - g_loss: 1.2093\n",
      "Epoch 684/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.5537 - g_loss: 1.1910\n",
      "Epoch 685/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.5669 - g_loss: 1.2471\n",
      "Epoch 686/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.5576 - g_loss: 1.1780\n",
      "Epoch 687/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.5780 - g_loss: 1.1388\n",
      "Epoch 688/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.5737 - g_loss: 1.1891\n",
      "Epoch 689/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5657 - g_loss: 1.1227\n",
      "Epoch 690/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.5706 - g_loss: 1.2152\n",
      "Epoch 691/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5753 - g_loss: 1.1781\n",
      "Epoch 692/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.5843 - g_loss: 1.0962\n",
      "Epoch 693/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5371 - g_loss: 1.2256\n",
      "Epoch 694/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.5943 - g_loss: 1.1336\n",
      "Epoch 695/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.5614 - g_loss: 1.1299\n",
      "Epoch 696/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5756 - g_loss: 1.1320\n",
      "Epoch 697/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5618 - g_loss: 1.1432\n",
      "Epoch 698/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5590 - g_loss: 1.2369\n",
      "Epoch 699/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.5772 - g_loss: 1.2089\n",
      "Epoch 700/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.5950 - g_loss: 1.1641\n",
      "Epoch 701/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5748 - g_loss: 1.1491\n",
      "Epoch 702/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.6017 - g_loss: 1.1614\n",
      "Epoch 703/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.5333 - g_loss: 1.2117\n",
      "Epoch 704/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.5843 - g_loss: 1.1547\n",
      "Epoch 705/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5411 - g_loss: 1.2429\n",
      "Epoch 706/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.5449 - g_loss: 1.1984\n",
      "Epoch 707/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5934 - g_loss: 1.1775\n",
      "Epoch 708/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.5600 - g_loss: 1.1678\n",
      "Epoch 709/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5702 - g_loss: 1.1457\n",
      "Epoch 710/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5589 - g_loss: 1.2062\n",
      "Epoch 711/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5742 - g_loss: 1.1024\n",
      "Epoch 712/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5823 - g_loss: 1.2164\n",
      "Epoch 713/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5561 - g_loss: 1.2745\n",
      "Epoch 714/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.5380 - g_loss: 1.3329\n",
      "Epoch 715/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.5739 - g_loss: 1.3430\n",
      "Epoch 716/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5677 - g_loss: 1.2545\n",
      "Epoch 717/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5525 - g_loss: 1.1742\n",
      "Epoch 718/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5649 - g_loss: 1.1080\n",
      "Epoch 719/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5630 - g_loss: 1.1305\n",
      "Epoch 720/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5510 - g_loss: 1.1548\n",
      "Epoch 721/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5520 - g_loss: 1.2250\n",
      "Epoch 722/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5705 - g_loss: 1.1080\n",
      "Epoch 723/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5678 - g_loss: 1.0889\n",
      "Epoch 724/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5722 - g_loss: 1.1403\n",
      "Epoch 725/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.5278 - g_loss: 1.1714\n",
      "Epoch 726/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5446 - g_loss: 1.1774\n",
      "Epoch 727/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.5459 - g_loss: 1.1553\n",
      "Epoch 728/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5973 - g_loss: 1.2432\n",
      "Epoch 729/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5670 - g_loss: 1.2087\n",
      "Epoch 730/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.5725 - g_loss: 1.3137\n",
      "Epoch 731/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5637 - g_loss: 1.1543\n",
      "Epoch 732/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.5366 - g_loss: 1.1430\n",
      "Epoch 733/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5428 - g_loss: 1.2250\n",
      "Epoch 734/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.5466 - g_loss: 1.1845\n",
      "Epoch 735/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5561 - g_loss: 1.2851\n",
      "Epoch 736/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5654 - g_loss: 1.2356\n",
      "Epoch 737/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5557 - g_loss: 1.1905\n",
      "Epoch 738/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.5285 - g_loss: 1.1957\n",
      "Epoch 739/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.5492 - g_loss: 1.1941\n",
      "Epoch 740/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5454 - g_loss: 1.1827\n",
      "Epoch 741/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5616 - g_loss: 1.1327\n",
      "Epoch 742/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.5462 - g_loss: 1.1958\n",
      "Epoch 743/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.5397 - g_loss: 1.2504\n",
      "Epoch 744/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.5721 - g_loss: 1.1741\n",
      "Epoch 745/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5413 - g_loss: 1.2236\n",
      "Epoch 746/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5547 - g_loss: 1.2294\n",
      "Epoch 747/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5455 - g_loss: 1.3591\n",
      "Epoch 748/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.5277 - g_loss: 1.3345\n",
      "Epoch 749/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.6009 - g_loss: 1.2609\n",
      "Epoch 750/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.5715 - g_loss: 1.1711\n",
      "Epoch 751/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5448 - g_loss: 1.1939\n",
      "Epoch 752/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.5415 - g_loss: 1.1811\n",
      "Epoch 753/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5316 - g_loss: 1.1523\n",
      "Epoch 754/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5455 - g_loss: 1.1989\n",
      "Epoch 755/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5457 - g_loss: 1.2441\n",
      "Epoch 756/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5473 - g_loss: 1.2034\n",
      "Epoch 757/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.5382 - g_loss: 1.1694\n",
      "Epoch 758/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5438 - g_loss: 1.1757\n",
      "Epoch 759/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.5385 - g_loss: 1.3476\n",
      "Epoch 760/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5504 - g_loss: 1.2610\n",
      "Epoch 761/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.5654 - g_loss: 1.2427\n",
      "Epoch 762/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5454 - g_loss: 1.2582\n",
      "Epoch 763/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.5358 - g_loss: 1.1913\n",
      "Epoch 764/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5451 - g_loss: 1.1971\n",
      "Epoch 765/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.5542 - g_loss: 1.1537\n",
      "Epoch 766/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.5423 - g_loss: 1.2103\n",
      "Epoch 767/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5430 - g_loss: 1.2424\n",
      "Epoch 768/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.5290 - g_loss: 1.1957\n",
      "Epoch 769/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5610 - g_loss: 1.1989\n",
      "Epoch 770/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5301 - g_loss: 1.2439\n",
      "Epoch 771/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.5487 - g_loss: 1.1825\n",
      "Epoch 772/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.5311 - g_loss: 1.2124\n",
      "Epoch 773/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5434 - g_loss: 1.1870\n",
      "Epoch 774/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5428 - g_loss: 1.2058\n",
      "Epoch 775/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.5405 - g_loss: 1.1844\n",
      "Epoch 776/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5382 - g_loss: 1.2355\n",
      "Epoch 777/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.5092 - g_loss: 1.2392\n",
      "Epoch 778/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5588 - g_loss: 1.1907\n",
      "Epoch 779/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.5185 - g_loss: 1.2106\n",
      "Epoch 780/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5145 - g_loss: 1.2552\n",
      "Epoch 781/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.5360 - g_loss: 1.2380\n",
      "Epoch 782/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5433 - g_loss: 1.4371\n",
      "Epoch 783/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5414 - g_loss: 1.3693\n",
      "Epoch 784/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.5325 - g_loss: 1.3248\n",
      "Epoch 785/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5193 - g_loss: 1.2496\n",
      "Epoch 786/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5396 - g_loss: 1.1865\n",
      "Epoch 787/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.5271 - g_loss: 1.2087\n",
      "Epoch 788/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5030 - g_loss: 1.2732\n",
      "Epoch 789/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.5276 - g_loss: 1.2186\n",
      "Epoch 790/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.5285 - g_loss: 1.2624\n",
      "Epoch 791/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5317 - g_loss: 1.1912\n",
      "Epoch 792/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5280 - g_loss: 1.2379\n",
      "Epoch 793/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.5069 - g_loss: 1.2695\n",
      "Epoch 794/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5177 - g_loss: 1.4052\n",
      "Epoch 795/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5335 - g_loss: 1.3097\n",
      "Epoch 796/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.5150 - g_loss: 1.3390\n",
      "Epoch 797/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5638 - g_loss: 1.3280\n",
      "Epoch 798/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5333 - g_loss: 1.2269\n",
      "Epoch 799/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5150 - g_loss: 1.2294\n",
      "Epoch 800/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5307 - g_loss: 1.2261\n",
      "Epoch 801/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5035 - g_loss: 1.2389\n",
      "Epoch 802/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.5174 - g_loss: 1.2255\n",
      "Epoch 803/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5105 - g_loss: 1.2175\n",
      "Epoch 804/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5119 - g_loss: 1.2174\n",
      "Epoch 805/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5336 - g_loss: 1.2251\n",
      "Epoch 806/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5268 - g_loss: 1.2350\n",
      "Epoch 807/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.5316 - g_loss: 1.2339\n",
      "Epoch 808/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5296 - g_loss: 1.2173\n",
      "Epoch 809/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.5259 - g_loss: 1.2622\n",
      "Epoch 810/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.5071 - g_loss: 1.2899\n",
      "Epoch 811/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.5153 - g_loss: 1.2921\n",
      "Epoch 812/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5186 - g_loss: 1.2811\n",
      "Epoch 813/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5181 - g_loss: 1.2825\n",
      "Epoch 814/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5245 - g_loss: 1.2835\n",
      "Epoch 815/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.5082 - g_loss: 1.2539\n",
      "Epoch 816/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.4918 - g_loss: 1.2626\n",
      "Epoch 817/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.5138 - g_loss: 1.2830\n",
      "Epoch 818/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5028 - g_loss: 1.2669\n",
      "Epoch 819/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5184 - g_loss: 1.3069\n",
      "Epoch 820/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.4894 - g_loss: 1.2778\n",
      "Epoch 821/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5238 - g_loss: 1.2448\n",
      "Epoch 822/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5141 - g_loss: 1.2353\n",
      "Epoch 823/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5049 - g_loss: 1.2399\n",
      "Epoch 824/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5068 - g_loss: 1.3123\n",
      "Epoch 825/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.4959 - g_loss: 1.3120\n",
      "Epoch 826/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.5195 - g_loss: 1.2675\n",
      "Epoch 827/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.4884 - g_loss: 1.3257\n",
      "Epoch 828/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5219 - g_loss: 1.2493\n",
      "Epoch 829/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.4951 - g_loss: 1.2616\n",
      "Epoch 830/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.4885 - g_loss: 1.2904\n",
      "Epoch 831/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5043 - g_loss: 1.3146\n",
      "Epoch 832/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5005 - g_loss: 1.3528\n",
      "Epoch 833/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5126 - g_loss: 1.3696\n",
      "Epoch 834/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5196 - g_loss: 1.3249\n",
      "Epoch 835/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.5118 - g_loss: 1.3569\n",
      "Epoch 836/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.4836 - g_loss: 1.3039\n",
      "Epoch 837/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.4937 - g_loss: 1.3040\n",
      "Epoch 838/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.4845 - g_loss: 1.2690\n",
      "Epoch 839/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.5007 - g_loss: 1.3155\n",
      "Epoch 840/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.4895 - g_loss: 1.2751\n",
      "Epoch 841/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.5065 - g_loss: 1.3180\n",
      "Epoch 842/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.5096 - g_loss: 1.3299\n",
      "Epoch 843/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.4749 - g_loss: 1.4115\n",
      "Epoch 844/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.4973 - g_loss: 1.3347\n",
      "Epoch 845/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.4956 - g_loss: 1.3727\n",
      "Epoch 846/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.4929 - g_loss: 1.3165\n",
      "Epoch 847/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.4845 - g_loss: 1.2949\n",
      "Epoch 848/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.4759 - g_loss: 1.3345\n",
      "Epoch 849/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.4929 - g_loss: 1.3152\n",
      "Epoch 850/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.4967 - g_loss: 1.2709\n",
      "Epoch 851/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.4750 - g_loss: 1.3284\n",
      "Epoch 852/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.4873 - g_loss: 1.2914\n",
      "Epoch 853/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.4814 - g_loss: 1.2992\n",
      "Epoch 854/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.4960 - g_loss: 1.3489\n",
      "Epoch 855/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.4827 - g_loss: 1.3167\n",
      "Epoch 856/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.4906 - g_loss: 1.3688\n",
      "Epoch 857/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.4757 - g_loss: 1.4040\n",
      "Epoch 858/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.4859 - g_loss: 1.3366\n",
      "Epoch 859/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.5007 - g_loss: 1.3048\n",
      "Epoch 860/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.4901 - g_loss: 1.3819\n",
      "Epoch 861/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.4685 - g_loss: 1.4060\n",
      "Epoch 862/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.4873 - g_loss: 1.3385\n",
      "Epoch 863/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.4644 - g_loss: 1.4563\n",
      "Epoch 864/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.4727 - g_loss: 1.3719\n",
      "Epoch 865/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.4765 - g_loss: 1.3852\n",
      "Epoch 866/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.4685 - g_loss: 1.3815\n",
      "Epoch 867/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.4744 - g_loss: 1.3268\n",
      "Epoch 868/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.4608 - g_loss: 1.3548\n",
      "Epoch 869/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.4867 - g_loss: 1.4030\n",
      "Epoch 870/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.4794 - g_loss: 1.3777\n",
      "Epoch 871/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.4668 - g_loss: 1.3897\n",
      "Epoch 872/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.4675 - g_loss: 1.3620\n",
      "Epoch 873/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.4726 - g_loss: 1.3235\n",
      "Epoch 874/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.4649 - g_loss: 1.3622\n",
      "Epoch 875/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.4625 - g_loss: 1.3353\n",
      "Epoch 876/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.4665 - g_loss: 1.3619\n",
      "Epoch 877/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.4688 - g_loss: 1.3825\n",
      "Epoch 878/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.4630 - g_loss: 1.3857\n",
      "Epoch 879/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.4758 - g_loss: 1.3790\n",
      "Epoch 880/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.4687 - g_loss: 1.3686\n",
      "Epoch 881/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.4733 - g_loss: 1.3623\n",
      "Epoch 882/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.4560 - g_loss: 1.3937\n",
      "Epoch 883/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.4575 - g_loss: 1.3961\n",
      "Epoch 884/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.4544 - g_loss: 1.3381\n",
      "Epoch 885/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.4490 - g_loss: 1.3791\n",
      "Epoch 886/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.4636 - g_loss: 1.3538\n",
      "Epoch 887/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.4483 - g_loss: 1.3950\n",
      "Epoch 888/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.4624 - g_loss: 1.3841\n",
      "Epoch 889/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.4632 - g_loss: 1.3875\n",
      "Epoch 890/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.4590 - g_loss: 1.3969\n",
      "Epoch 891/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.4613 - g_loss: 1.3930\n",
      "Epoch 892/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.4360 - g_loss: 1.4213\n",
      "Epoch 893/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.4562 - g_loss: 1.4395\n",
      "Epoch 894/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.4552 - g_loss: 1.3927\n",
      "Epoch 895/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.4571 - g_loss: 1.4006\n",
      "Epoch 896/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.4579 - g_loss: 1.4126\n",
      "Epoch 897/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.4488 - g_loss: 1.4605\n",
      "Epoch 898/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.4460 - g_loss: 1.4499\n",
      "Epoch 899/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.4385 - g_loss: 1.4581\n",
      "Epoch 900/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.4520 - g_loss: 1.4244\n",
      "Epoch 901/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.4429 - g_loss: 1.4422\n",
      "Epoch 902/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.4429 - g_loss: 1.3644\n",
      "Epoch 903/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.4382 - g_loss: 1.4360\n",
      "Epoch 904/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.4386 - g_loss: 1.4548\n",
      "Epoch 905/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.4310 - g_loss: 1.4568\n",
      "Epoch 906/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.4513 - g_loss: 1.4246\n",
      "Epoch 907/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.4526 - g_loss: 1.4144\n",
      "Epoch 908/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.4380 - g_loss: 1.4473\n",
      "Epoch 909/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.4296 - g_loss: 1.4263\n",
      "Epoch 910/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.4344 - g_loss: 1.4422\n",
      "Epoch 911/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.4299 - g_loss: 1.4367\n",
      "Epoch 912/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.4278 - g_loss: 1.4577\n",
      "Epoch 913/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.4256 - g_loss: 1.4884\n",
      "Epoch 914/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.4414 - g_loss: 1.5066\n",
      "Epoch 915/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.4402 - g_loss: 1.4901\n",
      "Epoch 916/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.4248 - g_loss: 1.4590\n",
      "Epoch 917/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.4442 - g_loss: 1.4926\n",
      "Epoch 918/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.4132 - g_loss: 1.4991\n",
      "Epoch 919/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.4281 - g_loss: 1.4394\n",
      "Epoch 920/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.4280 - g_loss: 1.4679\n",
      "Epoch 921/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.4149 - g_loss: 1.5004\n",
      "Epoch 922/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.4157 - g_loss: 1.4870\n",
      "Epoch 923/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.4121 - g_loss: 1.4636\n",
      "Epoch 924/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.4329 - g_loss: 1.4851\n",
      "Epoch 925/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.4265 - g_loss: 1.4904\n",
      "Epoch 926/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.4324 - g_loss: 1.4532\n",
      "Epoch 927/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.4272 - g_loss: 1.5121\n",
      "Epoch 928/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.4081 - g_loss: 1.4746\n",
      "Epoch 929/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.4046 - g_loss: 1.5156\n",
      "Epoch 930/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.4157 - g_loss: 1.5087\n",
      "Epoch 931/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.4139 - g_loss: 1.5589\n",
      "Epoch 932/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.4172 - g_loss: 1.5162\n",
      "Epoch 933/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.4070 - g_loss: 1.5562\n",
      "Epoch 934/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.4071 - g_loss: 1.5250\n",
      "Epoch 935/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.4071 - g_loss: 1.5195\n",
      "Epoch 936/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.4037 - g_loss: 1.5561\n",
      "Epoch 937/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.4096 - g_loss: 1.5321\n",
      "Epoch 938/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.4035 - g_loss: 1.5390\n",
      "Epoch 939/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.3982 - g_loss: 1.5351\n",
      "Epoch 940/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.3934 - g_loss: 1.5585\n",
      "Epoch 941/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.3986 - g_loss: 1.5747\n",
      "Epoch 942/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.3940 - g_loss: 1.6221\n",
      "Epoch 943/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.4064 - g_loss: 1.6461\n",
      "Epoch 944/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.3859 - g_loss: 1.6327\n",
      "Epoch 945/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.3937 - g_loss: 1.5936\n",
      "Epoch 946/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.4027 - g_loss: 1.6144\n",
      "Epoch 947/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.3875 - g_loss: 1.5531\n",
      "Epoch 948/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.3836 - g_loss: 1.5895\n",
      "Epoch 949/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.3874 - g_loss: 1.5861\n",
      "Epoch 950/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.3882 - g_loss: 1.6283\n",
      "Epoch 951/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.3852 - g_loss: 1.6292\n",
      "Epoch 952/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.3950 - g_loss: 1.6248\n",
      "Epoch 953/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.3784 - g_loss: 1.6328\n",
      "Epoch 954/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.3892 - g_loss: 1.6096\n",
      "Epoch 955/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.3973 - g_loss: 1.6499\n",
      "Epoch 956/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.3779 - g_loss: 1.6179\n",
      "Epoch 957/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.3819 - g_loss: 1.6609\n",
      "Epoch 958/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.3832 - g_loss: 1.6652\n",
      "Epoch 959/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.3864 - g_loss: 1.6099\n",
      "Epoch 960/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.3847 - g_loss: 1.6325\n",
      "Epoch 961/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.3831 - g_loss: 1.6457\n",
      "Epoch 962/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.3666 - g_loss: 1.6538\n",
      "Epoch 963/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.3746 - g_loss: 1.6669\n",
      "Epoch 964/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.3662 - g_loss: 1.7047\n",
      "Epoch 965/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.3795 - g_loss: 1.7082\n",
      "Epoch 966/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.3593 - g_loss: 1.7152\n",
      "Epoch 967/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.3731 - g_loss: 1.6733\n",
      "Epoch 968/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.3685 - g_loss: 1.6682\n",
      "Epoch 969/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.3636 - g_loss: 1.6831\n",
      "Epoch 970/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.3782 - g_loss: 1.7298\n",
      "Epoch 971/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.3647 - g_loss: 1.7165\n",
      "Epoch 972/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.3637 - g_loss: 1.7039\n",
      "Epoch 973/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.3719 - g_loss: 1.6915\n",
      "Epoch 974/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.3601 - g_loss: 1.7375\n",
      "Epoch 975/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.3546 - g_loss: 1.6885\n",
      "Epoch 976/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.3609 - g_loss: 1.7163\n",
      "Epoch 977/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.3550 - g_loss: 1.7727\n",
      "Epoch 978/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.3569 - g_loss: 1.7059\n",
      "Epoch 979/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.3547 - g_loss: 1.7658\n",
      "Epoch 980/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.3530 - g_loss: 1.7264\n",
      "Epoch 981/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.3580 - g_loss: 1.7429\n",
      "Epoch 982/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.3571 - g_loss: 1.7335\n",
      "Epoch 983/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.3573 - g_loss: 1.7647\n",
      "Epoch 984/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.3496 - g_loss: 1.7530\n",
      "Epoch 985/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.3618 - g_loss: 1.7898\n",
      "Epoch 986/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.3466 - g_loss: 1.7300\n",
      "Epoch 987/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.3366 - g_loss: 1.8006\n",
      "Epoch 988/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.3488 - g_loss: 1.7769\n",
      "Epoch 989/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.3404 - g_loss: 1.7689\n",
      "Epoch 990/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.3549 - g_loss: 1.7887\n",
      "Epoch 991/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.3350 - g_loss: 1.7974\n",
      "Epoch 992/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.3446 - g_loss: 1.7782\n",
      "Epoch 993/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.3584 - g_loss: 1.7858\n",
      "Epoch 994/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.3400 - g_loss: 1.8032\n",
      "Epoch 995/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.3435 - g_loss: 1.7872\n",
      "Epoch 996/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.3314 - g_loss: 1.8181\n",
      "Epoch 997/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.3351 - g_loss: 1.8131\n",
      "Epoch 998/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.3289 - g_loss: 1.8596\n",
      "Epoch 999/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.3265 - g_loss: 1.8358\n",
      "Epoch 1000/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.3428 - g_loss: 1.8321\n",
      "Epoch 1001/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.3313 - g_loss: 1.8370\n",
      "Epoch 1002/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.3322 - g_loss: 1.8361\n",
      "Epoch 1003/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.3275 - g_loss: 1.8555\n",
      "Epoch 1004/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.3230 - g_loss: 1.8609\n",
      "Epoch 1005/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.3241 - g_loss: 1.8703\n",
      "Epoch 1006/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.3247 - g_loss: 1.8631\n",
      "Epoch 1007/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.3229 - g_loss: 1.9229\n",
      "Epoch 1008/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.3400 - g_loss: 1.9014\n",
      "Epoch 1009/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.3201 - g_loss: 1.9015\n",
      "Epoch 1010/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.3306 - g_loss: 1.8791\n",
      "Epoch 1011/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.3148 - g_loss: 1.8593\n",
      "Epoch 1012/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.3284 - g_loss: 1.9220\n",
      "Epoch 1013/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.3288 - g_loss: 1.9789\n",
      "Epoch 1014/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.3220 - g_loss: 1.9376\n",
      "Epoch 1015/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.3090 - g_loss: 1.9070\n",
      "Epoch 1016/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.3206 - g_loss: 1.8829\n",
      "Epoch 1017/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.3125 - g_loss: 1.9362\n",
      "Epoch 1018/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.3073 - g_loss: 1.9479\n",
      "Epoch 1019/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.3225 - g_loss: 1.9797\n",
      "Epoch 1020/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.3143 - g_loss: 1.9789\n",
      "Epoch 1021/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.3109 - g_loss: 1.9559\n",
      "Epoch 1022/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.3024 - g_loss: 1.9769\n",
      "Epoch 1023/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.3045 - g_loss: 1.9663\n",
      "Epoch 1024/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.3031 - g_loss: 1.9315\n",
      "Epoch 1025/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.3111 - g_loss: 1.9712\n",
      "Epoch 1026/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.3154 - g_loss: 1.9966\n",
      "Epoch 1027/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.3151 - g_loss: 1.9693\n",
      "Epoch 1028/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.3074 - g_loss: 1.9862\n",
      "Epoch 1029/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.2948 - g_loss: 1.9463\n",
      "Epoch 1030/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.3058 - g_loss: 2.0028\n",
      "Epoch 1031/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.3079 - g_loss: 2.0240\n",
      "Epoch 1032/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.2912 - g_loss: 2.0032\n",
      "Epoch 1033/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.2916 - g_loss: 1.9912\n",
      "Epoch 1034/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.3033 - g_loss: 2.0514\n",
      "Epoch 1035/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.2930 - g_loss: 2.0371\n",
      "Epoch 1036/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.2819 - g_loss: 2.1115\n",
      "Epoch 1037/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.2933 - g_loss: 2.1020\n",
      "Epoch 1038/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.2954 - g_loss: 2.0912\n",
      "Epoch 1039/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.2942 - g_loss: 2.0852\n",
      "Epoch 1040/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.3063 - g_loss: 2.0674\n",
      "Epoch 1041/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.2917 - g_loss: 2.1062\n",
      "Epoch 1042/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.3016 - g_loss: 2.0784\n",
      "Epoch 1043/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.2863 - g_loss: 2.1310\n",
      "Epoch 1044/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.2883 - g_loss: 2.1089\n",
      "Epoch 1045/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.2786 - g_loss: 2.1442\n",
      "Epoch 1046/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.2813 - g_loss: 2.1259\n",
      "Epoch 1047/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.2867 - g_loss: 2.1513\n",
      "Epoch 1048/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.2793 - g_loss: 2.1067\n",
      "Epoch 1049/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.2777 - g_loss: 2.1561\n",
      "Epoch 1050/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.2779 - g_loss: 2.1275\n",
      "Epoch 1051/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.2785 - g_loss: 2.1821\n",
      "Epoch 1052/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.2816 - g_loss: 2.1961\n",
      "Epoch 1053/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.2865 - g_loss: 2.0962\n",
      "Epoch 1054/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.2798 - g_loss: 2.1382\n",
      "Epoch 1055/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.2627 - g_loss: 2.1700\n",
      "Epoch 1056/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.2839 - g_loss: 2.1707\n",
      "Epoch 1057/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.2677 - g_loss: 2.2528\n",
      "Epoch 1058/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.2741 - g_loss: 2.2520\n",
      "Epoch 1059/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.2743 - g_loss: 2.2122\n",
      "Epoch 1060/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.2751 - g_loss: 2.2208\n",
      "Epoch 1061/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.2617 - g_loss: 2.2657\n",
      "Epoch 1062/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.2758 - g_loss: 2.2180\n",
      "Epoch 1063/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.2679 - g_loss: 2.2196\n",
      "Epoch 1064/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.2649 - g_loss: 2.2404\n",
      "Epoch 1065/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.2615 - g_loss: 2.2071\n",
      "Epoch 1066/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.2619 - g_loss: 2.2702\n",
      "Epoch 1067/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.2538 - g_loss: 2.2911\n",
      "Epoch 1068/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.2716 - g_loss: 2.2586\n",
      "Epoch 1069/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.2700 - g_loss: 2.2514\n",
      "Epoch 1070/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.2575 - g_loss: 2.2210\n",
      "Epoch 1071/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.2657 - g_loss: 2.3292\n",
      "Epoch 1072/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.2567 - g_loss: 2.2932\n",
      "Epoch 1073/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.2497 - g_loss: 2.2684\n",
      "Epoch 1074/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.2531 - g_loss: 2.3323\n",
      "Epoch 1075/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.2545 - g_loss: 2.3302\n",
      "Epoch 1076/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.2608 - g_loss: 2.3554\n",
      "Epoch 1077/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.2536 - g_loss: 2.3322\n",
      "Epoch 1078/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.2478 - g_loss: 2.2903\n",
      "Epoch 1079/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.2542 - g_loss: 2.3295\n",
      "Epoch 1080/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.2505 - g_loss: 2.3583\n",
      "Epoch 1081/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.2393 - g_loss: 2.4468\n",
      "Epoch 1082/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.2511 - g_loss: 2.4536\n",
      "Epoch 1083/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.2477 - g_loss: 2.3650\n",
      "Epoch 1084/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.2494 - g_loss: 2.4033\n",
      "Epoch 1085/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.2609 - g_loss: 2.4192\n",
      "Epoch 1086/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.2529 - g_loss: 2.4231\n",
      "Epoch 1087/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.2404 - g_loss: 2.4251\n",
      "Epoch 1088/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.2475 - g_loss: 2.4360\n",
      "Epoch 1089/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.2483 - g_loss: 2.4055\n",
      "Epoch 1090/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.2460 - g_loss: 2.4654\n",
      "Epoch 1091/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.2426 - g_loss: 2.4350\n",
      "Epoch 1092/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.2412 - g_loss: 2.4453\n",
      "Epoch 1093/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.2307 - g_loss: 2.4727\n",
      "Epoch 1094/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.2290 - g_loss: 2.4090\n",
      "Epoch 1095/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.2461 - g_loss: 2.5013\n",
      "Epoch 1096/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.2402 - g_loss: 2.4710\n",
      "Epoch 1097/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.2408 - g_loss: 2.4567\n",
      "Epoch 1098/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.2346 - g_loss: 2.4814\n",
      "Epoch 1099/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.2303 - g_loss: 2.4825\n",
      "Epoch 1100/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.2317 - g_loss: 2.4875\n",
      "Epoch 1101/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.2286 - g_loss: 2.4686\n",
      "Epoch 1102/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.2364 - g_loss: 2.4901\n",
      "Epoch 1103/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.2395 - g_loss: 2.5116\n",
      "Epoch 1104/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.2333 - g_loss: 2.5506\n",
      "Epoch 1105/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.2361 - g_loss: 2.5547\n",
      "Epoch 1106/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.2323 - g_loss: 2.5761\n",
      "Epoch 1107/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.2263 - g_loss: 2.5387\n",
      "Epoch 1108/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.2329 - g_loss: 2.5474\n",
      "Epoch 1109/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.2378 - g_loss: 2.5411\n",
      "Epoch 1110/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.2235 - g_loss: 2.5035\n",
      "Epoch 1111/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.2251 - g_loss: 2.5889\n",
      "Epoch 1112/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.2229 - g_loss: 2.5886\n",
      "Epoch 1113/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.2254 - g_loss: 2.6051\n",
      "Epoch 1114/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.2209 - g_loss: 2.5794\n",
      "Epoch 1115/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.2186 - g_loss: 2.5869\n",
      "Epoch 1116/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.2321 - g_loss: 2.6169\n",
      "Epoch 1117/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.2329 - g_loss: 2.6153\n",
      "Epoch 1118/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.2283 - g_loss: 2.6331\n",
      "Epoch 1119/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.2183 - g_loss: 2.6271\n",
      "Epoch 1120/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.2272 - g_loss: 2.6264\n",
      "Epoch 1121/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.2152 - g_loss: 2.5823\n",
      "Epoch 1122/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.2093 - g_loss: 2.6375\n",
      "Epoch 1123/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.2061 - g_loss: 2.6166\n",
      "Epoch 1124/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.2119 - g_loss: 2.6589\n",
      "Epoch 1125/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.2166 - g_loss: 2.6657\n",
      "Epoch 1126/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.2179 - g_loss: 2.6592\n",
      "Epoch 1127/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.2144 - g_loss: 2.6634\n",
      "Epoch 1128/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.2192 - g_loss: 2.6920\n",
      "Epoch 1129/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.2157 - g_loss: 2.7120\n",
      "Epoch 1130/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.2190 - g_loss: 2.6934\n",
      "Epoch 1131/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.2136 - g_loss: 2.7077\n",
      "Epoch 1132/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.2315 - g_loss: 2.7036\n",
      "Epoch 1133/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.2204 - g_loss: 2.6776\n",
      "Epoch 1134/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.2192 - g_loss: 2.7379\n",
      "Epoch 1135/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.2126 - g_loss: 2.7224\n",
      "Epoch 1136/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.2169 - g_loss: 2.7537\n",
      "Epoch 1137/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.2038 - g_loss: 2.7625\n",
      "Epoch 1138/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.2070 - g_loss: 2.7465\n",
      "Epoch 1139/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1982 - g_loss: 2.7909\n",
      "Epoch 1140/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.2108 - g_loss: 2.7783\n",
      "Epoch 1141/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.2188 - g_loss: 2.7829\n",
      "Epoch 1142/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.2204 - g_loss: 2.7465\n",
      "Epoch 1143/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.2079 - g_loss: 2.7695\n",
      "Epoch 1144/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.2056 - g_loss: 2.8198\n",
      "Epoch 1145/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.2032 - g_loss: 2.7585\n",
      "Epoch 1146/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.2075 - g_loss: 2.8202\n",
      "Epoch 1147/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.1910 - g_loss: 2.7892\n",
      "Epoch 1148/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1966 - g_loss: 2.8130\n",
      "Epoch 1149/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1970 - g_loss: 2.7846\n",
      "Epoch 1150/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.2155 - g_loss: 2.8512\n",
      "Epoch 1151/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.2123 - g_loss: 2.8471\n",
      "Epoch 1152/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.2060 - g_loss: 2.8543\n",
      "Epoch 1153/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1954 - g_loss: 2.8334\n",
      "Epoch 1154/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1990 - g_loss: 2.9065\n",
      "Epoch 1155/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.2091 - g_loss: 2.8698\n",
      "Epoch 1156/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.1973 - g_loss: 2.9211\n",
      "Epoch 1157/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1914 - g_loss: 2.8575\n",
      "Epoch 1158/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.1952 - g_loss: 2.8648\n",
      "Epoch 1159/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.1986 - g_loss: 2.8398\n",
      "Epoch 1160/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1928 - g_loss: 2.8162\n",
      "Epoch 1161/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.1871 - g_loss: 2.9336\n",
      "Epoch 1162/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.2027 - g_loss: 2.9400\n",
      "Epoch 1163/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1845 - g_loss: 2.9669\n",
      "Epoch 1164/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.2014 - g_loss: 2.9220\n",
      "Epoch 1165/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.2030 - g_loss: 2.9636\n",
      "Epoch 1166/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1906 - g_loss: 2.9647\n",
      "Epoch 1167/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.1932 - g_loss: 2.9947\n",
      "Epoch 1168/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1850 - g_loss: 2.9629\n",
      "Epoch 1169/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1892 - g_loss: 3.0086\n",
      "Epoch 1170/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1798 - g_loss: 2.9849\n",
      "Epoch 1171/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1926 - g_loss: 2.9981\n",
      "Epoch 1172/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.1843 - g_loss: 2.9555\n",
      "Epoch 1173/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1949 - g_loss: 3.0379\n",
      "Epoch 1174/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.2059 - g_loss: 3.0307\n",
      "Epoch 1175/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1747 - g_loss: 2.9927\n",
      "Epoch 1176/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.1901 - g_loss: 3.0189\n",
      "Epoch 1177/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1929 - g_loss: 3.0321\n",
      "Epoch 1178/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.1934 - g_loss: 3.0646\n",
      "Epoch 1179/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.2032 - g_loss: 3.0415\n",
      "Epoch 1180/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1790 - g_loss: 3.1025\n",
      "Epoch 1181/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1912 - g_loss: 3.1445\n",
      "Epoch 1182/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1713 - g_loss: 3.0677\n",
      "Epoch 1183/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.1807 - g_loss: 3.1063\n",
      "Epoch 1184/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1767 - g_loss: 3.1169\n",
      "Epoch 1185/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.1736 - g_loss: 3.1094\n",
      "Epoch 1186/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.2013 - g_loss: 3.0408\n",
      "Epoch 1187/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1846 - g_loss: 3.1493\n",
      "Epoch 1188/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1694 - g_loss: 3.1137\n",
      "Epoch 1189/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1734 - g_loss: 3.1532\n",
      "Epoch 1190/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1781 - g_loss: 3.1560\n",
      "Epoch 1191/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.1754 - g_loss: 3.1231\n",
      "Epoch 1192/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1666 - g_loss: 3.2446\n",
      "Epoch 1193/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.1712 - g_loss: 3.2224\n",
      "Epoch 1194/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1656 - g_loss: 3.1739\n",
      "Epoch 1195/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.1626 - g_loss: 3.2055\n",
      "Epoch 1196/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.1723 - g_loss: 3.2371\n",
      "Epoch 1197/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1982 - g_loss: 3.1867\n",
      "Epoch 1198/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1777 - g_loss: 3.2433\n",
      "Epoch 1199/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1658 - g_loss: 3.2480\n",
      "Epoch 1200/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1696 - g_loss: 3.2194\n",
      "Epoch 1201/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.1791 - g_loss: 3.2878\n",
      "Epoch 1202/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1810 - g_loss: 3.2145\n",
      "Epoch 1203/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1755 - g_loss: 3.2519\n",
      "Epoch 1204/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1821 - g_loss: 3.2343\n",
      "Epoch 1205/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1738 - g_loss: 3.2633\n",
      "Epoch 1206/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1611 - g_loss: 3.2819\n",
      "Epoch 1207/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.1765 - g_loss: 3.3021\n",
      "Epoch 1208/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1737 - g_loss: 3.2607\n",
      "Epoch 1209/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1525 - g_loss: 3.3235\n",
      "Epoch 1210/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1664 - g_loss: 3.2799\n",
      "Epoch 1211/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1658 - g_loss: 3.3942\n",
      "Epoch 1212/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1629 - g_loss: 3.3555\n",
      "Epoch 1213/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1919 - g_loss: 3.3373\n",
      "Epoch 1214/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1639 - g_loss: 3.3339\n",
      "Epoch 1215/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1764 - g_loss: 3.3149\n",
      "Epoch 1216/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.1584 - g_loss: 3.3701\n",
      "Epoch 1217/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.1531 - g_loss: 3.3981\n",
      "Epoch 1218/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1603 - g_loss: 3.3949\n",
      "Epoch 1219/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1553 - g_loss: 3.4394\n",
      "Epoch 1220/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.1588 - g_loss: 3.4032\n",
      "Epoch 1221/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1533 - g_loss: 3.4371\n",
      "Epoch 1222/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.1593 - g_loss: 3.4702\n",
      "Epoch 1223/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1615 - g_loss: 3.4156\n",
      "Epoch 1224/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1721 - g_loss: 3.4310\n",
      "Epoch 1225/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.1680 - g_loss: 3.4458\n",
      "Epoch 1226/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1546 - g_loss: 3.4749\n",
      "Epoch 1227/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.1415 - g_loss: 3.5320\n",
      "Epoch 1228/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1464 - g_loss: 3.5092\n",
      "Epoch 1229/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1571 - g_loss: 3.5653\n",
      "Epoch 1230/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1529 - g_loss: 3.4862\n",
      "Epoch 1231/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.1574 - g_loss: 3.4982\n",
      "Epoch 1232/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1547 - g_loss: 3.5783\n",
      "Epoch 1233/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1476 - g_loss: 3.5580\n",
      "Epoch 1234/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.1520 - g_loss: 3.5424\n",
      "Epoch 1235/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1446 - g_loss: 3.5361\n",
      "Epoch 1236/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1510 - g_loss: 3.5321\n",
      "Epoch 1237/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1416 - g_loss: 3.5897\n",
      "Epoch 1238/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1743 - g_loss: 3.5667\n",
      "Epoch 1239/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1486 - g_loss: 3.6158\n",
      "Epoch 1240/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: 0.1471 - g_loss: 3.5969\n",
      "Epoch 1241/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.1584 - g_loss: 3.5532\n",
      "Epoch 1242/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1426 - g_loss: 3.6250\n",
      "Epoch 1243/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1471 - g_loss: 3.5434\n",
      "Epoch 1244/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1353 - g_loss: 3.7259\n",
      "Epoch 1245/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1484 - g_loss: 3.5935\n",
      "Epoch 1246/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1401 - g_loss: 3.6562\n",
      "Epoch 1247/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1331 - g_loss: 3.6733\n",
      "Epoch 1248/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1309 - g_loss: 3.6315\n",
      "Epoch 1249/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.1373 - g_loss: 3.7022\n",
      "Epoch 1250/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.1501 - g_loss: 3.7647\n",
      "Epoch 1251/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1453 - g_loss: 3.6735\n",
      "Epoch 1252/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1408 - g_loss: 3.6951\n",
      "Epoch 1253/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1451 - g_loss: 3.7409\n",
      "Epoch 1254/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.1355 - g_loss: 3.7387\n",
      "Epoch 1255/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1290 - g_loss: 3.6348\n",
      "Epoch 1256/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1317 - g_loss: 3.7972\n",
      "Epoch 1257/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1520 - g_loss: 3.8270\n",
      "Epoch 1258/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1318 - g_loss: 3.7207\n",
      "Epoch 1259/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.1183 - g_loss: 3.8114\n",
      "Epoch 1260/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.1428 - g_loss: 3.7609\n",
      "Epoch 1261/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.1286 - g_loss: 3.8729\n",
      "Epoch 1262/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1296 - g_loss: 3.8255\n",
      "Epoch 1263/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1203 - g_loss: 3.8369\n",
      "Epoch 1264/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1554 - g_loss: 3.7565\n",
      "Epoch 1265/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1203 - g_loss: 3.8572\n",
      "Epoch 1266/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1480 - g_loss: 3.8968\n",
      "Epoch 1267/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1276 - g_loss: 3.7976\n",
      "Epoch 1268/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.1357 - g_loss: 3.8860\n",
      "Epoch 1269/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1291 - g_loss: 3.8480\n",
      "Epoch 1270/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1233 - g_loss: 3.8721\n",
      "Epoch 1271/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1271 - g_loss: 3.8554\n",
      "Epoch 1272/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1305 - g_loss: 3.9557\n",
      "Epoch 1273/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1281 - g_loss: 3.8606\n",
      "Epoch 1274/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1318 - g_loss: 3.9639\n",
      "Epoch 1275/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.1240 - g_loss: 3.8852\n",
      "Epoch 1276/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1265 - g_loss: 3.8980\n",
      "Epoch 1277/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1328 - g_loss: 3.9732\n",
      "Epoch 1278/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1332 - g_loss: 3.9989\n",
      "Epoch 1279/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1353 - g_loss: 3.9314\n",
      "Epoch 1280/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.1274 - g_loss: 3.9735\n",
      "Epoch 1281/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1465 - g_loss: 3.9295\n",
      "Epoch 1282/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.1259 - g_loss: 3.9038\n",
      "Epoch 1283/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1229 - g_loss: 4.0366\n",
      "Epoch 1284/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1222 - g_loss: 4.0483\n",
      "Epoch 1285/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1372 - g_loss: 3.9761\n",
      "Epoch 1286/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1231 - g_loss: 3.9867\n",
      "Epoch 1287/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1184 - g_loss: 4.0933\n",
      "Epoch 1288/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1333 - g_loss: 4.1010\n",
      "Epoch 1289/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.1515 - g_loss: 4.0640\n",
      "Epoch 1290/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1291 - g_loss: 3.9970\n",
      "Epoch 1291/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.1238 - g_loss: 4.0767\n",
      "Epoch 1292/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1310 - g_loss: 4.0446\n",
      "Epoch 1293/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1284 - g_loss: 4.0614\n",
      "Epoch 1294/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1193 - g_loss: 4.0320\n",
      "Epoch 1295/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1087 - g_loss: 4.1263\n",
      "Epoch 1296/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.1305 - g_loss: 4.0794\n",
      "Epoch 1297/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1135 - g_loss: 4.1382\n",
      "Epoch 1298/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.1362 - g_loss: 4.0590\n",
      "Epoch 1299/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.1179 - g_loss: 4.1449\n",
      "Epoch 1300/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.1234 - g_loss: 4.1562\n",
      "Epoch 1301/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.1080 - g_loss: 4.0620\n",
      "Epoch 1302/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1283 - g_loss: 4.2008\n",
      "Epoch 1303/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1191 - g_loss: 4.2383\n",
      "Epoch 1304/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1185 - g_loss: 4.1438\n",
      "Epoch 1305/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1120 - g_loss: 4.1873\n",
      "Epoch 1306/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1305 - g_loss: 4.1706\n",
      "Epoch 1307/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1331 - g_loss: 4.0975\n",
      "Epoch 1308/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1197 - g_loss: 4.2069\n",
      "Epoch 1309/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1315 - g_loss: 4.2478\n",
      "Epoch 1310/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.1048 - g_loss: 4.2238\n",
      "Epoch 1311/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1212 - g_loss: 4.2314\n",
      "Epoch 1312/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1289 - g_loss: 4.1986\n",
      "Epoch 1313/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1235 - g_loss: 4.1922\n",
      "Epoch 1314/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1042 - g_loss: 4.2061\n",
      "Epoch 1315/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1098 - g_loss: 4.3224\n",
      "Epoch 1316/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1054 - g_loss: 4.1759\n",
      "Epoch 1317/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.1058 - g_loss: 4.2835\n",
      "Epoch 1318/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.1170 - g_loss: 4.2874\n",
      "Epoch 1319/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.1311 - g_loss: 4.3373\n",
      "Epoch 1320/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.1099 - g_loss: 4.2313\n",
      "Epoch 1321/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1067 - g_loss: 4.3393\n",
      "Epoch 1322/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1009 - g_loss: 4.3583\n",
      "Epoch 1323/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.1169 - g_loss: 4.3293\n",
      "Epoch 1324/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1053 - g_loss: 4.3988\n",
      "Epoch 1325/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.1034 - g_loss: 4.3964\n",
      "Epoch 1326/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.1137 - g_loss: 4.4420\n",
      "Epoch 1327/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1035 - g_loss: 4.3571\n",
      "Epoch 1328/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1079 - g_loss: 4.3780\n",
      "Epoch 1329/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0966 - g_loss: 4.4502\n",
      "Epoch 1330/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.0989 - g_loss: 4.4329\n",
      "Epoch 1331/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0991 - g_loss: 4.4592\n",
      "Epoch 1332/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1037 - g_loss: 4.4757\n",
      "Epoch 1333/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.1088 - g_loss: 4.3944\n",
      "Epoch 1334/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1001 - g_loss: 4.4158\n",
      "Epoch 1335/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1508 - g_loss: 4.4052\n",
      "Epoch 1336/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1084 - g_loss: 4.4938\n",
      "Epoch 1337/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.1028 - g_loss: 4.5220\n",
      "Epoch 1338/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1058 - g_loss: 4.4878\n",
      "Epoch 1339/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0971 - g_loss: 4.4296\n",
      "Epoch 1340/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1137 - g_loss: 4.5605\n",
      "Epoch 1341/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.1055 - g_loss: 4.5871\n",
      "Epoch 1342/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.1056 - g_loss: 4.5594\n",
      "Epoch 1343/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1086 - g_loss: 4.5522\n",
      "Epoch 1344/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1142 - g_loss: 4.4736\n",
      "Epoch 1345/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0968 - g_loss: 4.5336\n",
      "Epoch 1346/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0925 - g_loss: 4.6639\n",
      "Epoch 1347/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1349 - g_loss: 4.4832\n",
      "Epoch 1348/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1220 - g_loss: 4.5805\n",
      "Epoch 1349/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1146 - g_loss: 4.5919\n",
      "Epoch 1350/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1186 - g_loss: 4.6687\n",
      "Epoch 1351/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0993 - g_loss: 4.5926\n",
      "Epoch 1352/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1285 - g_loss: 4.5884\n",
      "Epoch 1353/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.1106 - g_loss: 4.5334\n",
      "Epoch 1354/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.0980 - g_loss: 4.7121\n",
      "Epoch 1355/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1115 - g_loss: 4.6489\n",
      "Epoch 1356/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0911 - g_loss: 4.5850\n",
      "Epoch 1357/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0943 - g_loss: 4.7173\n",
      "Epoch 1358/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0971 - g_loss: 4.6828\n",
      "Epoch 1359/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0957 - g_loss: 4.7395\n",
      "Epoch 1360/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0832 - g_loss: 4.6574\n",
      "Epoch 1361/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1027 - g_loss: 4.6193\n",
      "Epoch 1362/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0945 - g_loss: 4.8345\n",
      "Epoch 1363/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0986 - g_loss: 4.7545\n",
      "Epoch 1364/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1038 - g_loss: 4.6878\n",
      "Epoch 1365/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0943 - g_loss: 4.8146\n",
      "Epoch 1366/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0907 - g_loss: 4.8458\n",
      "Epoch 1367/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0859 - g_loss: 4.7863\n",
      "Epoch 1368/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1134 - g_loss: 4.7545\n",
      "Epoch 1369/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0925 - g_loss: 4.8240\n",
      "Epoch 1370/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0844 - g_loss: 4.8399\n",
      "Epoch 1371/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.1035 - g_loss: 4.8664\n",
      "Epoch 1372/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0831 - g_loss: 4.8205\n",
      "Epoch 1373/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.1044 - g_loss: 4.8183\n",
      "Epoch 1374/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0933 - g_loss: 4.8688\n",
      "Epoch 1375/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: 0.1078 - g_loss: 4.7353\n",
      "Epoch 1376/3000\n",
      "104/104 [==============================] - 13s 123ms/step - d_loss: 0.0989 - g_loss: 4.9145\n",
      "Epoch 1377/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.1016 - g_loss: 4.9231\n",
      "Epoch 1378/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0963 - g_loss: 4.8475\n",
      "Epoch 1379/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1023 - g_loss: 4.8928\n",
      "Epoch 1380/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.1370 - g_loss: 4.8101\n",
      "Epoch 1381/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.1173 - g_loss: 4.8707\n",
      "Epoch 1382/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0882 - g_loss: 4.9270\n",
      "Epoch 1383/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0960 - g_loss: 4.9040\n",
      "Epoch 1384/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.1111 - g_loss: 4.9573\n",
      "Epoch 1385/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0890 - g_loss: 4.9620\n",
      "Epoch 1386/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0982 - g_loss: 4.9183\n",
      "Epoch 1387/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0848 - g_loss: 4.9744\n",
      "Epoch 1388/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0749 - g_loss: 5.0037\n",
      "Epoch 1389/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0691 - g_loss: 5.1063\n",
      "Epoch 1390/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0994 - g_loss: 4.8446\n",
      "Epoch 1391/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0966 - g_loss: 4.9572\n",
      "Epoch 1392/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0984 - g_loss: 4.9740\n",
      "Epoch 1393/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0936 - g_loss: 4.9506\n",
      "Epoch 1394/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0840 - g_loss: 5.0833\n",
      "Epoch 1395/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0906 - g_loss: 5.0253\n",
      "Epoch 1396/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0695 - g_loss: 5.1668\n",
      "Epoch 1397/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.0782 - g_loss: 5.0326\n",
      "Epoch 1398/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.1070 - g_loss: 5.1034\n",
      "Epoch 1399/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1026 - g_loss: 5.1017\n",
      "Epoch 1400/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0798 - g_loss: 5.1349\n",
      "Epoch 1401/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.0792 - g_loss: 5.0610\n",
      "Epoch 1402/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0990 - g_loss: 5.1619\n",
      "Epoch 1403/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0890 - g_loss: 5.0692\n",
      "Epoch 1404/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0886 - g_loss: 5.1098\n",
      "Epoch 1405/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0971 - g_loss: 5.0557\n",
      "Epoch 1406/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0800 - g_loss: 5.2032\n",
      "Epoch 1407/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0769 - g_loss: 5.1646\n",
      "Epoch 1408/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0874 - g_loss: 5.1754\n",
      "Epoch 1409/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0762 - g_loss: 5.2605\n",
      "Epoch 1410/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.0966 - g_loss: 5.1147\n",
      "Epoch 1411/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0920 - g_loss: 5.1592\n",
      "Epoch 1412/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0920 - g_loss: 5.3149\n",
      "Epoch 1413/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0936 - g_loss: 5.2377\n",
      "Epoch 1414/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0915 - g_loss: 5.0891\n",
      "Epoch 1415/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0986 - g_loss: 5.1507\n",
      "Epoch 1416/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0761 - g_loss: 5.3371\n",
      "Epoch 1417/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0745 - g_loss: 5.2463\n",
      "Epoch 1418/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0812 - g_loss: 5.3540\n",
      "Epoch 1419/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0690 - g_loss: 5.2757\n",
      "Epoch 1420/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0891 - g_loss: 5.3593\n",
      "Epoch 1421/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0890 - g_loss: 5.3493\n",
      "Epoch 1422/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0759 - g_loss: 5.3641\n",
      "Epoch 1423/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0893 - g_loss: 5.2485\n",
      "Epoch 1424/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0851 - g_loss: 5.3327\n",
      "Epoch 1425/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0795 - g_loss: 5.2777\n",
      "Epoch 1426/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0817 - g_loss: 5.3641\n",
      "Epoch 1427/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0869 - g_loss: 5.2502\n",
      "Epoch 1428/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0632 - g_loss: 5.3568\n",
      "Epoch 1429/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0856 - g_loss: 5.3180\n",
      "Epoch 1430/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0823 - g_loss: 5.3569\n",
      "Epoch 1431/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0962 - g_loss: 5.3336\n",
      "Epoch 1432/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0697 - g_loss: 5.4040\n",
      "Epoch 1433/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0713 - g_loss: 5.3731\n",
      "Epoch 1434/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0681 - g_loss: 5.4764\n",
      "Epoch 1435/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0728 - g_loss: 5.3779\n",
      "Epoch 1436/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0969 - g_loss: 5.3346\n",
      "Epoch 1437/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0724 - g_loss: 5.5241\n",
      "Epoch 1438/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0707 - g_loss: 5.5114\n",
      "Epoch 1439/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0734 - g_loss: 5.4487\n",
      "Epoch 1440/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0788 - g_loss: 5.5231\n",
      "Epoch 1441/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1056 - g_loss: 5.5219\n",
      "Epoch 1442/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.1180 - g_loss: 5.4455\n",
      "Epoch 1443/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0869 - g_loss: 5.3982\n",
      "Epoch 1444/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0858 - g_loss: 5.5198\n",
      "Epoch 1445/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0668 - g_loss: 5.4502\n",
      "Epoch 1446/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0941 - g_loss: 5.3543\n",
      "Epoch 1447/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0889 - g_loss: 5.5147\n",
      "Epoch 1448/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0922 - g_loss: 5.5135\n",
      "Epoch 1449/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0826 - g_loss: 5.3974\n",
      "Epoch 1450/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0774 - g_loss: 5.6641\n",
      "Epoch 1451/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0898 - g_loss: 5.4731\n",
      "Epoch 1452/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0639 - g_loss: 5.5545\n",
      "Epoch 1453/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0670 - g_loss: 5.5381\n",
      "Epoch 1454/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0747 - g_loss: 5.5832\n",
      "Epoch 1455/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0669 - g_loss: 5.6742\n",
      "Epoch 1456/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0611 - g_loss: 5.7613\n",
      "Epoch 1457/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0595 - g_loss: 5.7347\n",
      "Epoch 1458/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0973 - g_loss: 5.5832\n",
      "Epoch 1459/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0681 - g_loss: 5.6412\n",
      "Epoch 1460/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0779 - g_loss: 5.6792\n",
      "Epoch 1461/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.0827 - g_loss: 5.6498\n",
      "Epoch 1462/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0840 - g_loss: 5.5564\n",
      "Epoch 1463/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0784 - g_loss: 5.6274\n",
      "Epoch 1464/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.0734 - g_loss: 5.7638\n",
      "Epoch 1465/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0547 - g_loss: 5.7461\n",
      "Epoch 1466/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0686 - g_loss: 5.8376\n",
      "Epoch 1467/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0707 - g_loss: 5.6596\n",
      "Epoch 1468/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0636 - g_loss: 5.7486\n",
      "Epoch 1469/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0738 - g_loss: 5.7300\n",
      "Epoch 1470/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0709 - g_loss: 5.8182\n",
      "Epoch 1471/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0706 - g_loss: 5.8455\n",
      "Epoch 1472/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0662 - g_loss: 5.8622\n",
      "Epoch 1473/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0881 - g_loss: 5.8073\n",
      "Epoch 1474/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0872 - g_loss: 5.6816\n",
      "Epoch 1475/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0632 - g_loss: 5.8328\n",
      "Epoch 1476/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0658 - g_loss: 5.7482\n",
      "Epoch 1477/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0667 - g_loss: 5.8784\n",
      "Epoch 1478/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0695 - g_loss: 5.8226\n",
      "Epoch 1479/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.0617 - g_loss: 5.8817\n",
      "Epoch 1480/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0494 - g_loss: 6.0245\n",
      "Epoch 1481/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0655 - g_loss: 5.8599\n",
      "Epoch 1482/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0813 - g_loss: 5.9039\n",
      "Epoch 1483/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0559 - g_loss: 5.9394\n",
      "Epoch 1484/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0595 - g_loss: 5.9749\n",
      "Epoch 1485/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0714 - g_loss: 5.9678\n",
      "Epoch 1486/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.0917 - g_loss: 5.7852\n",
      "Epoch 1487/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0851 - g_loss: 5.7925\n",
      "Epoch 1488/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0856 - g_loss: 5.9349\n",
      "Epoch 1489/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0665 - g_loss: 5.9666\n",
      "Epoch 1490/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.0806 - g_loss: 6.0202\n",
      "Epoch 1491/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0784 - g_loss: 5.8798\n",
      "Epoch 1492/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0714 - g_loss: 5.8566\n",
      "Epoch 1493/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0664 - g_loss: 5.9233\n",
      "Epoch 1494/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0805 - g_loss: 5.9395\n",
      "Epoch 1495/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0746 - g_loss: 5.8963\n",
      "Epoch 1496/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0651 - g_loss: 5.9702\n",
      "Epoch 1497/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0631 - g_loss: 6.0140\n",
      "Epoch 1498/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0717 - g_loss: 6.1097\n",
      "Epoch 1499/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.0548 - g_loss: 6.1397\n",
      "Epoch 1500/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.0689 - g_loss: 5.9938\n",
      "Epoch 1501/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.0542 - g_loss: 6.0739\n",
      "Epoch 1502/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0664 - g_loss: 6.0851\n",
      "Epoch 1503/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0742 - g_loss: 6.1026\n",
      "Epoch 1504/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0794 - g_loss: 5.9837\n",
      "Epoch 1505/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0563 - g_loss: 6.3456\n",
      "Epoch 1506/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0499 - g_loss: 6.1599\n",
      "Epoch 1507/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.0705 - g_loss: 6.0625\n",
      "Epoch 1508/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0796 - g_loss: 6.0178\n",
      "Epoch 1509/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0649 - g_loss: 6.1511\n",
      "Epoch 1510/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0643 - g_loss: 6.1126\n",
      "Epoch 1511/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0514 - g_loss: 6.3177\n",
      "Epoch 1512/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0928 - g_loss: 6.1116\n",
      "Epoch 1513/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0734 - g_loss: 6.0663\n",
      "Epoch 1514/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0631 - g_loss: 6.0577\n",
      "Epoch 1515/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0425 - g_loss: 6.3170\n",
      "Epoch 1516/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0471 - g_loss: 6.3293\n",
      "Epoch 1517/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0524 - g_loss: 6.4482\n",
      "Epoch 1518/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0519 - g_loss: 6.1942\n",
      "Epoch 1519/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0664 - g_loss: 6.1680\n",
      "Epoch 1520/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0599 - g_loss: 6.2244\n",
      "Epoch 1521/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0628 - g_loss: 6.1430\n",
      "Epoch 1522/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0484 - g_loss: 6.3317\n",
      "Epoch 1523/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0623 - g_loss: 6.3550\n",
      "Epoch 1524/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0945 - g_loss: 6.1544\n",
      "Epoch 1525/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0587 - g_loss: 6.2902\n",
      "Epoch 1526/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0662 - g_loss: 6.2749\n",
      "Epoch 1527/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0502 - g_loss: 6.5026\n",
      "Epoch 1528/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0431 - g_loss: 6.4103\n",
      "Epoch 1529/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0729 - g_loss: 6.3872\n",
      "Epoch 1530/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0637 - g_loss: 6.3640\n",
      "Epoch 1531/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0467 - g_loss: 6.4284\n",
      "Epoch 1532/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0578 - g_loss: 6.4432\n",
      "Epoch 1533/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0419 - g_loss: 6.4136\n",
      "Epoch 1534/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0537 - g_loss: 6.5742\n",
      "Epoch 1535/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0908 - g_loss: 6.2850\n",
      "Epoch 1536/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.0534 - g_loss: 6.4519\n",
      "Epoch 1537/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0487 - g_loss: 6.4551\n",
      "Epoch 1538/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0741 - g_loss: 6.2918\n",
      "Epoch 1539/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0419 - g_loss: 6.4706\n",
      "Epoch 1540/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0421 - g_loss: 6.7193\n",
      "Epoch 1541/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0352 - g_loss: 6.4266\n",
      "Epoch 1542/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.0814 - g_loss: 6.4907\n",
      "Epoch 1543/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0540 - g_loss: 6.4634\n",
      "Epoch 1544/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0564 - g_loss: 6.4570\n",
      "Epoch 1545/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.1366 - g_loss: 6.0895\n",
      "Epoch 1546/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0652 - g_loss: 6.4928\n",
      "Epoch 1547/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0511 - g_loss: 6.6243\n",
      "Epoch 1548/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0596 - g_loss: 6.4880\n",
      "Epoch 1549/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0536 - g_loss: 6.6241\n",
      "Epoch 1550/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0851 - g_loss: 6.4455\n",
      "Epoch 1551/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0648 - g_loss: 6.3341\n",
      "Epoch 1552/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0543 - g_loss: 6.5901\n",
      "Epoch 1553/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0755 - g_loss: 6.3613\n",
      "Epoch 1554/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0537 - g_loss: 6.4399\n",
      "Epoch 1555/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0588 - g_loss: 6.5188\n",
      "Epoch 1556/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0303 - g_loss: 6.7304\n",
      "Epoch 1557/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0703 - g_loss: 6.5828\n",
      "Epoch 1558/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0433 - g_loss: 6.6739\n",
      "Epoch 1559/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0647 - g_loss: 6.4566\n",
      "Epoch 1560/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0370 - g_loss: 6.7407\n",
      "Epoch 1561/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0404 - g_loss: 6.8942\n",
      "Epoch 1562/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0365 - g_loss: 6.7690\n",
      "Epoch 1563/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.0344 - g_loss: 6.8119\n",
      "Epoch 1564/3000\n",
      "104/104 [==============================] - 13s 124ms/step - d_loss: 0.0507 - g_loss: 6.7007\n",
      "Epoch 1565/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.0514 - g_loss: 6.7576\n",
      "Epoch 1566/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0412 - g_loss: 6.7439\n",
      "Epoch 1567/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0549 - g_loss: 6.8416\n",
      "Epoch 1568/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0465 - g_loss: 6.7792\n",
      "Epoch 1569/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0545 - g_loss: 6.8223\n",
      "Epoch 1570/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0324 - g_loss: 6.9245\n",
      "Epoch 1571/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0445 - g_loss: 6.7948\n",
      "Epoch 1572/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.1045 - g_loss: 6.6094\n",
      "Epoch 1573/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0856 - g_loss: 6.5930\n",
      "Epoch 1574/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0608 - g_loss: 6.8160\n",
      "Epoch 1575/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0722 - g_loss: 6.6530\n",
      "Epoch 1576/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.0534 - g_loss: 6.7645\n",
      "Epoch 1577/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0635 - g_loss: 6.7434\n",
      "Epoch 1578/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0572 - g_loss: 6.8236\n",
      "Epoch 1579/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0429 - g_loss: 6.9769\n",
      "Epoch 1580/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.0719 - g_loss: 6.8079\n",
      "Epoch 1581/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0803 - g_loss: 6.5973\n",
      "Epoch 1582/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0590 - g_loss: 6.8247\n",
      "Epoch 1583/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0319 - g_loss: 6.9055\n",
      "Epoch 1584/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0619 - g_loss: 6.8493\n",
      "Epoch 1585/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0623 - g_loss: 6.8286\n",
      "Epoch 1586/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0585 - g_loss: 6.8392\n",
      "Epoch 1587/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0367 - g_loss: 6.9209\n",
      "Epoch 1588/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0326 - g_loss: 7.0911\n",
      "Epoch 1589/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0302 - g_loss: 7.1023\n",
      "Epoch 1590/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.0722 - g_loss: 6.7545\n",
      "Epoch 1591/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0657 - g_loss: 6.9183\n",
      "Epoch 1592/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0668 - g_loss: 6.8329\n",
      "Epoch 1593/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0504 - g_loss: 7.0073\n",
      "Epoch 1594/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0754 - g_loss: 6.8181\n",
      "Epoch 1595/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0490 - g_loss: 6.9883\n",
      "Epoch 1596/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0778 - g_loss: 6.8418\n",
      "Epoch 1597/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0570 - g_loss: 7.1086\n",
      "Epoch 1598/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0431 - g_loss: 7.0777\n",
      "Epoch 1599/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0471 - g_loss: 7.1052\n",
      "Epoch 1600/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0275 - g_loss: 6.9163\n",
      "Epoch 1601/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0334 - g_loss: 7.1532\n",
      "Epoch 1602/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0685 - g_loss: 6.9416\n",
      "Epoch 1603/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0534 - g_loss: 6.8742\n",
      "Epoch 1604/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0618 - g_loss: 7.0439\n",
      "Epoch 1605/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0334 - g_loss: 6.9548\n",
      "Epoch 1606/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0435 - g_loss: 7.1231\n",
      "Epoch 1607/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0444 - g_loss: 7.0513\n",
      "Epoch 1608/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0282 - g_loss: 7.3528\n",
      "Epoch 1609/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0412 - g_loss: 7.2124\n",
      "Epoch 1610/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0309 - g_loss: 7.2255\n",
      "Epoch 1611/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0370 - g_loss: 7.3150\n",
      "Epoch 1612/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0230 - g_loss: 7.2910\n",
      "Epoch 1613/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0215 - g_loss: 7.3425\n",
      "Epoch 1614/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0282 - g_loss: 7.3537\n",
      "Epoch 1615/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0701 - g_loss: 7.2201\n",
      "Epoch 1616/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0661 - g_loss: 7.1562\n",
      "Epoch 1617/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.0521 - g_loss: 7.2786\n",
      "Epoch 1618/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0386 - g_loss: 7.3936\n",
      "Epoch 1619/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.0406 - g_loss: 7.2734\n",
      "Epoch 1620/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0369 - g_loss: 7.2736\n",
      "Epoch 1621/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0781 - g_loss: 7.4010\n",
      "Epoch 1622/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0387 - g_loss: 7.2617\n",
      "Epoch 1623/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0297 - g_loss: 7.3742\n",
      "Epoch 1624/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0277 - g_loss: 7.3974\n",
      "Epoch 1625/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0530 - g_loss: 7.2453\n",
      "Epoch 1626/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0410 - g_loss: 7.3328\n",
      "Epoch 1627/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0392 - g_loss: 7.2177\n",
      "Epoch 1628/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0569 - g_loss: 7.1927\n",
      "Epoch 1629/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0509 - g_loss: 7.1974\n",
      "Epoch 1630/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0657 - g_loss: 7.1393\n",
      "Epoch 1631/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0707 - g_loss: 7.3588\n",
      "Epoch 1632/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0381 - g_loss: 7.3490\n",
      "Epoch 1633/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.0140 - g_loss: 7.4770\n",
      "Epoch 1634/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0654 - g_loss: 7.4303\n",
      "Epoch 1635/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0856 - g_loss: 7.2790\n",
      "Epoch 1636/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0526 - g_loss: 7.2911\n",
      "Epoch 1637/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0900 - g_loss: 7.1347\n",
      "Epoch 1638/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0654 - g_loss: 7.2867\n",
      "Epoch 1639/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0432 - g_loss: 7.3512\n",
      "Epoch 1640/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0237 - g_loss: 7.5494\n",
      "Epoch 1641/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0495 - g_loss: 7.4829\n",
      "Epoch 1642/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.1058 - g_loss: 7.1824\n",
      "Epoch 1643/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0478 - g_loss: 7.3534\n",
      "Epoch 1644/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0514 - g_loss: 7.3157\n",
      "Epoch 1645/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0278 - g_loss: 7.4479\n",
      "Epoch 1646/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0287 - g_loss: 7.4946\n",
      "Epoch 1647/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0312 - g_loss: 7.5675\n",
      "Epoch 1648/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0219 - g_loss: 7.6349\n",
      "Epoch 1649/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0354 - g_loss: 7.6403\n",
      "Epoch 1650/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0455 - g_loss: 7.4780\n",
      "Epoch 1651/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0379 - g_loss: 7.5076\n",
      "Epoch 1652/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0508 - g_loss: 7.4740\n",
      "Epoch 1653/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0618 - g_loss: 7.3292\n",
      "Epoch 1654/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0260 - g_loss: 7.6055\n",
      "Epoch 1655/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0510 - g_loss: 7.4923\n",
      "Epoch 1656/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0496 - g_loss: 7.5519\n",
      "Epoch 1657/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0217 - g_loss: 7.6382\n",
      "Epoch 1658/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0338 - g_loss: 7.6444\n",
      "Epoch 1659/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0391 - g_loss: 7.4820\n",
      "Epoch 1660/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0428 - g_loss: 7.5549\n",
      "Epoch 1661/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0252 - g_loss: 7.6888\n",
      "Epoch 1662/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.0390 - g_loss: 7.7528\n",
      "Epoch 1663/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0453 - g_loss: 7.5224\n",
      "Epoch 1664/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.0100 - g_loss: 7.8759\n",
      "Epoch 1665/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0146 - g_loss: 7.9179\n",
      "Epoch 1666/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0197 - g_loss: 7.9257\n",
      "Epoch 1667/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0490 - g_loss: 7.7641\n",
      "Epoch 1668/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0345 - g_loss: 7.6481\n",
      "Epoch 1669/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0336 - g_loss: 7.8202\n",
      "Epoch 1670/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0440 - g_loss: 7.7597\n",
      "Epoch 1671/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0124 - g_loss: 7.9712\n",
      "Epoch 1672/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0335 - g_loss: 7.7921\n",
      "Epoch 1673/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0343 - g_loss: 7.7831\n",
      "Epoch 1674/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0392 - g_loss: 7.8560\n",
      "Epoch 1675/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0975 - g_loss: 7.6194\n",
      "Epoch 1676/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.0945 - g_loss: 7.4598\n",
      "Epoch 1677/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0467 - g_loss: 7.7577\n",
      "Epoch 1678/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0240 - g_loss: 7.8641\n",
      "Epoch 1679/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0330 - g_loss: 7.7897\n",
      "Epoch 1680/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0453 - g_loss: 7.7700\n",
      "Epoch 1681/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0268 - g_loss: 7.7521\n",
      "Epoch 1682/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0422 - g_loss: 7.8748\n",
      "Epoch 1683/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0311 - g_loss: 7.8420\n",
      "Epoch 1684/3000\n",
      "104/104 [==============================] - 13s 123ms/step - d_loss: 0.0243 - g_loss: 7.9681\n",
      "Epoch 1685/3000\n",
      "104/104 [==============================] - 13s 124ms/step - d_loss: 0.0337 - g_loss: 7.9001\n",
      "Epoch 1686/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0266 - g_loss: 8.1408\n",
      "Epoch 1687/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0266 - g_loss: 8.1879\n",
      "Epoch 1688/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0530 - g_loss: 7.7570\n",
      "Epoch 1689/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0838 - g_loss: 7.6983\n",
      "Epoch 1690/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.0929 - g_loss: 7.6550\n",
      "Epoch 1691/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0448 - g_loss: 7.7927\n",
      "Epoch 1692/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0210 - g_loss: 7.9735\n",
      "Epoch 1693/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0247 - g_loss: 7.9113\n",
      "Epoch 1694/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0115 - g_loss: 8.0510\n",
      "Epoch 1695/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0086 - g_loss: 8.3015\n",
      "Epoch 1696/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0200 - g_loss: 8.1656\n",
      "Epoch 1697/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0157 - g_loss: 8.2025\n",
      "Epoch 1698/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0080 - g_loss: 8.3140\n",
      "Epoch 1699/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0333 - g_loss: 8.3784\n",
      "Epoch 1700/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.1006 - g_loss: 7.7230\n",
      "Epoch 1701/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0443 - g_loss: 7.9434\n",
      "Epoch 1702/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0221 - g_loss: 8.1400\n",
      "Epoch 1703/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0180 - g_loss: 8.0860\n",
      "Epoch 1704/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0039 - g_loss: 8.2310\n",
      "Epoch 1705/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0107 - g_loss: 8.5482\n",
      "Epoch 1706/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0350 - g_loss: 8.0442\n",
      "Epoch 1707/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0403 - g_loss: 8.1314\n",
      "Epoch 1708/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0284 - g_loss: 8.2593\n",
      "Epoch 1709/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0080 - g_loss: 8.2826\n",
      "Epoch 1710/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0263 - g_loss: 8.4226\n",
      "Epoch 1711/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0712 - g_loss: 7.9735\n",
      "Epoch 1712/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0621 - g_loss: 8.1115\n",
      "Epoch 1713/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0313 - g_loss: 8.3326\n",
      "Epoch 1714/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0377 - g_loss: 8.2615\n",
      "Epoch 1715/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0331 - g_loss: 8.1543\n",
      "Epoch 1716/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0192 - g_loss: 8.4669\n",
      "Epoch 1717/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0036 - g_loss: 8.5540\n",
      "Epoch 1718/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0477 - g_loss: 8.1515\n",
      "Epoch 1719/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0748 - g_loss: 8.1188\n",
      "Epoch 1720/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0250 - g_loss: 8.1585\n",
      "Epoch 1721/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0225 - g_loss: 8.2773\n",
      "Epoch 1722/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0434 - g_loss: 8.1647\n",
      "Epoch 1723/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0177 - g_loss: 8.4054\n",
      "Epoch 1724/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0267 - g_loss: 8.3140\n",
      "Epoch 1725/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: 0.0188 - g_loss: 8.4561\n",
      "Epoch 1726/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0160 - g_loss: 8.5652\n",
      "Epoch 1727/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0043 - g_loss: 8.6072\n",
      "Epoch 1728/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0172 - g_loss: 8.5669\n",
      "Epoch 1729/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0474 - g_loss: 8.2538\n",
      "Epoch 1730/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0484 - g_loss: 8.3456\n",
      "Epoch 1731/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0476 - g_loss: 8.2752\n",
      "Epoch 1732/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0392 - g_loss: 8.3460\n",
      "Epoch 1733/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0782 - g_loss: 8.2827\n",
      "Epoch 1734/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0656 - g_loss: 8.2768\n",
      "Epoch 1735/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0447 - g_loss: 8.3913\n",
      "Epoch 1736/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0756 - g_loss: 8.1224\n",
      "Epoch 1737/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0483 - g_loss: 8.3143\n",
      "Epoch 1738/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0506 - g_loss: 8.2760\n",
      "Epoch 1739/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0237 - g_loss: 8.5115\n",
      "Epoch 1740/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0575 - g_loss: 8.2085\n",
      "Epoch 1741/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0375 - g_loss: 8.3122\n",
      "Epoch 1742/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0131 - g_loss: 8.6505\n",
      "Epoch 1743/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0087 - g_loss: 8.6300\n",
      "Epoch 1744/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0168 - g_loss: 8.6766\n",
      "Epoch 1745/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0285 - g_loss: 8.5120\n",
      "Epoch 1746/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0177 - g_loss: 8.3676\n",
      "Epoch 1747/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: -5.7372e-04 - g_loss: 8.8912\n",
      "Epoch 1748/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: -0.0058 - g_loss: 8.8375\n",
      "Epoch 1749/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0186 - g_loss: 8.8264\n",
      "Epoch 1750/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0445 - g_loss: 8.5194\n",
      "Epoch 1751/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0327 - g_loss: 8.4677\n",
      "Epoch 1752/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0378 - g_loss: 8.6312\n",
      "Epoch 1753/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0491 - g_loss: 8.5650\n",
      "Epoch 1754/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0390 - g_loss: 8.4139\n",
      "Epoch 1755/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0411 - g_loss: 8.5071\n",
      "Epoch 1756/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0334 - g_loss: 8.5485\n",
      "Epoch 1757/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0130 - g_loss: 8.8458\n",
      "Epoch 1758/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0797 - g_loss: 8.3646\n",
      "Epoch 1759/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0424 - g_loss: 8.4838\n",
      "Epoch 1760/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: 0.0283 - g_loss: 8.5892\n",
      "Epoch 1761/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0284 - g_loss: 8.6465\n",
      "Epoch 1762/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: 0.0222 - g_loss: 8.7266\n",
      "Epoch 1763/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0134 - g_loss: 8.7432\n",
      "Epoch 1764/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0216 - g_loss: 8.7528\n",
      "Epoch 1765/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0127 - g_loss: 8.9107\n",
      "Epoch 1766/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0192 - g_loss: 8.7533\n",
      "Epoch 1767/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0377 - g_loss: 8.8183\n",
      "Epoch 1768/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0362 - g_loss: 8.6628\n",
      "Epoch 1769/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0414 - g_loss: 8.7619\n",
      "Epoch 1770/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0327 - g_loss: 8.6741\n",
      "Epoch 1771/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0370 - g_loss: 8.6989\n",
      "Epoch 1772/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0381 - g_loss: 8.7396\n",
      "Epoch 1773/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0360 - g_loss: 8.7959\n",
      "Epoch 1774/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0482 - g_loss: 8.6839\n",
      "Epoch 1775/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0825 - g_loss: 8.5526\n",
      "Epoch 1776/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0274 - g_loss: 8.7665\n",
      "Epoch 1777/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0205 - g_loss: 8.7319\n",
      "Epoch 1778/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0308 - g_loss: 8.6018\n",
      "Epoch 1779/3000\n",
      "104/104 [==============================] - 13s 124ms/step - d_loss: 0.0386 - g_loss: 8.6844\n",
      "Epoch 1780/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0081 - g_loss: 9.0010\n",
      "Epoch 1781/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: -4.9387e-04 - g_loss: 9.0292\n",
      "Epoch 1782/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: 0.0167 - g_loss: 8.9620\n",
      "Epoch 1783/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0072 - g_loss: 8.8877\n",
      "Epoch 1784/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0186 - g_loss: 8.8761\n",
      "Epoch 1785/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0269 - g_loss: 8.9071\n",
      "Epoch 1786/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0480 - g_loss: 8.7534\n",
      "Epoch 1787/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0388 - g_loss: 8.8949\n",
      "Epoch 1788/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0113 - g_loss: 9.3322\n",
      "Epoch 1789/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: 0.0236 - g_loss: 8.8702\n",
      "Epoch 1790/3000\n",
      "104/104 [==============================] - 13s 123ms/step - d_loss: 0.0394 - g_loss: 8.8727\n",
      "Epoch 1791/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.1025 - g_loss: 8.4925\n",
      "Epoch 1792/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0138 - g_loss: 8.8671\n",
      "Epoch 1793/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0450 - g_loss: 8.8732\n",
      "Epoch 1794/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0533 - g_loss: 8.8182\n",
      "Epoch 1795/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0555 - g_loss: 8.7715\n",
      "Epoch 1796/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0175 - g_loss: 9.1113\n",
      "Epoch 1797/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0211 - g_loss: 9.0538\n",
      "Epoch 1798/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: 0.0109 - g_loss: 9.2192\n",
      "Epoch 1799/3000\n",
      "104/104 [==============================] - 13s 124ms/step - d_loss: -0.0012 - g_loss: 9.2646\n",
      "Epoch 1800/3000\n",
      "104/104 [==============================] - 13s 124ms/step - d_loss: -0.0117 - g_loss: 9.3611\n",
      "Epoch 1801/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0914 - g_loss: 8.6861\n",
      "Epoch 1802/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0719 - g_loss: 8.6757\n",
      "Epoch 1803/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0431 - g_loss: 8.8621\n",
      "Epoch 1804/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0120 - g_loss: 9.0620\n",
      "Epoch 1805/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0127 - g_loss: 9.1550\n",
      "Epoch 1806/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0112 - g_loss: 9.0952\n",
      "Epoch 1807/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: -0.0053 - g_loss: 9.4244\n",
      "Epoch 1808/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: 0.0126 - g_loss: 9.2762\n",
      "Epoch 1809/3000\n",
      "104/104 [==============================] - 13s 123ms/step - d_loss: 0.0229 - g_loss: 9.0074\n",
      "Epoch 1810/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: -0.0061 - g_loss: 9.5290\n",
      "Epoch 1811/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0065 - g_loss: 9.4497\n",
      "Epoch 1812/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0109 - g_loss: 9.2978\n",
      "Epoch 1813/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0271 - g_loss: 9.2381\n",
      "Epoch 1814/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0299 - g_loss: 9.0860\n",
      "Epoch 1815/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0111 - g_loss: 9.4009\n",
      "Epoch 1816/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: 0.0253 - g_loss: 9.2765\n",
      "Epoch 1817/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: 0.0306 - g_loss: 9.1569\n",
      "Epoch 1818/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: 0.0321 - g_loss: 9.0510\n",
      "Epoch 1819/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0678 - g_loss: 9.1668\n",
      "Epoch 1820/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0349 - g_loss: 8.9049\n",
      "Epoch 1821/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 7.0884e-04 - g_loss: 9.5333\n",
      "Epoch 1822/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0139 - g_loss: 9.1451\n",
      "Epoch 1823/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0061 - g_loss: 9.3886\n",
      "Epoch 1824/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0254 - g_loss: 9.4566\n",
      "Epoch 1825/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0674 - g_loss: 8.9717\n",
      "Epoch 1826/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: 0.0490 - g_loss: 9.0876\n",
      "Epoch 1827/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: 0.0375 - g_loss: 9.0276\n",
      "Epoch 1828/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0494 - g_loss: 9.0690\n",
      "Epoch 1829/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: 0.0979 - g_loss: 8.9574\n",
      "Epoch 1830/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0322 - g_loss: 8.9788\n",
      "Epoch 1831/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0196 - g_loss: 9.3572\n",
      "Epoch 1832/3000\n",
      "104/104 [==============================] - 13s 123ms/step - d_loss: 0.0196 - g_loss: 9.3303\n",
      "Epoch 1833/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: 0.0043 - g_loss: 9.3955\n",
      "Epoch 1834/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: -0.0026 - g_loss: 9.5417\n",
      "Epoch 1835/3000\n",
      "104/104 [==============================] - 13s 123ms/step - d_loss: -4.8259e-05 - g_loss: 9.5088\n",
      "Epoch 1836/3000\n",
      "104/104 [==============================] - 13s 124ms/step - d_loss: -0.0024 - g_loss: 9.6924\n",
      "Epoch 1837/3000\n",
      "104/104 [==============================] - 13s 124ms/step - d_loss: -0.0020 - g_loss: 9.6989\n",
      "Epoch 1838/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: -0.0042 - g_loss: 9.5619\n",
      "Epoch 1839/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0235 - g_loss: 9.3744\n",
      "Epoch 1840/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.0363 - g_loss: 9.2327\n",
      "Epoch 1841/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0420 - g_loss: 9.3547\n",
      "Epoch 1842/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0662 - g_loss: 9.2293\n",
      "Epoch 1843/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0842 - g_loss: 8.9279\n",
      "Epoch 1844/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: -0.0039 - g_loss: 9.4629\n",
      "Epoch 1845/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 9.0013e-04 - g_loss: 9.5858\n",
      "Epoch 1846/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: -0.0139 - g_loss: 9.9035\n",
      "Epoch 1847/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 1.8737e-05 - g_loss: 9.7554\n",
      "Epoch 1848/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0017 - g_loss: 9.8462\n",
      "Epoch 1849/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0114 - g_loss: 9.5615\n",
      "Epoch 1850/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0643 - g_loss: 9.0025\n",
      "Epoch 1851/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0316 - g_loss: 9.2276\n",
      "Epoch 1852/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0264 - g_loss: 9.3743\n",
      "Epoch 1853/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0214 - g_loss: 9.4320\n",
      "Epoch 1854/3000\n",
      "104/104 [==============================] - 13s 124ms/step - d_loss: 0.0403 - g_loss: 9.2199\n",
      "Epoch 1855/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: 0.0156 - g_loss: 9.3995\n",
      "Epoch 1856/3000\n",
      "104/104 [==============================] - 13s 123ms/step - d_loss: 0.0299 - g_loss: 9.5178\n",
      "Epoch 1857/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: 0.0318 - g_loss: 9.5016\n",
      "Epoch 1858/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0263 - g_loss: 9.5999\n",
      "Epoch 1859/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0359 - g_loss: 9.4199\n",
      "Epoch 1860/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0197 - g_loss: 9.5889\n",
      "Epoch 1861/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: -6.4910e-04 - g_loss: 9.9282\n",
      "Epoch 1862/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0199 - g_loss: 9.3579\n",
      "Epoch 1863/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0014 - g_loss: 9.8246\n",
      "Epoch 1864/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0060 - g_loss: 9.7454\n",
      "Epoch 1865/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: -0.0061 - g_loss: 9.8763\n",
      "Epoch 1866/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0115 - g_loss: 9.8995\n",
      "Epoch 1867/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: -8.2540e-04 - g_loss: 9.9600\n",
      "Epoch 1868/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: -0.0190 - g_loss: 10.2074\n",
      "Epoch 1869/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0559 - g_loss: 9.6904\n",
      "Epoch 1870/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0028 - g_loss: 9.9243\n",
      "Epoch 1871/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0106 - g_loss: 10.0909\n",
      "Epoch 1872/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0320 - g_loss: 9.5640\n",
      "Epoch 1873/3000\n",
      "104/104 [==============================] - 13s 123ms/step - d_loss: 0.0265 - g_loss: 9.5459\n",
      "Epoch 1874/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: 0.0097 - g_loss: 9.9127\n",
      "Epoch 1875/3000\n",
      "104/104 [==============================] - 13s 123ms/step - d_loss: 0.0325 - g_loss: 9.7971\n",
      "Epoch 1876/3000\n",
      "104/104 [==============================] - 13s 123ms/step - d_loss: 0.0877 - g_loss: 9.3488\n",
      "Epoch 1877/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0195 - g_loss: 9.6933\n",
      "Epoch 1878/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0207 - g_loss: 9.8429\n",
      "Epoch 1879/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: 0.0287 - g_loss: 9.6714\n",
      "Epoch 1880/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0174 - g_loss: 9.8286\n",
      "Epoch 1881/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0041 - g_loss: 9.8213\n",
      "Epoch 1882/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0130 - g_loss: 10.0971\n",
      "Epoch 1883/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0177 - g_loss: 9.8336\n",
      "Epoch 1884/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0255 - g_loss: 9.7836\n",
      "Epoch 1885/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0825 - g_loss: 9.4327\n",
      "Epoch 1886/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: -0.0046 - g_loss: 9.7882\n",
      "Epoch 1887/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: -0.0156 - g_loss: 10.0774\n",
      "Epoch 1888/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: -0.0043 - g_loss: 10.1669\n",
      "Epoch 1889/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: -0.0095 - g_loss: 10.1954\n",
      "Epoch 1890/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: -0.0106 - g_loss: 10.3346\n",
      "Epoch 1891/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0234 - g_loss: 9.8765\n",
      "Epoch 1892/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: 0.0405 - g_loss: 9.7336\n",
      "Epoch 1893/3000\n",
      "104/104 [==============================] - 13s 124ms/step - d_loss: 0.0100 - g_loss: 9.9222\n",
      "Epoch 1894/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0218 - g_loss: 9.8516\n",
      "Epoch 1895/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0289 - g_loss: 10.1188\n",
      "Epoch 1896/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0546 - g_loss: 9.4784\n",
      "Epoch 1897/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0240 - g_loss: 9.8644\n",
      "Epoch 1898/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0094 - g_loss: 10.1204\n",
      "Epoch 1899/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0063 - g_loss: 10.1005\n",
      "Epoch 1900/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0112 - g_loss: 10.1161\n",
      "Epoch 1901/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0269 - g_loss: 9.9044\n",
      "Epoch 1902/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0061 - g_loss: 10.1843\n",
      "Epoch 1903/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0146 - g_loss: 10.1778\n",
      "Epoch 1904/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: -0.0016 - g_loss: 10.3036\n",
      "Epoch 1905/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: -0.0126 - g_loss: 10.4687\n",
      "Epoch 1906/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0192 - g_loss: 10.0173\n",
      "Epoch 1907/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0277 - g_loss: 9.9967\n",
      "Epoch 1908/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0149 - g_loss: 10.2354\n",
      "Epoch 1909/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0040 - g_loss: 10.1124\n",
      "Epoch 1910/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0066 - g_loss: 10.2893\n",
      "Epoch 1911/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: -0.0060 - g_loss: 10.3855\n",
      "Epoch 1912/3000\n",
      "104/104 [==============================] - 13s 123ms/step - d_loss: 0.0302 - g_loss: 10.1350\n",
      "Epoch 1913/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: 0.0217 - g_loss: 10.1228\n",
      "Epoch 1914/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0369 - g_loss: 9.9942\n",
      "Epoch 1915/3000\n",
      "104/104 [==============================] - 13s 124ms/step - d_loss: 0.0142 - g_loss: 10.1480\n",
      "Epoch 1916/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: 0.0531 - g_loss: 9.8006\n",
      "Epoch 1917/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0253 - g_loss: 10.1003\n",
      "Epoch 1918/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: -0.0157 - g_loss: 10.6388\n",
      "Epoch 1919/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0091 - g_loss: 10.1465\n",
      "Epoch 1920/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 5.6909e-04 - g_loss: 10.3032\n",
      "Epoch 1921/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0055 - g_loss: 10.4080\n",
      "Epoch 1922/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: 0.1023 - g_loss: 9.7152\n",
      "Epoch 1923/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0315 - g_loss: 9.8950\n",
      "Epoch 1924/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: 0.0342 - g_loss: 10.0261\n",
      "Epoch 1925/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0812 - g_loss: 9.5227\n",
      "Epoch 1926/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0095 - g_loss: 10.3537\n",
      "Epoch 1927/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0032 - g_loss: 10.3888\n",
      "Epoch 1928/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0298 - g_loss: 9.8626\n",
      "Epoch 1929/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0145 - g_loss: 9.9754\n",
      "Epoch 1930/3000\n",
      "104/104 [==============================] - 13s 124ms/step - d_loss: 0.0182 - g_loss: 10.1997\n",
      "Epoch 1931/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: -0.0019 - g_loss: 10.5097\n",
      "Epoch 1932/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: -0.0099 - g_loss: 10.6061\n",
      "Epoch 1933/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0080 - g_loss: 10.4870\n",
      "Epoch 1934/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0201 - g_loss: 10.2918\n",
      "Epoch 1935/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0080 - g_loss: 10.5323\n",
      "Epoch 1936/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0457 - g_loss: 10.1712\n",
      "Epoch 1937/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: 0.0282 - g_loss: 10.0366\n",
      "Epoch 1938/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0074 - g_loss: 10.3736\n",
      "Epoch 1939/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: -0.0229 - g_loss: 10.7285\n",
      "Epoch 1940/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0094 - g_loss: 10.3714\n",
      "Epoch 1941/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: -0.0111 - g_loss: 10.7088\n",
      "Epoch 1942/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0011 - g_loss: 10.6479\n",
      "Epoch 1943/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: -0.0116 - g_loss: 10.8917\n",
      "Epoch 1944/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0285 - g_loss: 10.1968\n",
      "Epoch 1945/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0072 - g_loss: 10.7106\n",
      "Epoch 1946/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0021 - g_loss: 10.5959\n",
      "Epoch 1947/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0800 - g_loss: 9.7839\n",
      "Epoch 1948/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0267 - g_loss: 10.2282\n",
      "Epoch 1949/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: -0.0110 - g_loss: 10.6028\n",
      "Epoch 1950/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0060 - g_loss: 10.4795\n",
      "Epoch 1951/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: -0.0117 - g_loss: 10.8541\n",
      "Epoch 1952/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: 4.9776e-04 - g_loss: 10.5682\n",
      "Epoch 1953/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: -0.0115 - g_loss: 10.8402\n",
      "Epoch 1954/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: -0.0082 - g_loss: 10.8516\n",
      "Epoch 1955/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0041 - g_loss: 10.7912\n",
      "Epoch 1956/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: -0.0017 - g_loss: 10.7420\n",
      "Epoch 1957/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0142 - g_loss: 10.5609\n",
      "Epoch 1958/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 5.2161e-04 - g_loss: 10.7550\n",
      "Epoch 1959/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0121 - g_loss: 10.6264\n",
      "Epoch 1960/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0726 - g_loss: 10.3652\n",
      "Epoch 1961/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0592 - g_loss: 10.0429\n",
      "Epoch 1962/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0289 - g_loss: 10.3905\n",
      "Epoch 1963/3000\n",
      "104/104 [==============================] - 13s 123ms/step - d_loss: 0.0155 - g_loss: 10.6714\n",
      "Epoch 1964/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0043 - g_loss: 10.6127\n",
      "Epoch 1965/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0352 - g_loss: 10.3107\n",
      "Epoch 1966/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: -0.0010 - g_loss: 10.6752\n",
      "Epoch 1967/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: -0.0182 - g_loss: 10.9703\n",
      "Epoch 1968/3000\n",
      "104/104 [==============================] - 13s 123ms/step - d_loss: -3.3968e-04 - g_loss: 10.8032\n",
      "Epoch 1969/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: -0.0053 - g_loss: 10.8379\n",
      "Epoch 1970/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0436 - g_loss: 10.3386\n",
      "Epoch 1971/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0161 - g_loss: 10.7067\n",
      "Epoch 1972/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: -0.0059 - g_loss: 10.8770\n",
      "Epoch 1973/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: -0.0152 - g_loss: 11.2529\n",
      "Epoch 1974/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: -0.0149 - g_loss: 11.1110\n",
      "Epoch 1975/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: -0.0011 - g_loss: 11.0296\n",
      "Epoch 1976/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0127 - g_loss: 10.7917\n",
      "Epoch 1977/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: -0.0038 - g_loss: 11.1133\n",
      "Epoch 1978/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0162 - g_loss: 10.8329\n",
      "Epoch 1979/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0384 - g_loss: 10.7486\n",
      "Epoch 1980/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0165 - g_loss: 10.7495\n",
      "Epoch 1981/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 7.9944e-05 - g_loss: 10.9119\n",
      "Epoch 1982/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0162 - g_loss: 10.8830\n",
      "Epoch 1983/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0382 - g_loss: 10.4403\n",
      "Epoch 1984/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: 0.0344 - g_loss: 10.6992\n",
      "Epoch 1985/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0264 - g_loss: 10.4765\n",
      "Epoch 1986/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0696 - g_loss: 10.3434\n",
      "Epoch 1987/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0202 - g_loss: 10.7216\n",
      "Epoch 1988/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: -6.3965e-04 - g_loss: 10.7652\n",
      "Epoch 1989/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0340 - g_loss: 10.5715\n",
      "Epoch 1990/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0066 - g_loss: 10.7911\n",
      "Epoch 1991/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: -0.0228 - g_loss: 11.1269\n",
      "Epoch 1992/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: -0.0054 - g_loss: 11.0772\n",
      "Epoch 1993/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: -0.0060 - g_loss: 11.3168\n",
      "Epoch 1994/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: -0.0239 - g_loss: 11.4102\n",
      "Epoch 1995/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0335 - g_loss: 10.7878\n",
      "Epoch 1996/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: -0.0176 - g_loss: 11.3378\n",
      "Epoch 1997/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0280 - g_loss: 10.9035\n",
      "Epoch 1998/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0339 - g_loss: 10.4516\n",
      "Epoch 1999/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0103 - g_loss: 10.8021\n",
      "Epoch 2000/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: -0.0095 - g_loss: 11.3882\n",
      "Epoch 2001/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: -0.0018 - g_loss: 11.1292\n",
      "Epoch 2002/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: 0.0055 - g_loss: 11.1647\n",
      "Epoch 2003/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: -0.0020 - g_loss: 11.0119\n",
      "Epoch 2004/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: -0.0098 - g_loss: 11.2335\n",
      "Epoch 2005/3000\n",
      "104/104 [==============================] - 13s 124ms/step - d_loss: 0.0079 - g_loss: 11.1149\n",
      "Epoch 2006/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0088 - g_loss: 11.0844\n",
      "Epoch 2007/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0662 - g_loss: 10.7685\n",
      "Epoch 2008/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0366 - g_loss: 10.7996\n",
      "Epoch 2009/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0249 - g_loss: 11.0384\n",
      "Epoch 2010/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: -0.0060 - g_loss: 11.1784\n",
      "Epoch 2011/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0562 - g_loss: 10.7510\n",
      "Epoch 2012/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0040 - g_loss: 11.2290\n",
      "Epoch 2013/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0121 - g_loss: 11.3788\n",
      "Epoch 2014/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0271 - g_loss: 10.8721\n",
      "Epoch 2015/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: 0.0043 - g_loss: 11.1969\n",
      "Epoch 2016/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: -0.0073 - g_loss: 11.2943\n",
      "Epoch 2017/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: -0.0214 - g_loss: 11.5708\n",
      "Epoch 2018/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: -0.0111 - g_loss: 11.5099\n",
      "Epoch 2019/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: -0.0115 - g_loss: 11.5537\n",
      "Epoch 2020/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0014 - g_loss: 11.2849\n",
      "Epoch 2021/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: -0.0152 - g_loss: 11.5286\n",
      "Epoch 2022/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: -0.0050 - g_loss: 11.3142\n",
      "Epoch 2023/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: -0.0082 - g_loss: 11.4313\n",
      "Epoch 2024/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0242 - g_loss: 11.2797\n",
      "Epoch 2025/3000\n",
      "104/104 [==============================] - 13s 123ms/step - d_loss: 0.0147 - g_loss: 11.1182\n",
      "Epoch 2026/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: -0.0106 - g_loss: 11.5545\n",
      "Epoch 2027/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: -0.0061 - g_loss: 11.4104\n",
      "Epoch 2028/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: 0.0955 - g_loss: 10.8970\n",
      "Epoch 2029/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0474 - g_loss: 10.8721\n",
      "Epoch 2030/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.0483 - g_loss: 11.0015\n",
      "Epoch 2031/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 4.3716e-04 - g_loss: 11.1164\n",
      "Epoch 2032/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.0170 - g_loss: 11.1371\n",
      "Epoch 2033/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: -0.0112 - g_loss: 11.6245\n",
      "Epoch 2034/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: -0.0088 - g_loss: 11.5153\n",
      "Epoch 2035/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0266 - g_loss: 11.2452\n",
      "Epoch 2036/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0294 - g_loss: 11.0112\n",
      "Epoch 2037/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: -0.0237 - g_loss: 11.5586\n",
      "Epoch 2038/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: -0.0207 - g_loss: 11.7288\n",
      "Epoch 2039/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: -0.0316 - g_loss: 12.0062\n",
      "Epoch 2040/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0094 - g_loss: 11.2484\n",
      "Epoch 2041/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0023 - g_loss: 11.4002\n",
      "Epoch 2042/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0167 - g_loss: 11.1732\n",
      "Epoch 2043/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: 0.0010 - g_loss: 11.3214\n",
      "Epoch 2044/3000\n",
      "104/104 [==============================] - 13s 123ms/step - d_loss: -0.0163 - g_loss: 11.4826\n",
      "Epoch 2045/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: -0.0256 - g_loss: 11.9046\n",
      "Epoch 2046/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0265 - g_loss: 11.1795\n",
      "Epoch 2047/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0206 - g_loss: 11.0649\n",
      "Epoch 2048/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.0648 - g_loss: 11.0618\n",
      "Epoch 2049/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0150 - g_loss: 11.3910\n",
      "Epoch 2050/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: -0.0094 - g_loss: 11.4688\n",
      "Epoch 2051/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: -0.0139 - g_loss: 11.6029\n",
      "Epoch 2052/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: -0.0183 - g_loss: 11.8676\n",
      "Epoch 2053/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: -0.0024 - g_loss: 11.7739\n",
      "Epoch 2054/3000\n",
      "104/104 [==============================] - 13s 124ms/step - d_loss: -0.0069 - g_loss: 11.7083\n",
      "Epoch 2055/3000\n",
      "104/104 [==============================] - 13s 125ms/step - d_loss: 0.0192 - g_loss: 11.2939\n",
      "Epoch 2056/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: -0.0281 - g_loss: 11.9343\n",
      "Epoch 2057/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0022 - g_loss: 11.4803\n",
      "Epoch 2058/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: 0.0560 - g_loss: 11.0177\n",
      "Epoch 2059/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: 0.0063 - g_loss: 11.4739\n",
      "Epoch 2060/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: -0.0070 - g_loss: 11.7495\n",
      "Epoch 2061/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: -0.0143 - g_loss: 12.0054\n",
      "Epoch 2062/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0147 - g_loss: 11.4082\n",
      "Epoch 2063/3000\n",
      "104/104 [==============================] - 13s 123ms/step - d_loss: 0.0317 - g_loss: 11.4765\n",
      "Epoch 2064/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: -0.0048 - g_loss: 11.6516\n",
      "Epoch 2065/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: -0.0102 - g_loss: 11.9407\n",
      "Epoch 2066/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0098 - g_loss: 11.6236\n",
      "Epoch 2067/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: -0.0019 - g_loss: 11.9027\n",
      "Epoch 2068/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: -0.0114 - g_loss: 12.0814\n",
      "Epoch 2069/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0100 - g_loss: 12.0054\n",
      "Epoch 2070/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: -0.0028 - g_loss: 11.9635\n",
      "Epoch 2071/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0062 - g_loss: 11.8310\n",
      "Epoch 2072/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0069 - g_loss: 11.8411\n",
      "Epoch 2073/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: -0.0071 - g_loss: 11.9757\n",
      "Epoch 2074/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: -6.4959e-04 - g_loss: 11.7595\n",
      "Epoch 2075/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0049 - g_loss: 11.7576\n",
      "Epoch 2076/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: -0.0047 - g_loss: 12.0305\n",
      "Epoch 2077/3000\n",
      "104/104 [==============================] - 13s 124ms/step - d_loss: 0.0075 - g_loss: 11.9875\n",
      "Epoch 2078/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: -0.0148 - g_loss: 12.1063\n",
      "Epoch 2079/3000\n",
      "104/104 [==============================] - 13s 123ms/step - d_loss: 0.0137 - g_loss: 11.7597\n",
      "Epoch 2080/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: -0.0084 - g_loss: 11.9743\n",
      "Epoch 2081/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: -0.0180 - g_loss: 12.3159\n",
      "Epoch 2082/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.0215 - g_loss: 11.6542\n",
      "Epoch 2083/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0185 - g_loss: 11.6693\n",
      "Epoch 2084/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0130 - g_loss: 11.7976\n",
      "Epoch 2085/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0302 - g_loss: 11.7992\n",
      "Epoch 2086/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0245 - g_loss: 11.7973\n",
      "Epoch 2087/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0188 - g_loss: 11.7923\n",
      "Epoch 2088/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0986 - g_loss: 11.0913\n",
      "Epoch 2089/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0117 - g_loss: 11.6016\n",
      "Epoch 2090/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: -0.0129 - g_loss: 11.9215\n",
      "Epoch 2091/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: 0.0259 - g_loss: 11.7829\n",
      "Epoch 2092/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: -0.0093 - g_loss: 12.1018\n",
      "Epoch 2093/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: -0.0225 - g_loss: 12.1444\n",
      "Epoch 2094/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0038 - g_loss: 12.0415\n",
      "Epoch 2095/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: -0.0228 - g_loss: 12.1833\n",
      "Epoch 2096/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0116 - g_loss: 11.9837\n",
      "Epoch 2097/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: -0.0167 - g_loss: 12.2878\n",
      "Epoch 2098/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: -0.0051 - g_loss: 11.9803\n",
      "Epoch 2099/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: -0.0024 - g_loss: 12.0019\n",
      "Epoch 2100/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: -0.0076 - g_loss: 12.1434\n",
      "Epoch 2101/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: -0.0261 - g_loss: 12.5426\n",
      "Epoch 2102/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: -0.0055 - g_loss: 11.9223\n",
      "Epoch 2103/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: -0.0312 - g_loss: 12.3529\n",
      "Epoch 2104/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0076 - g_loss: 12.0670\n",
      "Epoch 2105/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0616 - g_loss: 11.4558\n",
      "Epoch 2106/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0330 - g_loss: 11.8716\n",
      "Epoch 2107/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0582 - g_loss: 11.5290\n",
      "Epoch 2108/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: -0.0107 - g_loss: 12.0973\n",
      "Epoch 2109/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0191 - g_loss: 11.8033\n",
      "Epoch 2110/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0144 - g_loss: 12.0543\n",
      "Epoch 2111/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: 0.0321 - g_loss: 11.7358\n",
      "Epoch 2112/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: -0.0017 - g_loss: 12.1300\n",
      "Epoch 2113/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: -0.0113 - g_loss: 12.4356\n",
      "Epoch 2114/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: -0.0027 - g_loss: 12.1714\n",
      "Epoch 2115/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0175 - g_loss: 11.9591\n",
      "Epoch 2116/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: -0.0117 - g_loss: 12.1646\n",
      "Epoch 2117/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: -0.0212 - g_loss: 12.3035\n",
      "Epoch 2118/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0108 - g_loss: 12.0262\n",
      "Epoch 2119/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: -0.0241 - g_loss: 12.6882\n",
      "Epoch 2120/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: -0.0058 - g_loss: 12.3370\n",
      "Epoch 2121/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: 0.0221 - g_loss: 12.0183\n",
      "Epoch 2122/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0043 - g_loss: 12.4578\n",
      "Epoch 2123/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: -0.0142 - g_loss: 12.2766\n",
      "Epoch 2124/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0030 - g_loss: 12.2785\n",
      "Epoch 2125/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0236 - g_loss: 12.2609\n",
      "Epoch 2126/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: 0.0127 - g_loss: 12.2514\n",
      "Epoch 2127/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: -0.0156 - g_loss: 12.4314\n",
      "Epoch 2128/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0203 - g_loss: 12.0356\n",
      "Epoch 2129/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0400 - g_loss: 11.8860\n",
      "Epoch 2130/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0334 - g_loss: 12.1472\n",
      "Epoch 2131/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0053 - g_loss: 12.1821\n",
      "Epoch 2132/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0180 - g_loss: 12.1601\n",
      "Epoch 2133/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: -0.0113 - g_loss: 12.3852\n",
      "Epoch 2134/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: -0.0088 - g_loss: 12.5120\n",
      "Epoch 2135/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: -0.0078 - g_loss: 12.5033\n",
      "Epoch 2136/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: 0.0153 - g_loss: 12.5226\n",
      "Epoch 2137/3000\n",
      "104/104 [==============================] - 13s 127ms/step - d_loss: 0.0012 - g_loss: 12.3493\n",
      "Epoch 2138/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: 0.0069 - g_loss: 12.4114\n",
      "Epoch 2139/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: -0.0062 - g_loss: 12.4932\n",
      "Epoch 2140/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: -0.0269 - g_loss: 12.9173\n",
      "Epoch 2141/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: -0.0342 - g_loss: 13.0933\n",
      "Epoch 2142/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0020 - g_loss: 12.5423\n",
      "Epoch 2143/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: -0.0081 - g_loss: 12.8339\n",
      "Epoch 2144/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: -0.0012 - g_loss: 12.5880\n",
      "Epoch 2145/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: -0.0250 - g_loss: 12.8463\n",
      "Epoch 2146/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: 0.0355 - g_loss: 12.2856\n",
      "Epoch 2147/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: 0.0086 - g_loss: 12.3152\n",
      "Epoch 2148/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: -0.0089 - g_loss: 12.6978\n",
      "Epoch 2149/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0111 - g_loss: 12.5946\n",
      "Epoch 2150/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: -0.0093 - g_loss: 12.6674\n",
      "Epoch 2151/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: -0.0190 - g_loss: 13.0356\n",
      "Epoch 2152/3000\n",
      "104/104 [==============================] - 13s 123ms/step - d_loss: -0.0142 - g_loss: 12.6479\n",
      "Epoch 2153/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: -0.0244 - g_loss: 12.7954\n",
      "Epoch 2154/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0172 - g_loss: 12.6751\n",
      "Epoch 2155/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: 0.0051 - g_loss: 12.5618\n",
      "Epoch 2156/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0092 - g_loss: 12.3355\n",
      "Epoch 2157/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.0032 - g_loss: 12.4906\n",
      "Epoch 2158/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: -0.0229 - g_loss: 12.8385\n",
      "Epoch 2159/3000\n",
      "104/104 [==============================] - 13s 127ms/step - d_loss: -0.0193 - g_loss: 12.8936\n",
      "Epoch 2160/3000\n",
      "104/104 [==============================] - 15s 143ms/step - d_loss: -0.0065 - g_loss: 12.6072\n",
      "Epoch 2161/3000\n",
      "104/104 [==============================] - 15s 141ms/step - d_loss: -0.0292 - g_loss: 13.0180\n",
      "Epoch 2162/3000\n",
      "104/104 [==============================] - 13s 127ms/step - d_loss: -0.0181 - g_loss: 12.8947\n",
      "Epoch 2163/3000\n",
      "104/104 [==============================] - 14s 134ms/step - d_loss: 0.0073 - g_loss: 12.3155\n",
      "Epoch 2164/3000\n",
      "104/104 [==============================] - 14s 135ms/step - d_loss: -0.0026 - g_loss: 12.7400\n",
      "Epoch 2165/3000\n",
      "104/104 [==============================] - 15s 139ms/step - d_loss: -0.0321 - g_loss: 12.9701\n",
      "Epoch 2166/3000\n",
      "104/104 [==============================] - 15s 137ms/step - d_loss: 0.0058 - g_loss: 12.6554\n",
      "Epoch 2167/3000\n",
      "104/104 [==============================] - 14s 135ms/step - d_loss: -0.0175 - g_loss: 12.7862\n",
      "Epoch 2168/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: 0.0336 - g_loss: 12.1758\n",
      "Epoch 2169/3000\n",
      "104/104 [==============================] - 14s 135ms/step - d_loss: 0.0277 - g_loss: 12.5424\n",
      "Epoch 2170/3000\n",
      "104/104 [==============================] - 15s 141ms/step - d_loss: 0.0138 - g_loss: 12.4964\n",
      "Epoch 2171/3000\n",
      "104/104 [==============================] - 15s 139ms/step - d_loss: 0.0082 - g_loss: 12.6707\n",
      "Epoch 2172/3000\n",
      "104/104 [==============================] - 15s 141ms/step - d_loss: 0.0014 - g_loss: 12.6210\n",
      "Epoch 2173/3000\n",
      "104/104 [==============================] - 14s 134ms/step - d_loss: -0.0191 - g_loss: 12.9697\n",
      "Epoch 2174/3000\n",
      "104/104 [==============================] - 15s 139ms/step - d_loss: -0.0043 - g_loss: 12.7450\n",
      "Epoch 2175/3000\n",
      "104/104 [==============================] - 15s 145ms/step - d_loss: 0.0219 - g_loss: 12.2391\n",
      "Epoch 2176/3000\n",
      "104/104 [==============================] - 14s 135ms/step - d_loss: -0.0163 - g_loss: 12.7151\n",
      "Epoch 2177/3000\n",
      "104/104 [==============================] - 15s 138ms/step - d_loss: -0.0082 - g_loss: 12.9123\n",
      "Epoch 2178/3000\n",
      "104/104 [==============================] - 14s 136ms/step - d_loss: -0.0223 - g_loss: 12.8983\n",
      "Epoch 2179/3000\n",
      "104/104 [==============================] - 15s 145ms/step - d_loss: 2.7735e-04 - g_loss: 12.5875\n",
      "Epoch 2180/3000\n",
      "104/104 [==============================] - 15s 137ms/step - d_loss: -0.0164 - g_loss: 13.1859\n",
      "Epoch 2181/3000\n",
      "104/104 [==============================] - 15s 137ms/step - d_loss: 0.0312 - g_loss: 12.4606\n",
      "Epoch 2182/3000\n",
      "104/104 [==============================] - 15s 143ms/step - d_loss: -0.0166 - g_loss: 12.5389\n",
      "Epoch 2183/3000\n",
      "104/104 [==============================] - 15s 139ms/step - d_loss: -0.0265 - g_loss: 12.9322\n",
      "Epoch 2184/3000\n",
      "104/104 [==============================] - 16s 144ms/step - d_loss: -0.0338 - g_loss: 13.3218\n",
      "Epoch 2185/3000\n",
      "104/104 [==============================] - 15s 143ms/step - d_loss: -0.0291 - g_loss: 13.2825\n",
      "Epoch 2186/3000\n",
      "104/104 [==============================] - 15s 139ms/step - d_loss: -0.0286 - g_loss: 13.1919\n",
      "Epoch 2187/3000\n",
      "104/104 [==============================] - 16s 151ms/step - d_loss: -0.0385 - g_loss: 13.4661\n",
      "Epoch 2188/3000\n",
      "104/104 [==============================] - 16s 147ms/step - d_loss: -0.0442 - g_loss: 13.6621\n",
      "Epoch 2189/3000\n",
      "104/104 [==============================] - 15s 142ms/step - d_loss: -0.0254 - g_loss: 13.1250\n",
      "Epoch 2190/3000\n",
      "104/104 [==============================] - 15s 143ms/step - d_loss: -0.0242 - g_loss: 13.4136\n",
      "Epoch 2191/3000\n",
      "104/104 [==============================] - 15s 139ms/step - d_loss: 0.0116 - g_loss: 12.8495\n",
      "Epoch 2192/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: 0.0198 - g_loss: 12.5380\n",
      "Epoch 2193/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: -0.0122 - g_loss: 13.1747\n",
      "Epoch 2194/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0222 - g_loss: 13.3115\n",
      "Epoch 2195/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0414 - g_loss: 13.6131\n",
      "Epoch 2196/3000\n",
      "104/104 [==============================] - 11s 108ms/step - d_loss: -0.0454 - g_loss: 13.7546\n",
      "Epoch 2197/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0391 - g_loss: 13.6178\n",
      "Epoch 2198/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: -0.0552 - g_loss: 13.7620\n",
      "Epoch 2199/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: -0.0096 - g_loss: 13.2636\n",
      "Epoch 2200/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: 0.0829 - g_loss: 12.1643\n",
      "Epoch 2201/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.0826 - g_loss: 12.6193\n",
      "Epoch 2202/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.0666 - g_loss: 12.3613\n",
      "Epoch 2203/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.0094 - g_loss: 13.1358\n",
      "Epoch 2204/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: -0.0144 - g_loss: 13.2090\n",
      "Epoch 2205/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: -0.0367 - g_loss: 13.6605\n",
      "Epoch 2206/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: -0.0493 - g_loss: 13.9327\n",
      "Epoch 2207/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: -0.0273 - g_loss: 13.6931\n",
      "Epoch 2208/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: 0.0025 - g_loss: 12.8971\n",
      "Epoch 2209/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: 0.0020 - g_loss: 13.2749\n",
      "Epoch 2210/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: -0.0053 - g_loss: 13.3551\n",
      "Epoch 2211/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: -0.0018 - g_loss: 13.3951\n",
      "Epoch 2212/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: -0.0161 - g_loss: 13.5738\n",
      "Epoch 2213/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: -0.0413 - g_loss: 13.7301\n",
      "Epoch 2214/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: -0.0484 - g_loss: 13.8673\n",
      "Epoch 2215/3000\n",
      "104/104 [==============================] - 516s 5s/step - d_loss: -0.0121 - g_loss: 13.4001\n",
      "Epoch 2216/3000\n",
      "104/104 [==============================] - 18s 168ms/step - d_loss: -0.0277 - g_loss: 13.7108\n",
      "Epoch 2217/3000\n",
      "104/104 [==============================] - 30s 273ms/step - d_loss: -0.0342 - g_loss: 13.8068\n",
      "Epoch 2218/3000\n",
      "104/104 [==============================] - 28s 253ms/step - d_loss: -0.0400 - g_loss: 13.8647\n",
      "Epoch 2219/3000\n",
      "104/104 [==============================] - 27s 243ms/step - d_loss: -0.0277 - g_loss: 13.5427\n",
      "Epoch 2220/3000\n",
      "104/104 [==============================] - 27s 243ms/step - d_loss: 0.1154 - g_loss: 12.6297\n",
      "Epoch 2221/3000\n",
      "104/104 [==============================] - 27s 242ms/step - d_loss: 0.0403 - g_loss: 12.7200\n",
      "Epoch 2222/3000\n",
      "104/104 [==============================] - 28s 245ms/step - d_loss: 3.2100e-04 - g_loss: 12.9923\n",
      "Epoch 2223/3000\n",
      "104/104 [==============================] - 29s 259ms/step - d_loss: -0.0273 - g_loss: 13.6367\n",
      "Epoch 2224/3000\n",
      "104/104 [==============================] - 31s 277ms/step - d_loss: -0.0176 - g_loss: 13.5420\n",
      "Epoch 2225/3000\n",
      "104/104 [==============================] - 28s 248ms/step - d_loss: -0.0074 - g_loss: 13.3608\n",
      "Epoch 2226/3000\n",
      "104/104 [==============================] - 28s 251ms/step - d_loss: -0.0298 - g_loss: 13.8828\n",
      "Epoch 2227/3000\n",
      "104/104 [==============================] - 29s 262ms/step - d_loss: -0.0399 - g_loss: 14.1322\n",
      "Epoch 2228/3000\n",
      "104/104 [==============================] - 30s 268ms/step - d_loss: -0.0227 - g_loss: 13.7109\n",
      "Epoch 2229/3000\n",
      "104/104 [==============================] - 31s 271ms/step - d_loss: -0.0104 - g_loss: 13.6594\n",
      "Epoch 2230/3000\n",
      "104/104 [==============================] - 28s 250ms/step - d_loss: -0.0178 - g_loss: 13.3857\n",
      "Epoch 2231/3000\n",
      "104/104 [==============================] - 28s 254ms/step - d_loss: -0.0215 - g_loss: 13.8585\n",
      "Epoch 2232/3000\n",
      "104/104 [==============================] - 28s 245ms/step - d_loss: -0.0212 - g_loss: 13.7653\n",
      "Epoch 2233/3000\n",
      "104/104 [==============================] - 28s 251ms/step - d_loss: -0.0192 - g_loss: 13.5348\n",
      "Epoch 2234/3000\n",
      "104/104 [==============================] - 29s 256ms/step - d_loss: -0.0338 - g_loss: 13.8974\n",
      "Epoch 2235/3000\n",
      "104/104 [==============================] - 243s 1s/step - d_loss: -0.0277 - g_loss: 13.9960\n",
      "Epoch 2236/3000\n",
      "104/104 [==============================] - 24s 205ms/step - d_loss: 0.0353 - g_loss: 13.3317\n",
      "Epoch 2237/3000\n",
      "104/104 [==============================] - 23s 202ms/step - d_loss: 0.0206 - g_loss: 13.2024\n",
      "Epoch 2238/3000\n",
      "104/104 [==============================] - 26s 221ms/step - d_loss: 0.0115 - g_loss: 13.1557\n",
      "Epoch 2239/3000\n",
      "104/104 [==============================] - 28s 243ms/step - d_loss: -0.0385 - g_loss: 13.9795\n",
      "Epoch 2240/3000\n",
      "104/104 [==============================] - 27s 237ms/step - d_loss: -0.0125 - g_loss: 13.6395\n",
      "Epoch 2241/3000\n",
      "104/104 [==============================] - 18s 159ms/step - d_loss: -0.0086 - g_loss: 13.4154\n",
      "Epoch 2242/3000\n",
      "104/104 [==============================] - 9s 82ms/step - d_loss: -0.0065 - g_loss: 13.4862\n",
      "Epoch 2243/3000\n",
      "104/104 [==============================] - 9s 82ms/step - d_loss: -0.0230 - g_loss: 13.8517\n",
      "Epoch 2244/3000\n",
      "104/104 [==============================] - 9s 83ms/step - d_loss: -0.0131 - g_loss: 13.9833\n",
      "Epoch 2245/3000\n",
      "104/104 [==============================] - 9s 82ms/step - d_loss: 0.0068 - g_loss: 13.5826\n",
      "Epoch 2246/3000\n",
      "104/104 [==============================] - 9s 83ms/step - d_loss: 0.0067 - g_loss: 13.6916\n",
      "Epoch 2247/3000\n",
      "104/104 [==============================] - 9s 82ms/step - d_loss: 0.0059 - g_loss: 13.3880\n",
      "Epoch 2248/3000\n",
      "104/104 [==============================] - 9s 82ms/step - d_loss: -0.0051 - g_loss: 13.5564\n",
      "Epoch 2249/3000\n",
      "104/104 [==============================] - 9s 85ms/step - d_loss: -0.0189 - g_loss: 13.8507\n",
      "Epoch 2250/3000\n",
      "104/104 [==============================] - 13s 124ms/step - d_loss: -0.0232 - g_loss: 13.9252\n",
      "Epoch 2251/3000\n",
      "104/104 [==============================] - 13s 118ms/step - d_loss: -0.0353 - g_loss: 14.1184\n",
      "Epoch 2252/3000\n",
      "104/104 [==============================] - 13s 124ms/step - d_loss: 0.0052 - g_loss: 13.5052\n",
      "Epoch 2253/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0240 - g_loss: 13.5593\n",
      "Epoch 2254/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0014 - g_loss: 13.7210\n",
      "Epoch 2255/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0349 - g_loss: 13.9643\n",
      "Epoch 2256/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: -0.0305 - g_loss: 13.9234\n",
      "Epoch 2257/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0074 - g_loss: 13.7881\n",
      "Epoch 2258/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0131 - g_loss: 13.7409\n",
      "Epoch 2259/3000\n",
      "104/104 [==============================] - 14s 135ms/step - d_loss: -0.0180 - g_loss: 14.0227\n",
      "Epoch 2260/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: -0.0140 - g_loss: 13.9121\n",
      "Epoch 2261/3000\n",
      "104/104 [==============================] - 16s 143ms/step - d_loss: 0.0233 - g_loss: 13.4977\n",
      "Epoch 2262/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: 0.1505 - g_loss: 12.4626\n",
      "Epoch 2263/3000\n",
      "104/104 [==============================] - 14s 135ms/step - d_loss: 0.0284 - g_loss: 13.4236\n",
      "Epoch 2264/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: 4.2144e-04 - g_loss: 13.5328\n",
      "Epoch 2265/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: 0.0164 - g_loss: 13.3220\n",
      "Epoch 2266/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0041 - g_loss: 13.7384\n",
      "Epoch 2267/3000\n",
      "104/104 [==============================] - 15s 139ms/step - d_loss: -0.0468 - g_loss: 14.3250\n",
      "Epoch 2268/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0077 - g_loss: 14.0483\n",
      "Epoch 2269/3000\n",
      "104/104 [==============================] - 14s 134ms/step - d_loss: -0.0484 - g_loss: 14.1258\n",
      "Epoch 2270/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0409 - g_loss: 14.3272\n",
      "Epoch 2271/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0161 - g_loss: 14.1102\n",
      "Epoch 2272/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: 0.0177 - g_loss: 13.7961\n",
      "Epoch 2273/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0293 - g_loss: 14.1028\n",
      "Epoch 2274/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0223 - g_loss: 14.1980\n",
      "Epoch 2275/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0243 - g_loss: 14.1913\n",
      "Epoch 2276/3000\n",
      "104/104 [==============================] - 15s 135ms/step - d_loss: 0.0241 - g_loss: 13.9254\n",
      "Epoch 2277/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: 0.0255 - g_loss: 13.1960\n",
      "Epoch 2278/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: 0.0165 - g_loss: 13.7559\n",
      "Epoch 2279/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0077 - g_loss: 14.0346\n",
      "Epoch 2280/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0231 - g_loss: 13.7542\n",
      "Epoch 2281/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0206 - g_loss: 14.0011\n",
      "Epoch 2282/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0322 - g_loss: 14.4645\n",
      "Epoch 2283/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0369 - g_loss: 14.4724\n",
      "Epoch 2284/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0281 - g_loss: 14.3002\n",
      "Epoch 2285/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: 0.0220 - g_loss: 13.8257\n",
      "Epoch 2286/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: 0.0068 - g_loss: 13.7772\n",
      "Epoch 2287/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0248 - g_loss: 13.9955\n",
      "Epoch 2288/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0194 - g_loss: 14.1350\n",
      "Epoch 2289/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: 0.0069 - g_loss: 13.6972\n",
      "Epoch 2290/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0515 - g_loss: 14.7043\n",
      "Epoch 2291/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0346 - g_loss: 14.5331\n",
      "Epoch 2292/3000\n",
      "104/104 [==============================] - 15s 136ms/step - d_loss: -0.0153 - g_loss: 14.0289\n",
      "Epoch 2293/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0382 - g_loss: 14.7612\n",
      "Epoch 2294/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: -0.0558 - g_loss: 15.0224\n",
      "Epoch 2295/3000\n",
      "104/104 [==============================] - 15s 136ms/step - d_loss: -0.0161 - g_loss: 14.1659\n",
      "Epoch 2296/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0131 - g_loss: 14.3086\n",
      "Epoch 2297/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: 3.4489e-04 - g_loss: 13.9674\n",
      "Epoch 2298/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0209 - g_loss: 14.3879\n",
      "Epoch 2299/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: 0.0201 - g_loss: 14.0759\n",
      "Epoch 2300/3000\n",
      "104/104 [==============================] - 14s 129ms/step - d_loss: 0.1875 - g_loss: 12.6695\n",
      "Epoch 2301/3000\n",
      "104/104 [==============================] - 14s 134ms/step - d_loss: -0.0188 - g_loss: 13.7910\n",
      "Epoch 2302/3000\n",
      "104/104 [==============================] - 14s 135ms/step - d_loss: 0.0035 - g_loss: 14.0258\n",
      "Epoch 2303/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: 0.0185 - g_loss: 13.9812\n",
      "Epoch 2304/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0178 - g_loss: 14.1508\n",
      "Epoch 2305/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0350 - g_loss: 14.5200\n",
      "Epoch 2306/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0285 - g_loss: 14.3955\n",
      "Epoch 2307/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: -0.0306 - g_loss: 14.5470\n",
      "Epoch 2308/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0463 - g_loss: 15.0171\n",
      "Epoch 2309/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0324 - g_loss: 14.3337\n",
      "Epoch 2310/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: 0.0400 - g_loss: 13.6672\n",
      "Epoch 2311/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0038 - g_loss: 13.8356\n",
      "Epoch 2312/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0414 - g_loss: 14.7446\n",
      "Epoch 2313/3000\n",
      "104/104 [==============================] - 14s 129ms/step - d_loss: -0.0131 - g_loss: 14.4697\n",
      "Epoch 2314/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0151 - g_loss: 14.5573\n",
      "Epoch 2315/3000\n",
      "104/104 [==============================] - 14s 129ms/step - d_loss: -0.0190 - g_loss: 14.2533\n",
      "Epoch 2316/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0272 - g_loss: 14.6968\n",
      "Epoch 2317/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: -0.0384 - g_loss: 14.8111\n",
      "Epoch 2318/3000\n",
      "104/104 [==============================] - 14s 135ms/step - d_loss: -0.0025 - g_loss: 14.5020\n",
      "Epoch 2319/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0280 - g_loss: 14.8485\n",
      "Epoch 2320/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0238 - g_loss: 14.6543\n",
      "Epoch 2321/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0451 - g_loss: 14.7844\n",
      "Epoch 2322/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0013 - g_loss: 14.2156\n",
      "Epoch 2323/3000\n",
      "104/104 [==============================] - 14s 136ms/step - d_loss: -0.0015 - g_loss: 14.5504\n",
      "Epoch 2324/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: 0.0080 - g_loss: 14.2852\n",
      "Epoch 2325/3000\n",
      "104/104 [==============================] - 14s 134ms/step - d_loss: -0.0460 - g_loss: 15.0228\n",
      "Epoch 2326/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0012 - g_loss: 14.1939\n",
      "Epoch 2327/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0234 - g_loss: 14.9414\n",
      "Epoch 2328/3000\n",
      "104/104 [==============================] - 14s 135ms/step - d_loss: -6.5157e-04 - g_loss: 14.7063\n",
      "Epoch 2329/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0405 - g_loss: 14.8844\n",
      "Epoch 2330/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: 0.0352 - g_loss: 14.0129\n",
      "Epoch 2331/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0132 - g_loss: 14.3389\n",
      "Epoch 2332/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0295 - g_loss: 14.5725\n",
      "Epoch 2333/3000\n",
      "104/104 [==============================] - 14s 129ms/step - d_loss: 0.0188 - g_loss: 13.9227\n",
      "Epoch 2334/3000\n",
      "104/104 [==============================] - 14s 129ms/step - d_loss: 0.0211 - g_loss: 14.0016\n",
      "Epoch 2335/3000\n",
      "104/104 [==============================] - 14s 129ms/step - d_loss: -0.0217 - g_loss: 14.7289\n",
      "Epoch 2336/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: 4.4570e-04 - g_loss: 14.4441\n",
      "Epoch 2337/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0501 - g_loss: 15.1366\n",
      "Epoch 2338/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0711 - g_loss: 15.4314\n",
      "Epoch 2339/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0290 - g_loss: 14.7309\n",
      "Epoch 2340/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0189 - g_loss: 14.9552\n",
      "Epoch 2341/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: 0.0650 - g_loss: 13.9861\n",
      "Epoch 2342/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: 0.0278 - g_loss: 13.9497\n",
      "Epoch 2343/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: 0.0013 - g_loss: 14.5766\n",
      "Epoch 2344/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0052 - g_loss: 14.2496\n",
      "Epoch 2345/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0338 - g_loss: 14.5981\n",
      "Epoch 2346/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: -0.0417 - g_loss: 14.9028\n",
      "Epoch 2347/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: 0.0170 - g_loss: 14.1122\n",
      "Epoch 2348/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0107 - g_loss: 14.6196\n",
      "Epoch 2349/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0364 - g_loss: 14.8331\n",
      "Epoch 2350/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0531 - g_loss: 15.4494\n",
      "Epoch 2351/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0261 - g_loss: 14.8587\n",
      "Epoch 2352/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: 0.0502 - g_loss: 13.9142\n",
      "Epoch 2353/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: 0.0150 - g_loss: 14.2113\n",
      "Epoch 2354/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: 0.0097 - g_loss: 14.3441\n",
      "Epoch 2355/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0277 - g_loss: 15.0264\n",
      "Epoch 2356/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0686 - g_loss: 15.5391\n",
      "Epoch 2357/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: -0.0417 - g_loss: 15.5084\n",
      "Epoch 2358/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0489 - g_loss: 15.2382\n",
      "Epoch 2359/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: -0.0488 - g_loss: 15.2744\n",
      "Epoch 2360/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: 0.0464 - g_loss: 14.2861\n",
      "Epoch 2361/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: -0.0260 - g_loss: 14.8353\n",
      "Epoch 2362/3000\n",
      "104/104 [==============================] - 14s 129ms/step - d_loss: -0.0163 - g_loss: 14.8157\n",
      "Epoch 2363/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0419 - g_loss: 15.2929\n",
      "Epoch 2364/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: -0.0569 - g_loss: 15.3651\n",
      "Epoch 2365/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0112 - g_loss: 14.8182\n",
      "Epoch 2366/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0559 - g_loss: 15.7273\n",
      "Epoch 2367/3000\n",
      "104/104 [==============================] - 14s 129ms/step - d_loss: -0.0199 - g_loss: 15.2249\n",
      "Epoch 2368/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0205 - g_loss: 15.0681\n",
      "Epoch 2369/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0356 - g_loss: 15.4314\n",
      "Epoch 2370/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: 0.0352 - g_loss: 14.4338\n",
      "Epoch 2371/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0376 - g_loss: 15.2709\n",
      "Epoch 2372/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: 0.0280 - g_loss: 14.6271\n",
      "Epoch 2373/3000\n",
      "104/104 [==============================] - 15s 137ms/step - d_loss: 7.4730e-04 - g_loss: 14.6940\n",
      "Epoch 2374/3000\n",
      "104/104 [==============================] - 17s 156ms/step - d_loss: 0.0066 - g_loss: 14.8903\n",
      "Epoch 2375/3000\n",
      "104/104 [==============================] - 15s 144ms/step - d_loss: -0.0091 - g_loss: 14.5689\n",
      "Epoch 2376/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0363 - g_loss: 15.1290\n",
      "Epoch 2377/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0612 - g_loss: 15.4319\n",
      "Epoch 2378/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0792 - g_loss: 16.1739\n",
      "Epoch 2379/3000\n",
      "104/104 [==============================] - 15s 137ms/step - d_loss: -0.0442 - g_loss: 15.5653\n",
      "Epoch 2380/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0079 - g_loss: 14.8430\n",
      "Epoch 2381/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0105 - g_loss: 15.2372\n",
      "Epoch 2382/3000\n",
      "104/104 [==============================] - 15s 136ms/step - d_loss: 0.0300 - g_loss: 14.3599\n",
      "Epoch 2383/3000\n",
      "104/104 [==============================] - 15s 138ms/step - d_loss: -0.0359 - g_loss: 15.3590\n",
      "Epoch 2384/3000\n",
      "104/104 [==============================] - 15s 142ms/step - d_loss: -0.0376 - g_loss: 15.2829\n",
      "Epoch 2385/3000\n",
      "104/104 [==============================] - 16s 149ms/step - d_loss: -0.0566 - g_loss: 15.7657\n",
      "Epoch 2386/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0465 - g_loss: 16.2250\n",
      "Epoch 2387/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0043 - g_loss: 15.3724\n",
      "Epoch 2388/3000\n",
      "104/104 [==============================] - 14s 129ms/step - d_loss: -0.0010 - g_loss: 14.9228\n",
      "Epoch 2389/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0493 - g_loss: 15.5499\n",
      "Epoch 2390/3000\n",
      "104/104 [==============================] - 15s 136ms/step - d_loss: -0.0264 - g_loss: 15.4029\n",
      "Epoch 2391/3000\n",
      "104/104 [==============================] - 15s 137ms/step - d_loss: -0.0046 - g_loss: 14.9806\n",
      "Epoch 2392/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0062 - g_loss: 14.7860\n",
      "Epoch 2393/3000\n",
      "104/104 [==============================] - 15s 139ms/step - d_loss: -0.0169 - g_loss: 15.1924\n",
      "Epoch 2394/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0193 - g_loss: 15.5066\n",
      "Epoch 2395/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0389 - g_loss: 15.6010\n",
      "Epoch 2396/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0391 - g_loss: 15.5956\n",
      "Epoch 2397/3000\n",
      "104/104 [==============================] - 14s 134ms/step - d_loss: -0.0122 - g_loss: 15.1974\n",
      "Epoch 2398/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: 0.0019 - g_loss: 14.9150\n",
      "Epoch 2399/3000\n",
      "104/104 [==============================] - 16s 148ms/step - d_loss: -0.0353 - g_loss: 15.5179\n",
      "Epoch 2400/3000\n",
      "104/104 [==============================] - 16s 146ms/step - d_loss: -0.0514 - g_loss: 16.0920\n",
      "Epoch 2401/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: 0.0048 - g_loss: 15.0712\n",
      "Epoch 2402/3000\n",
      "104/104 [==============================] - 14s 134ms/step - d_loss: 0.0319 - g_loss: 14.6912\n",
      "Epoch 2403/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0264 - g_loss: 15.2069\n",
      "Epoch 2404/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0246 - g_loss: 15.5385\n",
      "Epoch 2405/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: 0.0388 - g_loss: 14.7208\n",
      "Epoch 2406/3000\n",
      "104/104 [==============================] - 14s 134ms/step - d_loss: -0.0425 - g_loss: 15.4500\n",
      "Epoch 2407/3000\n",
      "104/104 [==============================] - 15s 139ms/step - d_loss: -0.0498 - g_loss: 15.6365\n",
      "Epoch 2408/3000\n",
      "104/104 [==============================] - 14s 134ms/step - d_loss: -0.0569 - g_loss: 16.1510\n",
      "Epoch 2409/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0721 - g_loss: 16.3974\n",
      "Epoch 2410/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: 0.0186 - g_loss: 14.9553\n",
      "Epoch 2411/3000\n",
      "104/104 [==============================] - 14s 134ms/step - d_loss: -0.0607 - g_loss: 16.0467\n",
      "Epoch 2412/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0493 - g_loss: 16.1400\n",
      "Epoch 2413/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0045 - g_loss: 15.7130\n",
      "Epoch 2414/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: 0.0246 - g_loss: 15.1442\n",
      "Epoch 2415/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: 0.0211 - g_loss: 14.6227\n",
      "Epoch 2416/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: 0.0057 - g_loss: 15.2970\n",
      "Epoch 2417/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0417 - g_loss: 15.7430\n",
      "Epoch 2418/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: -0.0720 - g_loss: 16.7540\n",
      "Epoch 2419/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: -0.0744 - g_loss: 16.2304\n",
      "Epoch 2420/3000\n",
      "104/104 [==============================] - 14s 134ms/step - d_loss: -0.0077 - g_loss: 15.3083\n",
      "Epoch 2421/3000\n",
      "104/104 [==============================] - 14s 134ms/step - d_loss: -0.0117 - g_loss: 15.1278\n",
      "Epoch 2422/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: -0.0186 - g_loss: 15.6020\n",
      "Epoch 2423/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: 0.0293 - g_loss: 15.0241\n",
      "Epoch 2424/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: 0.0224 - g_loss: 15.2358\n",
      "Epoch 2425/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: -0.0056 - g_loss: 15.2477\n",
      "Epoch 2426/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0345 - g_loss: 15.8986\n",
      "Epoch 2427/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: -0.0539 - g_loss: 16.0738\n",
      "Epoch 2428/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0323 - g_loss: 15.8898\n",
      "Epoch 2429/3000\n",
      "104/104 [==============================] - 14s 129ms/step - d_loss: -0.0469 - g_loss: 16.0624\n",
      "Epoch 2430/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0590 - g_loss: 16.2337\n",
      "Epoch 2431/3000\n",
      "104/104 [==============================] - 15s 137ms/step - d_loss: -0.0144 - g_loss: 15.6820\n",
      "Epoch 2432/3000\n",
      "104/104 [==============================] - 16s 146ms/step - d_loss: -0.0322 - g_loss: 16.0632\n",
      "Epoch 2433/3000\n",
      "104/104 [==============================] - 15s 137ms/step - d_loss: -0.0233 - g_loss: 15.6425\n",
      "Epoch 2434/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0342 - g_loss: 16.0923\n",
      "Epoch 2435/3000\n",
      "104/104 [==============================] - 15s 140ms/step - d_loss: 0.0092 - g_loss: 15.4992\n",
      "Epoch 2436/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: 0.0157 - g_loss: 15.2990\n",
      "Epoch 2437/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0455 - g_loss: 15.7444\n",
      "Epoch 2438/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: -0.0124 - g_loss: 16.1091\n",
      "Epoch 2439/3000\n",
      "104/104 [==============================] - 14s 134ms/step - d_loss: -0.0146 - g_loss: 15.2811\n",
      "Epoch 2440/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0487 - g_loss: 16.1893\n",
      "Epoch 2441/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0526 - g_loss: 16.3373\n",
      "Epoch 2442/3000\n",
      "104/104 [==============================] - 14s 134ms/step - d_loss: -3.1708e-04 - g_loss: 15.6090\n",
      "Epoch 2443/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0543 - g_loss: 16.1348\n",
      "Epoch 2444/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0479 - g_loss: 16.1261\n",
      "Epoch 2445/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: 0.0100 - g_loss: 15.7269\n",
      "Epoch 2446/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: 0.0556 - g_loss: 15.3865\n",
      "Epoch 2447/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -8.1142e-04 - g_loss: 15.3198\n",
      "Epoch 2448/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0392 - g_loss: 16.1213\n",
      "Epoch 2449/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0425 - g_loss: 16.5131\n",
      "Epoch 2450/3000\n",
      "104/104 [==============================] - 14s 129ms/step - d_loss: -0.0453 - g_loss: 16.3307\n",
      "Epoch 2451/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0240 - g_loss: 16.2414\n",
      "Epoch 2452/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0128 - g_loss: 15.8873\n",
      "Epoch 2453/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: -0.0394 - g_loss: 16.4554\n",
      "Epoch 2454/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0247 - g_loss: 15.9753\n",
      "Epoch 2455/3000\n",
      "104/104 [==============================] - 17s 157ms/step - d_loss: -0.0268 - g_loss: 16.0120\n",
      "Epoch 2456/3000\n",
      "104/104 [==============================] - 16s 146ms/step - d_loss: 0.0441 - g_loss: 14.9826\n",
      "Epoch 2457/3000\n",
      "104/104 [==============================] - 15s 141ms/step - d_loss: -0.0032 - g_loss: 15.9129\n",
      "Epoch 2458/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: -7.1984e-05 - g_loss: 16.0848\n",
      "Epoch 2459/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: -0.0121 - g_loss: 15.7151\n",
      "Epoch 2460/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: -0.0188 - g_loss: 15.9830\n",
      "Epoch 2461/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0445 - g_loss: 16.6659\n",
      "Epoch 2462/3000\n",
      "104/104 [==============================] - 14s 134ms/step - d_loss: -0.0548 - g_loss: 16.6716\n",
      "Epoch 2463/3000\n",
      "104/104 [==============================] - 15s 136ms/step - d_loss: -0.0031 - g_loss: 15.9878\n",
      "Epoch 2464/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: -0.0396 - g_loss: 16.2106\n",
      "Epoch 2465/3000\n",
      "104/104 [==============================] - 14s 134ms/step - d_loss: -0.0341 - g_loss: 16.1326\n",
      "Epoch 2466/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0573 - g_loss: 16.4450\n",
      "Epoch 2467/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0111 - g_loss: 16.3370\n",
      "Epoch 2468/3000\n",
      "104/104 [==============================] - 15s 138ms/step - d_loss: -0.0431 - g_loss: 16.4214\n",
      "Epoch 2469/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: -0.0425 - g_loss: 16.4887\n",
      "Epoch 2470/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: 0.0052 - g_loss: 15.6793\n",
      "Epoch 2471/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0582 - g_loss: 16.7226\n",
      "Epoch 2472/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0285 - g_loss: 16.0884\n",
      "Epoch 2473/3000\n",
      "104/104 [==============================] - 14s 134ms/step - d_loss: -0.0034 - g_loss: 16.0758\n",
      "Epoch 2474/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0277 - g_loss: 16.1269\n",
      "Epoch 2475/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0160 - g_loss: 16.2967\n",
      "Epoch 2476/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0336 - g_loss: 16.5315\n",
      "Epoch 2477/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0348 - g_loss: 16.6519\n",
      "Epoch 2478/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: 0.0469 - g_loss: 15.8768\n",
      "Epoch 2479/3000\n",
      "104/104 [==============================] - 14s 135ms/step - d_loss: -0.0111 - g_loss: 16.0321\n",
      "Epoch 2480/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0595 - g_loss: 16.7270\n",
      "Epoch 2481/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0413 - g_loss: 16.3253\n",
      "Epoch 2482/3000\n",
      "104/104 [==============================] - 15s 140ms/step - d_loss: -0.0372 - g_loss: 16.5848\n",
      "Epoch 2483/3000\n",
      "104/104 [==============================] - 15s 141ms/step - d_loss: -0.0575 - g_loss: 16.9359\n",
      "Epoch 2484/3000\n",
      "104/104 [==============================] - 16s 151ms/step - d_loss: -0.0126 - g_loss: 16.1449\n",
      "Epoch 2485/3000\n",
      "104/104 [==============================] - 15s 139ms/step - d_loss: -0.0454 - g_loss: 16.7422\n",
      "Epoch 2486/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0491 - g_loss: 16.8003\n",
      "Epoch 2487/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: -0.0349 - g_loss: 16.7889\n",
      "Epoch 2488/3000\n",
      "104/104 [==============================] - 14s 134ms/step - d_loss: 0.0174 - g_loss: 15.8641\n",
      "Epoch 2489/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0286 - g_loss: 16.6377\n",
      "Epoch 2490/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: 0.0535 - g_loss: 15.6420\n",
      "Epoch 2491/3000\n",
      "104/104 [==============================] - 14s 134ms/step - d_loss: -0.0155 - g_loss: 16.5243\n",
      "Epoch 2492/3000\n",
      "104/104 [==============================] - 14s 129ms/step - d_loss: -0.0245 - g_loss: 16.3735\n",
      "Epoch 2493/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: 0.0133 - g_loss: 15.8687\n",
      "Epoch 2494/3000\n",
      "104/104 [==============================] - 15s 137ms/step - d_loss: -0.0471 - g_loss: 16.6140\n",
      "Epoch 2495/3000\n",
      "104/104 [==============================] - 16s 149ms/step - d_loss: -0.0737 - g_loss: 17.2529\n",
      "Epoch 2496/3000\n",
      "104/104 [==============================] - 16s 154ms/step - d_loss: -0.0521 - g_loss: 16.9977\n",
      "Epoch 2497/3000\n",
      "104/104 [==============================] - 16s 150ms/step - d_loss: -0.0487 - g_loss: 16.8250\n",
      "Epoch 2498/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: -0.0567 - g_loss: 17.0003\n",
      "Epoch 2499/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0402 - g_loss: 17.0157\n",
      "Epoch 2500/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0296 - g_loss: 16.8263\n",
      "Epoch 2501/3000\n",
      "104/104 [==============================] - 14s 135ms/step - d_loss: -0.0141 - g_loss: 16.2939\n",
      "Epoch 2502/3000\n",
      "104/104 [==============================] - 14s 135ms/step - d_loss: -0.0482 - g_loss: 16.8447\n",
      "Epoch 2503/3000\n",
      "104/104 [==============================] - 14s 135ms/step - d_loss: -0.0167 - g_loss: 16.4461\n",
      "Epoch 2504/3000\n",
      "104/104 [==============================] - 14s 129ms/step - d_loss: 0.0042 - g_loss: 16.3039\n",
      "Epoch 2505/3000\n",
      "104/104 [==============================] - 14s 134ms/step - d_loss: -0.0361 - g_loss: 16.3985\n",
      "Epoch 2506/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0379 - g_loss: 16.7882\n",
      "Epoch 2507/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: -0.0116 - g_loss: 16.1659\n",
      "Epoch 2508/3000\n",
      "104/104 [==============================] - 14s 134ms/step - d_loss: -0.0430 - g_loss: 16.9789\n",
      "Epoch 2509/3000\n",
      "104/104 [==============================] - 16s 153ms/step - d_loss: -0.0526 - g_loss: 17.2056\n",
      "Epoch 2510/3000\n",
      "104/104 [==============================] - 15s 143ms/step - d_loss: 0.0102 - g_loss: 16.3484\n",
      "Epoch 2511/3000\n",
      "104/104 [==============================] - 16s 150ms/step - d_loss: -0.0045 - g_loss: 16.2587\n",
      "Epoch 2512/3000\n",
      "104/104 [==============================] - 15s 136ms/step - d_loss: 0.0276 - g_loss: 16.1568\n",
      "Epoch 2513/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0495 - g_loss: 17.0792\n",
      "Epoch 2514/3000\n",
      "104/104 [==============================] - 15s 136ms/step - d_loss: -0.0390 - g_loss: 16.6680\n",
      "Epoch 2515/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0352 - g_loss: 16.4257\n",
      "Epoch 2516/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0282 - g_loss: 16.7758\n",
      "Epoch 2517/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0425 - g_loss: 17.0117\n",
      "Epoch 2518/3000\n",
      "104/104 [==============================] - 14s 134ms/step - d_loss: -0.0612 - g_loss: 17.1886\n",
      "Epoch 2519/3000\n",
      "104/104 [==============================] - 15s 142ms/step - d_loss: -0.0548 - g_loss: 17.2685\n",
      "Epoch 2520/3000\n",
      "104/104 [==============================] - 15s 142ms/step - d_loss: -0.0192 - g_loss: 16.4895\n",
      "Epoch 2521/3000\n",
      "104/104 [==============================] - 15s 140ms/step - d_loss: 0.0138 - g_loss: 16.1788\n",
      "Epoch 2522/3000\n",
      "104/104 [==============================] - 14s 127ms/step - d_loss: -0.0087 - g_loss: 16.4158\n",
      "Epoch 2523/3000\n",
      "104/104 [==============================] - 15s 139ms/step - d_loss: 0.0121 - g_loss: 15.7576\n",
      "Epoch 2524/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0315 - g_loss: 16.5955\n",
      "Epoch 2525/3000\n",
      "104/104 [==============================] - 16s 144ms/step - d_loss: -0.0566 - g_loss: 17.1229\n",
      "Epoch 2526/3000\n",
      "104/104 [==============================] - 15s 144ms/step - d_loss: -0.0728 - g_loss: 17.4779\n",
      "Epoch 2527/3000\n",
      "104/104 [==============================] - 16s 146ms/step - d_loss: -0.0263 - g_loss: 17.0130\n",
      "Epoch 2528/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0711 - g_loss: 17.7618\n",
      "Epoch 2529/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0334 - g_loss: 17.0835\n",
      "Epoch 2530/3000\n",
      "104/104 [==============================] - 15s 139ms/step - d_loss: 0.0110 - g_loss: 16.2547\n",
      "Epoch 2531/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: 0.0644 - g_loss: 16.0243\n",
      "Epoch 2532/3000\n",
      "104/104 [==============================] - 14s 129ms/step - d_loss: -0.0190 - g_loss: 16.5451\n",
      "Epoch 2533/3000\n",
      "104/104 [==============================] - 15s 135ms/step - d_loss: 0.0048 - g_loss: 16.5305\n",
      "Epoch 2534/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0464 - g_loss: 17.0791\n",
      "Epoch 2535/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: -0.0093 - g_loss: 16.3298\n",
      "Epoch 2536/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: 0.0217 - g_loss: 16.3325\n",
      "Epoch 2537/3000\n",
      "104/104 [==============================] - 15s 143ms/step - d_loss: -0.0048 - g_loss: 16.4005\n",
      "Epoch 2538/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: -0.0429 - g_loss: 16.8837\n",
      "Epoch 2539/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0331 - g_loss: 16.8542\n",
      "Epoch 2540/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: -0.0168 - g_loss: 16.9516\n",
      "Epoch 2541/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0474 - g_loss: 17.1775\n",
      "Epoch 2542/3000\n",
      "104/104 [==============================] - 14s 135ms/step - d_loss: -0.0528 - g_loss: 17.1648\n",
      "Epoch 2543/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0185 - g_loss: 16.6211\n",
      "Epoch 2544/3000\n",
      "104/104 [==============================] - 16s 145ms/step - d_loss: -0.0508 - g_loss: 17.0929\n",
      "Epoch 2545/3000\n",
      "104/104 [==============================] - 15s 142ms/step - d_loss: -0.0816 - g_loss: 17.9690\n",
      "Epoch 2546/3000\n",
      "104/104 [==============================] - 15s 138ms/step - d_loss: -0.0501 - g_loss: 17.1040\n",
      "Epoch 2547/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0352 - g_loss: 17.1831\n",
      "Epoch 2548/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0508 - g_loss: 17.1623\n",
      "Epoch 2549/3000\n",
      "104/104 [==============================] - 15s 136ms/step - d_loss: -0.0477 - g_loss: 17.3332\n",
      "Epoch 2550/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0027 - g_loss: 16.6165\n",
      "Epoch 2551/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0013 - g_loss: 16.7322\n",
      "Epoch 2552/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0216 - g_loss: 17.5109\n",
      "Epoch 2553/3000\n",
      "104/104 [==============================] - 15s 139ms/step - d_loss: -0.0512 - g_loss: 17.5578\n",
      "Epoch 2554/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0836 - g_loss: 18.0595\n",
      "Epoch 2555/3000\n",
      "104/104 [==============================] - 15s 138ms/step - d_loss: -0.0532 - g_loss: 17.7594\n",
      "Epoch 2556/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0061 - g_loss: 16.9774\n",
      "Epoch 2557/3000\n",
      "104/104 [==============================] - 15s 140ms/step - d_loss: -0.0046 - g_loss: 16.8098\n",
      "Epoch 2558/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0349 - g_loss: 17.4568\n",
      "Epoch 2559/3000\n",
      "104/104 [==============================] - 15s 133ms/step - d_loss: -0.0623 - g_loss: 17.7669\n",
      "Epoch 2560/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0459 - g_loss: 17.6336\n",
      "Epoch 2561/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: 0.0544 - g_loss: 16.3434\n",
      "Epoch 2562/3000\n",
      "104/104 [==============================] - 15s 137ms/step - d_loss: 0.0041 - g_loss: 16.5553\n",
      "Epoch 2563/3000\n",
      "104/104 [==============================] - 14s 129ms/step - d_loss: 0.0012 - g_loss: 16.3946\n",
      "Epoch 2564/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0238 - g_loss: 17.0251\n",
      "Epoch 2565/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: 0.0021 - g_loss: 16.5432\n",
      "Epoch 2566/3000\n",
      "104/104 [==============================] - 16s 146ms/step - d_loss: -0.0196 - g_loss: 17.1143\n",
      "Epoch 2567/3000\n",
      "104/104 [==============================] - 16s 150ms/step - d_loss: -0.0804 - g_loss: 18.2032\n",
      "Epoch 2568/3000\n",
      "104/104 [==============================] - 16s 149ms/step - d_loss: -0.0671 - g_loss: 17.8764\n",
      "Epoch 2569/3000\n",
      "104/104 [==============================] - 17s 157ms/step - d_loss: -0.0258 - g_loss: 17.5572\n",
      "Epoch 2570/3000\n",
      "104/104 [==============================] - 16s 151ms/step - d_loss: -0.0603 - g_loss: 18.1069\n",
      "Epoch 2571/3000\n",
      "104/104 [==============================] - 15s 138ms/step - d_loss: -0.0513 - g_loss: 18.0525\n",
      "Epoch 2572/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0802 - g_loss: 18.6036\n",
      "Epoch 2573/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0532 - g_loss: 17.8755\n",
      "Epoch 2574/3000\n",
      "104/104 [==============================] - 14s 134ms/step - d_loss: -0.0848 - g_loss: 18.1699\n",
      "Epoch 2575/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: -0.0661 - g_loss: 18.0960\n",
      "Epoch 2576/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: 0.0178 - g_loss: 16.9422\n",
      "Epoch 2577/3000\n",
      "104/104 [==============================] - 15s 137ms/step - d_loss: -0.0379 - g_loss: 17.3070\n",
      "Epoch 2578/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0224 - g_loss: 17.3635\n",
      "Epoch 2579/3000\n",
      "104/104 [==============================] - 14s 134ms/step - d_loss: -0.0641 - g_loss: 17.7035\n",
      "Epoch 2580/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0250 - g_loss: 17.2629\n",
      "Epoch 2581/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0089 - g_loss: 16.9406\n",
      "Epoch 2582/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0121 - g_loss: 16.9249\n",
      "Epoch 2583/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0125 - g_loss: 17.0975\n",
      "Epoch 2584/3000\n",
      "104/104 [==============================] - 15s 143ms/step - d_loss: -0.0078 - g_loss: 17.0584\n",
      "Epoch 2585/3000\n",
      "104/104 [==============================] - 16s 146ms/step - d_loss: 0.0466 - g_loss: 16.5880\n",
      "Epoch 2586/3000\n",
      "104/104 [==============================] - 15s 144ms/step - d_loss: -0.0176 - g_loss: 17.3316\n",
      "Epoch 2587/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: 0.0191 - g_loss: 16.8080\n",
      "Epoch 2588/3000\n",
      "104/104 [==============================] - 15s 134ms/step - d_loss: -0.0591 - g_loss: 17.6781\n",
      "Epoch 2589/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: -0.0701 - g_loss: 18.0188\n",
      "Epoch 2590/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: -0.0826 - g_loss: 18.2312\n",
      "Epoch 2591/3000\n",
      "104/104 [==============================] - 15s 139ms/step - d_loss: -0.0217 - g_loss: 17.5442\n",
      "Epoch 2592/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: 0.0232 - g_loss: 16.6399\n",
      "Epoch 2593/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: -0.0258 - g_loss: 17.4895\n",
      "Epoch 2594/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0256 - g_loss: 17.4255\n",
      "Epoch 2595/3000\n",
      "104/104 [==============================] - 14s 129ms/step - d_loss: -0.0276 - g_loss: 17.3528\n",
      "Epoch 2596/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: -0.0644 - g_loss: 18.3241\n",
      "Epoch 2597/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0846 - g_loss: 18.6469\n",
      "Epoch 2598/3000\n",
      "104/104 [==============================] - 16s 146ms/step - d_loss: -0.0953 - g_loss: 18.7455\n",
      "Epoch 2599/3000\n",
      "104/104 [==============================] - 16s 151ms/step - d_loss: -0.0751 - g_loss: 18.4753\n",
      "Epoch 2600/3000\n",
      "104/104 [==============================] - 16s 153ms/step - d_loss: -0.0616 - g_loss: 18.3994\n",
      "Epoch 2601/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0318 - g_loss: 17.8797\n",
      "Epoch 2602/3000\n",
      "104/104 [==============================] - 14s 129ms/step - d_loss: -0.0224 - g_loss: 17.5237\n",
      "Epoch 2603/3000\n",
      "104/104 [==============================] - 14s 134ms/step - d_loss: -0.0014 - g_loss: 17.6236\n",
      "Epoch 2604/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: 0.0663 - g_loss: 16.3632\n",
      "Epoch 2605/3000\n",
      "104/104 [==============================] - 15s 138ms/step - d_loss: -0.0154 - g_loss: 17.2910\n",
      "Epoch 2606/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0647 - g_loss: 18.1770\n",
      "Epoch 2607/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0487 - g_loss: 18.0247\n",
      "Epoch 2608/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: -0.0476 - g_loss: 18.5263\n",
      "Epoch 2609/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0512 - g_loss: 18.1038\n",
      "Epoch 2610/3000\n",
      "104/104 [==============================] - 15s 141ms/step - d_loss: -0.0688 - g_loss: 18.4745\n",
      "Epoch 2611/3000\n",
      "104/104 [==============================] - 15s 141ms/step - d_loss: -0.0839 - g_loss: 18.8170\n",
      "Epoch 2612/3000\n",
      "104/104 [==============================] - 16s 149ms/step - d_loss: -0.0446 - g_loss: 18.3933\n",
      "Epoch 2613/3000\n",
      "104/104 [==============================] - 16s 149ms/step - d_loss: -0.0663 - g_loss: 18.1827\n",
      "Epoch 2614/3000\n",
      "104/104 [==============================] - 15s 141ms/step - d_loss: -0.0218 - g_loss: 17.9680\n",
      "Epoch 2615/3000\n",
      "104/104 [==============================] - 16s 147ms/step - d_loss: -0.0036 - g_loss: 17.6487\n",
      "Epoch 2616/3000\n",
      "104/104 [==============================] - 14s 126ms/step - d_loss: -0.0096 - g_loss: 17.8589\n",
      "Epoch 2617/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: -0.0182 - g_loss: 17.8416\n",
      "Epoch 2618/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: -0.0391 - g_loss: 18.4559\n",
      "Epoch 2619/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: -0.0758 - g_loss: 18.6259\n",
      "Epoch 2620/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: -0.0114 - g_loss: 18.1816\n",
      "Epoch 2621/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: -0.0497 - g_loss: 18.3021\n",
      "Epoch 2622/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: -0.0483 - g_loss: 17.9310\n",
      "Epoch 2623/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: -0.0211 - g_loss: 18.1410\n",
      "Epoch 2624/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0481 - g_loss: 18.4285\n",
      "Epoch 2625/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: -0.0368 - g_loss: 18.2428\n",
      "Epoch 2626/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: -0.0291 - g_loss: 18.3135\n",
      "Epoch 2627/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: -0.0444 - g_loss: 17.9758\n",
      "Epoch 2628/3000\n",
      "104/104 [==============================] - 13s 121ms/step - d_loss: -0.0473 - g_loss: 18.5471\n",
      "Epoch 2629/3000\n",
      "104/104 [==============================] - 13s 119ms/step - d_loss: -0.0416 - g_loss: 18.3813\n",
      "Epoch 2630/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: -0.0754 - g_loss: 19.0199\n",
      "Epoch 2631/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: -0.0385 - g_loss: 18.2876\n",
      "Epoch 2632/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: -0.0432 - g_loss: 18.5561\n",
      "Epoch 2633/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: -0.0299 - g_loss: 17.6882\n",
      "Epoch 2634/3000\n",
      "104/104 [==============================] - 13s 122ms/step - d_loss: -0.0511 - g_loss: 18.7175\n",
      "Epoch 2635/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: -0.0285 - g_loss: 17.5579\n",
      "Epoch 2636/3000\n",
      "104/104 [==============================] - 12s 117ms/step - d_loss: -0.0592 - g_loss: 19.0150\n",
      "Epoch 2637/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: -0.0635 - g_loss: 18.6801\n",
      "Epoch 2638/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: -0.0257 - g_loss: 17.9221\n",
      "Epoch 2639/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: -0.0330 - g_loss: 18.0575\n",
      "Epoch 2640/3000\n",
      "104/104 [==============================] - 12s 108ms/step - d_loss: -0.0448 - g_loss: 18.3846\n",
      "Epoch 2641/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0657 - g_loss: 18.6315\n",
      "Epoch 2642/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0636 - g_loss: 18.9846\n",
      "Epoch 2643/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.0322 - g_loss: 17.4187\n",
      "Epoch 2644/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0023 - g_loss: 17.6720\n",
      "Epoch 2645/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0771 - g_loss: 18.9171\n",
      "Epoch 2646/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: -0.0583 - g_loss: 18.5536\n",
      "Epoch 2647/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0060 - g_loss: 17.8500\n",
      "Epoch 2648/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: -0.0513 - g_loss: 18.4683\n",
      "Epoch 2649/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0341 - g_loss: 18.5312\n",
      "Epoch 2650/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0195 - g_loss: 18.0899\n",
      "Epoch 2651/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.0033 - g_loss: 17.7449\n",
      "Epoch 2652/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0130 - g_loss: 17.9577\n",
      "Epoch 2653/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0154 - g_loss: 17.6986\n",
      "Epoch 2654/3000\n",
      "104/104 [==============================] - 13s 126ms/step - d_loss: -0.0802 - g_loss: 19.1933\n",
      "Epoch 2655/3000\n",
      "104/104 [==============================] - 14s 129ms/step - d_loss: -0.0757 - g_loss: 19.1567\n",
      "Epoch 2656/3000\n",
      "104/104 [==============================] - 14s 129ms/step - d_loss: -0.0181 - g_loss: 18.4713\n",
      "Epoch 2657/3000\n",
      "104/104 [==============================] - 14s 128ms/step - d_loss: -0.0239 - g_loss: 18.1382\n",
      "Epoch 2658/3000\n",
      "104/104 [==============================] - 14s 128ms/step - d_loss: -0.0239 - g_loss: 18.3344\n",
      "Epoch 2659/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0445 - g_loss: 18.7219\n",
      "Epoch 2660/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0148 - g_loss: 18.3912\n",
      "Epoch 2661/3000\n",
      "104/104 [==============================] - 14s 129ms/step - d_loss: -0.0663 - g_loss: 18.9795\n",
      "Epoch 2662/3000\n",
      "104/104 [==============================] - 14s 128ms/step - d_loss: -0.0692 - g_loss: 18.9777\n",
      "Epoch 2663/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0724 - g_loss: 19.2798\n",
      "Epoch 2664/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0497 - g_loss: 19.2719\n",
      "Epoch 2665/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0315 - g_loss: 18.6450\n",
      "Epoch 2666/3000\n",
      "104/104 [==============================] - 14s 127ms/step - d_loss: -0.0914 - g_loss: 19.5358\n",
      "Epoch 2667/3000\n",
      "104/104 [==============================] - 13s 125ms/step - d_loss: -0.0740 - g_loss: 19.5042\n",
      "Epoch 2668/3000\n",
      "104/104 [==============================] - 14s 128ms/step - d_loss: -0.0193 - g_loss: 18.3411\n",
      "Epoch 2669/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0156 - g_loss: 18.2639\n",
      "Epoch 2670/3000\n",
      "104/104 [==============================] - 14s 127ms/step - d_loss: -0.0458 - g_loss: 18.7425\n",
      "Epoch 2671/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0334 - g_loss: 19.0244\n",
      "Epoch 2672/3000\n",
      "104/104 [==============================] - 13s 126ms/step - d_loss: -0.0407 - g_loss: 18.6589\n",
      "Epoch 2673/3000\n",
      "104/104 [==============================] - 16s 152ms/step - d_loss: -0.0292 - g_loss: 18.8992\n",
      "Epoch 2674/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: 0.0310 - g_loss: 17.4946\n",
      "Epoch 2675/3000\n",
      "104/104 [==============================] - 14s 127ms/step - d_loss: -0.0254 - g_loss: 18.3863\n",
      "Epoch 2676/3000\n",
      "104/104 [==============================] - 17s 157ms/step - d_loss: -0.0634 - g_loss: 18.9567\n",
      "Epoch 2677/3000\n",
      "104/104 [==============================] - 16s 151ms/step - d_loss: -0.0303 - g_loss: 18.7837\n",
      "Epoch 2678/3000\n",
      "104/104 [==============================] - 14s 135ms/step - d_loss: -0.0665 - g_loss: 18.9957\n",
      "Epoch 2679/3000\n",
      "104/104 [==============================] - 14s 128ms/step - d_loss: -0.0995 - g_loss: 19.8501\n",
      "Epoch 2680/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0716 - g_loss: 19.7675\n",
      "Epoch 2681/3000\n",
      "104/104 [==============================] - 15s 139ms/step - d_loss: -0.0385 - g_loss: 19.1174\n",
      "Epoch 2682/3000\n",
      "104/104 [==============================] - 16s 152ms/step - d_loss: -0.0503 - g_loss: 19.2037\n",
      "Epoch 2683/3000\n",
      "104/104 [==============================] - 15s 141ms/step - d_loss: -0.0759 - g_loss: 19.6265\n",
      "Epoch 2684/3000\n",
      "104/104 [==============================] - 14s 127ms/step - d_loss: -0.0621 - g_loss: 19.2427\n",
      "Epoch 2685/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0115 - g_loss: 18.3188\n",
      "Epoch 2686/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0845 - g_loss: 19.8317\n",
      "Epoch 2687/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: 0.0271 - g_loss: 18.5732\n",
      "Epoch 2688/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: 0.0225 - g_loss: 17.8985\n",
      "Epoch 2689/3000\n",
      "104/104 [==============================] - 15s 139ms/step - d_loss: -0.0195 - g_loss: 18.5489\n",
      "Epoch 2690/3000\n",
      "104/104 [==============================] - 16s 149ms/step - d_loss: -0.0403 - g_loss: 18.8190\n",
      "Epoch 2691/3000\n",
      "104/104 [==============================] - 15s 143ms/step - d_loss: -0.0660 - g_loss: 19.7492\n",
      "Epoch 2692/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0081 - g_loss: 18.9023\n",
      "Epoch 2693/3000\n",
      "104/104 [==============================] - 14s 135ms/step - d_loss: -0.0337 - g_loss: 18.9403\n",
      "Epoch 2694/3000\n",
      "104/104 [==============================] - 14s 134ms/step - d_loss: -0.0289 - g_loss: 18.4117\n",
      "Epoch 2695/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0285 - g_loss: 18.7651\n",
      "Epoch 2696/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: 0.0150 - g_loss: 18.0898\n",
      "Epoch 2697/3000\n",
      "104/104 [==============================] - 16s 149ms/step - d_loss: -0.0254 - g_loss: 18.8348\n",
      "Epoch 2698/3000\n",
      "104/104 [==============================] - 15s 145ms/step - d_loss: -0.0742 - g_loss: 19.4729\n",
      "Epoch 2699/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0751 - g_loss: 19.6044\n",
      "Epoch 2700/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0405 - g_loss: 18.7979\n",
      "Epoch 2701/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0768 - g_loss: 19.9123\n",
      "Epoch 2702/3000\n",
      "104/104 [==============================] - 14s 134ms/step - d_loss: -0.0488 - g_loss: 19.4625\n",
      "Epoch 2703/3000\n",
      "104/104 [==============================] - 14s 129ms/step - d_loss: -0.0381 - g_loss: 18.7210\n",
      "Epoch 2704/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: -0.0344 - g_loss: 18.6739\n",
      "Epoch 2705/3000\n",
      "104/104 [==============================] - 14s 128ms/step - d_loss: -0.0464 - g_loss: 18.9791\n",
      "Epoch 2706/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0553 - g_loss: 19.6795\n",
      "Epoch 2707/3000\n",
      "104/104 [==============================] - 14s 128ms/step - d_loss: -0.0288 - g_loss: 18.6748\n",
      "Epoch 2708/3000\n",
      "104/104 [==============================] - 14s 128ms/step - d_loss: -0.0086 - g_loss: 18.4723\n",
      "Epoch 2709/3000\n",
      "104/104 [==============================] - 14s 127ms/step - d_loss: -0.0023 - g_loss: 18.5302\n",
      "Epoch 2710/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0048 - g_loss: 18.2868\n",
      "Epoch 2711/3000\n",
      "104/104 [==============================] - 16s 152ms/step - d_loss: -0.0621 - g_loss: 19.2698\n",
      "Epoch 2712/3000\n",
      "104/104 [==============================] - 17s 160ms/step - d_loss: -0.0340 - g_loss: 19.1309\n",
      "Epoch 2713/3000\n",
      "104/104 [==============================] - 16s 152ms/step - d_loss: -0.0577 - g_loss: 19.4914\n",
      "Epoch 2714/3000\n",
      "104/104 [==============================] - 16s 153ms/step - d_loss: -0.0128 - g_loss: 19.0455\n",
      "Epoch 2715/3000\n",
      "104/104 [==============================] - 14s 127ms/step - d_loss: -0.0388 - g_loss: 19.5331\n",
      "Epoch 2716/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0326 - g_loss: 18.8670\n",
      "Epoch 2717/3000\n",
      "104/104 [==============================] - 14s 132ms/step - d_loss: -0.0963 - g_loss: 19.9818\n",
      "Epoch 2718/3000\n",
      "104/104 [==============================] - 14s 127ms/step - d_loss: -0.0899 - g_loss: 20.3682\n",
      "Epoch 2719/3000\n",
      "104/104 [==============================] - 14s 127ms/step - d_loss: -0.0855 - g_loss: 19.8351\n",
      "Epoch 2720/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0052 - g_loss: 18.9788\n",
      "Epoch 2721/3000\n",
      "104/104 [==============================] - 14s 128ms/step - d_loss: -0.0554 - g_loss: 19.8884\n",
      "Epoch 2722/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0857 - g_loss: 20.0498\n",
      "Epoch 2723/3000\n",
      "104/104 [==============================] - 14s 128ms/step - d_loss: -0.0697 - g_loss: 19.9775\n",
      "Epoch 2724/3000\n",
      "104/104 [==============================] - 14s 127ms/step - d_loss: 0.0061 - g_loss: 18.8187\n",
      "Epoch 2725/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0782 - g_loss: 19.9113\n",
      "Epoch 2726/3000\n",
      "104/104 [==============================] - 14s 127ms/step - d_loss: -0.0645 - g_loss: 19.8247\n",
      "Epoch 2727/3000\n",
      "104/104 [==============================] - 16s 153ms/step - d_loss: -0.0909 - g_loss: 20.3103\n",
      "Epoch 2728/3000\n",
      "104/104 [==============================] - 17s 160ms/step - d_loss: -0.0930 - g_loss: 20.4617\n",
      "Epoch 2729/3000\n",
      "104/104 [==============================] - 15s 137ms/step - d_loss: -0.0761 - g_loss: 20.2088\n",
      "Epoch 2730/3000\n",
      "104/104 [==============================] - 14s 128ms/step - d_loss: -0.0132 - g_loss: 19.4418\n",
      "Epoch 2731/3000\n",
      "104/104 [==============================] - 14s 128ms/step - d_loss: -0.0622 - g_loss: 19.9812\n",
      "Epoch 2732/3000\n",
      "104/104 [==============================] - 17s 164ms/step - d_loss: -0.0641 - g_loss: 20.2735\n",
      "Epoch 2733/3000\n",
      "104/104 [==============================] - 17s 158ms/step - d_loss: -0.0537 - g_loss: 19.5422\n",
      "Epoch 2734/3000\n",
      "104/104 [==============================] - 14s 127ms/step - d_loss: -0.0652 - g_loss: 19.9955\n",
      "Epoch 2735/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0455 - g_loss: 19.5395\n",
      "Epoch 2736/3000\n",
      "104/104 [==============================] - 16s 148ms/step - d_loss: -0.0785 - g_loss: 20.2887\n",
      "Epoch 2737/3000\n",
      "104/104 [==============================] - 18s 172ms/step - d_loss: -0.0374 - g_loss: 20.4142\n",
      "Epoch 2738/3000\n",
      "104/104 [==============================] - 16s 147ms/step - d_loss: -0.0312 - g_loss: 19.6208\n",
      "Epoch 2739/3000\n",
      "104/104 [==============================] - 14s 127ms/step - d_loss: -0.0345 - g_loss: 19.3251\n",
      "Epoch 2740/3000\n",
      "104/104 [==============================] - 14s 128ms/step - d_loss: -0.0379 - g_loss: 19.6975\n",
      "Epoch 2741/3000\n",
      "104/104 [==============================] - 14s 135ms/step - d_loss: -0.0672 - g_loss: 20.0877\n",
      "Epoch 2742/3000\n",
      "104/104 [==============================] - 18s 169ms/step - d_loss: -0.0519 - g_loss: 19.6720\n",
      "Epoch 2743/3000\n",
      "104/104 [==============================] - 17s 160ms/step - d_loss: 0.0049 - g_loss: 18.9984\n",
      "Epoch 2744/3000\n",
      "104/104 [==============================] - 12s 118ms/step - d_loss: -0.0468 - g_loss: 19.6199\n",
      "Epoch 2745/3000\n",
      "104/104 [==============================] - 14s 135ms/step - d_loss: 0.0016 - g_loss: 19.3726\n",
      "Epoch 2746/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: -0.0596 - g_loss: 19.9292\n",
      "Epoch 2747/3000\n",
      "104/104 [==============================] - 14s 127ms/step - d_loss: -0.0450 - g_loss: 19.6975\n",
      "Epoch 2748/3000\n",
      "104/104 [==============================] - 14s 133ms/step - d_loss: -0.0283 - g_loss: 19.7752\n",
      "Epoch 2749/3000\n",
      "104/104 [==============================] - 14s 129ms/step - d_loss: -0.0034 - g_loss: 19.0895\n",
      "Epoch 2750/3000\n",
      "104/104 [==============================] - 14s 128ms/step - d_loss: -0.0672 - g_loss: 20.1964\n",
      "Epoch 2751/3000\n",
      "104/104 [==============================] - 14s 131ms/step - d_loss: -0.0716 - g_loss: 19.8912\n",
      "Epoch 2752/3000\n",
      "104/104 [==============================] - 14s 130ms/step - d_loss: -0.0602 - g_loss: 19.6899\n",
      "Epoch 2753/3000\n",
      "104/104 [==============================] - 13s 120ms/step - d_loss: -0.0712 - g_loss: 20.3573\n",
      "Epoch 2754/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.0148 - g_loss: 18.7741\n",
      "Epoch 2755/3000\n",
      "104/104 [==============================] - 11s 108ms/step - d_loss: -0.0402 - g_loss: 19.1520\n",
      "Epoch 2756/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0203 - g_loss: 19.9219\n",
      "Epoch 2757/3000\n",
      "104/104 [==============================] - 11s 107ms/step - d_loss: -0.0629 - g_loss: 19.7373\n",
      "Epoch 2758/3000\n",
      "104/104 [==============================] - 11s 107ms/step - d_loss: -0.0907 - g_loss: 20.5668\n",
      "Epoch 2759/3000\n",
      "104/104 [==============================] - 11s 109ms/step - d_loss: -0.0187 - g_loss: 19.0350\n",
      "Epoch 2760/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0869 - g_loss: 20.3253\n",
      "Epoch 2761/3000\n",
      "104/104 [==============================] - 11s 108ms/step - d_loss: 0.0129 - g_loss: 19.6712\n",
      "Epoch 2762/3000\n",
      "104/104 [==============================] - 11s 108ms/step - d_loss: -0.0021 - g_loss: 18.9854\n",
      "Epoch 2763/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0634 - g_loss: 20.3701\n",
      "Epoch 2764/3000\n",
      "104/104 [==============================] - 11s 107ms/step - d_loss: -0.0518 - g_loss: 20.1869\n",
      "Epoch 2765/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0486 - g_loss: 20.4346\n",
      "Epoch 2766/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0903 - g_loss: 20.9514\n",
      "Epoch 2767/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: -0.0893 - g_loss: 21.3630\n",
      "Epoch 2768/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0490 - g_loss: 20.1739\n",
      "Epoch 2769/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0580 - g_loss: 20.1709\n",
      "Epoch 2770/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0131 - g_loss: 19.9617\n",
      "Epoch 2771/3000\n",
      "104/104 [==============================] - 11s 107ms/step - d_loss: -0.0122 - g_loss: 19.4815\n",
      "Epoch 2772/3000\n",
      "104/104 [==============================] - 11s 106ms/step - d_loss: -0.0039 - g_loss: 19.3042\n",
      "Epoch 2773/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0801 - g_loss: 20.5763\n",
      "Epoch 2774/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: -0.0112 - g_loss: 19.2626\n",
      "Epoch 2775/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0211 - g_loss: 20.0219\n",
      "Epoch 2776/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0761 - g_loss: 20.6547\n",
      "Epoch 2777/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: -0.0940 - g_loss: 21.4772\n",
      "Epoch 2778/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0568 - g_loss: 20.4435\n",
      "Epoch 2779/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0344 - g_loss: 20.3635\n",
      "Epoch 2780/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: -0.0627 - g_loss: 20.8575\n",
      "Epoch 2781/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: 0.0169 - g_loss: 19.2989\n",
      "Epoch 2782/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0396 - g_loss: 20.0115\n",
      "Epoch 2783/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0384 - g_loss: 20.3364\n",
      "Epoch 2784/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0091 - g_loss: 19.6342\n",
      "Epoch 2785/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: -0.0055 - g_loss: 19.3944\n",
      "Epoch 2786/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: 0.0153 - g_loss: 18.8334\n",
      "Epoch 2787/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0686 - g_loss: 20.7916\n",
      "Epoch 2788/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0165 - g_loss: 19.8848\n",
      "Epoch 2789/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0329 - g_loss: 19.7087\n",
      "Epoch 2790/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: -0.0768 - g_loss: 20.7368\n",
      "Epoch 2791/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.1014 - g_loss: 21.1830\n",
      "Epoch 2792/3000\n",
      "104/104 [==============================] - 11s 108ms/step - d_loss: -0.1271 - g_loss: 21.9061\n",
      "Epoch 2793/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.1224 - g_loss: 21.6737\n",
      "Epoch 2794/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.1059 - g_loss: 21.8370\n",
      "Epoch 2795/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0836 - g_loss: 20.9457\n",
      "Epoch 2796/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.0480 - g_loss: 19.1178\n",
      "Epoch 2797/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0285 - g_loss: 19.8708\n",
      "Epoch 2798/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0603 - g_loss: 20.7022\n",
      "Epoch 2799/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.1113 - g_loss: 21.7107\n",
      "Epoch 2800/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0759 - g_loss: 21.3282\n",
      "Epoch 2801/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0832 - g_loss: 21.5162\n",
      "Epoch 2802/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0448 - g_loss: 20.3333\n",
      "Epoch 2803/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: -0.0465 - g_loss: 20.8258\n",
      "Epoch 2804/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0438 - g_loss: 20.6800\n",
      "Epoch 2805/3000\n",
      "104/104 [==============================] - 11s 106ms/step - d_loss: -0.0557 - g_loss: 20.6076\n",
      "Epoch 2806/3000\n",
      "104/104 [==============================] - 11s 108ms/step - d_loss: -0.0781 - g_loss: 21.1202\n",
      "Epoch 2807/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0689 - g_loss: 21.1207\n",
      "Epoch 2808/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0840 - g_loss: 21.3515\n",
      "Epoch 2809/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: -0.0763 - g_loss: 21.1401\n",
      "Epoch 2810/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0095 - g_loss: 19.6742\n",
      "Epoch 2811/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0563 - g_loss: 20.5869\n",
      "Epoch 2812/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0813 - g_loss: 21.2177\n",
      "Epoch 2813/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0217 - g_loss: 20.0099\n",
      "Epoch 2814/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0269 - g_loss: 20.3277\n",
      "Epoch 2815/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0149 - g_loss: 20.3883\n",
      "Epoch 2816/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0331 - g_loss: 20.7417\n",
      "Epoch 2817/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: -0.0648 - g_loss: 21.0342\n",
      "Epoch 2818/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0860 - g_loss: 21.3354\n",
      "Epoch 2819/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0270 - g_loss: 20.6640\n",
      "Epoch 2820/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0907 - g_loss: 21.3132\n",
      "Epoch 2821/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0148 - g_loss: 20.5366\n",
      "Epoch 2822/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0587 - g_loss: 20.9710\n",
      "Epoch 2823/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0693 - g_loss: 20.8911\n",
      "Epoch 2824/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0989 - g_loss: 21.7763\n",
      "Epoch 2825/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0495 - g_loss: 21.1097\n",
      "Epoch 2826/3000\n",
      "104/104 [==============================] - 11s 107ms/step - d_loss: -0.0462 - g_loss: 21.1956\n",
      "Epoch 2827/3000\n",
      "104/104 [==============================] - 11s 109ms/step - d_loss: -0.0176 - g_loss: 20.2034\n",
      "Epoch 2828/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0449 - g_loss: 21.0732\n",
      "Epoch 2829/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0467 - g_loss: 20.5738\n",
      "Epoch 2830/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: -0.0769 - g_loss: 21.6056\n",
      "Epoch 2831/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: -0.0917 - g_loss: 21.5224\n",
      "Epoch 2832/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.0171 - g_loss: 19.6659\n",
      "Epoch 2833/3000\n",
      "104/104 [==============================] - 11s 108ms/step - d_loss: -0.0611 - g_loss: 20.7752\n",
      "Epoch 2834/3000\n",
      "104/104 [==============================] - 11s 108ms/step - d_loss: -0.1038 - g_loss: 21.8917\n",
      "Epoch 2835/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0514 - g_loss: 20.8032\n",
      "Epoch 2836/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0734 - g_loss: 21.5454\n",
      "Epoch 2837/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0303 - g_loss: 20.8478\n",
      "Epoch 2838/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0745 - g_loss: 21.5274\n",
      "Epoch 2839/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: -0.0361 - g_loss: 21.2494\n",
      "Epoch 2840/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0413 - g_loss: 21.0572\n",
      "Epoch 2841/3000\n",
      "104/104 [==============================] - 11s 108ms/step - d_loss: -0.0490 - g_loss: 20.9514\n",
      "Epoch 2842/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0668 - g_loss: 21.2316\n",
      "Epoch 2843/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0879 - g_loss: 21.0353\n",
      "Epoch 2844/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0887 - g_loss: 21.7413\n",
      "Epoch 2845/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: -0.0396 - g_loss: 21.2184\n",
      "Epoch 2846/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0557 - g_loss: 21.0940\n",
      "Epoch 2847/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0484 - g_loss: 20.9138\n",
      "Epoch 2848/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: -0.0745 - g_loss: 21.0648\n",
      "Epoch 2849/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0706 - g_loss: 21.2662\n",
      "Epoch 2850/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.1083 - g_loss: 22.1469\n",
      "Epoch 2851/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.1096 - g_loss: 22.3933\n",
      "Epoch 2852/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0998 - g_loss: 22.2290\n",
      "Epoch 2853/3000\n",
      "104/104 [==============================] - 11s 108ms/step - d_loss: -0.0081 - g_loss: 20.7438\n",
      "Epoch 2854/3000\n",
      "104/104 [==============================] - 11s 108ms/step - d_loss: 0.0232 - g_loss: 20.3763\n",
      "Epoch 2855/3000\n",
      "104/104 [==============================] - 11s 108ms/step - d_loss: -0.0211 - g_loss: 20.8167\n",
      "Epoch 2856/3000\n",
      "104/104 [==============================] - 11s 108ms/step - d_loss: -0.0332 - g_loss: 21.0529\n",
      "Epoch 2857/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0340 - g_loss: 21.0620\n",
      "Epoch 2858/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: -0.0340 - g_loss: 21.0791\n",
      "Epoch 2859/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: -0.0914 - g_loss: 22.1153\n",
      "Epoch 2860/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0992 - g_loss: 22.4537\n",
      "Epoch 2861/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.0102 - g_loss: 20.6781\n",
      "Epoch 2862/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0531 - g_loss: 21.6740\n",
      "Epoch 2863/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0866 - g_loss: 22.1916\n",
      "Epoch 2864/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0627 - g_loss: 21.6974\n",
      "Epoch 2865/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0707 - g_loss: 22.1009\n",
      "Epoch 2866/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: -0.1013 - g_loss: 22.3038\n",
      "Epoch 2867/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0472 - g_loss: 21.3496\n",
      "Epoch 2868/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: -0.0145 - g_loss: 21.0951\n",
      "Epoch 2869/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: -0.0617 - g_loss: 21.6327\n",
      "Epoch 2870/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0661 - g_loss: 21.5289\n",
      "Epoch 2871/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0354 - g_loss: 21.2617\n",
      "Epoch 2872/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0657 - g_loss: 21.8077\n",
      "Epoch 2873/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0780 - g_loss: 21.9431\n",
      "Epoch 2874/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0966 - g_loss: 22.1810\n",
      "Epoch 2875/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0529 - g_loss: 21.4280\n",
      "Epoch 2876/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: -0.0867 - g_loss: 22.3824\n",
      "Epoch 2877/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: 0.0182 - g_loss: 21.3328\n",
      "Epoch 2878/3000\n",
      "104/104 [==============================] - 11s 108ms/step - d_loss: -0.0368 - g_loss: 21.4385\n",
      "Epoch 2879/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0366 - g_loss: 21.2537\n",
      "Epoch 2880/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0672 - g_loss: 21.4925\n",
      "Epoch 2881/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0416 - g_loss: 21.3558\n",
      "Epoch 2882/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0926 - g_loss: 22.0765\n",
      "Epoch 2883/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0083 - g_loss: 20.5902\n",
      "Epoch 2884/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.0051 - g_loss: 20.6492\n",
      "Epoch 2885/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: -0.0384 - g_loss: 21.3130\n",
      "Epoch 2886/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: -0.1035 - g_loss: 22.5610\n",
      "Epoch 2887/3000\n",
      "104/104 [==============================] - 11s 107ms/step - d_loss: -0.0981 - g_loss: 21.9286\n",
      "Epoch 2888/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.1155 - g_loss: 22.6827\n",
      "Epoch 2889/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0680 - g_loss: 22.3573\n",
      "Epoch 2890/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0193 - g_loss: 21.3081\n",
      "Epoch 2891/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: -0.0712 - g_loss: 22.2856\n",
      "Epoch 2892/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: -0.0654 - g_loss: 22.4910\n",
      "Epoch 2893/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: -0.1250 - g_loss: 23.1722\n",
      "Epoch 2894/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0958 - g_loss: 23.2895\n",
      "Epoch 2895/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: -0.0808 - g_loss: 22.8238\n",
      "Epoch 2896/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0973 - g_loss: 23.0472\n",
      "Epoch 2897/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: -0.0266 - g_loss: 21.5582\n",
      "Epoch 2898/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.0198 - g_loss: 20.2935\n",
      "Epoch 2899/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0687 - g_loss: 21.9272\n",
      "Epoch 2900/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0882 - g_loss: 22.5070\n",
      "Epoch 2901/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0184 - g_loss: 21.4413\n",
      "Epoch 2902/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0291 - g_loss: 21.7064\n",
      "Epoch 2903/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0617 - g_loss: 21.7729\n",
      "Epoch 2904/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0871 - g_loss: 22.7077\n",
      "Epoch 2905/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0856 - g_loss: 22.8112\n",
      "Epoch 2906/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0767 - g_loss: 22.3470\n",
      "Epoch 2907/3000\n",
      "104/104 [==============================] - 11s 108ms/step - d_loss: -0.0909 - g_loss: 22.6471\n",
      "Epoch 2908/3000\n",
      "104/104 [==============================] - 11s 108ms/step - d_loss: -0.1200 - g_loss: 23.5774\n",
      "Epoch 2909/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: -0.0771 - g_loss: 22.9224\n",
      "Epoch 2910/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: -0.0705 - g_loss: 22.7823\n",
      "Epoch 2911/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: -0.0720 - g_loss: 23.0558\n",
      "Epoch 2912/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: -0.0860 - g_loss: 22.6485\n",
      "Epoch 2913/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0516 - g_loss: 22.4193\n",
      "Epoch 2914/3000\n",
      "104/104 [==============================] - 11s 108ms/step - d_loss: -0.0420 - g_loss: 22.2749\n",
      "Epoch 2915/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0999 - g_loss: 22.6507\n",
      "Epoch 2916/3000\n",
      "104/104 [==============================] - 12s 108ms/step - d_loss: -0.0597 - g_loss: 22.5006\n",
      "Epoch 2917/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.0237 - g_loss: 21.5769\n",
      "Epoch 2918/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0683 - g_loss: 22.1546\n",
      "Epoch 2919/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0569 - g_loss: 22.3697\n",
      "Epoch 2920/3000\n",
      "104/104 [==============================] - 12s 114ms/step - d_loss: -0.0446 - g_loss: 22.0811\n",
      "Epoch 2921/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: -0.0511 - g_loss: 22.2191\n",
      "Epoch 2922/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: 0.0198 - g_loss: 21.5037\n",
      "Epoch 2923/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: -0.0978 - g_loss: 22.7607\n",
      "Epoch 2924/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0262 - g_loss: 21.5927\n",
      "Epoch 2925/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0422 - g_loss: 22.0437\n",
      "Epoch 2926/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.1036 - g_loss: 22.8126\n",
      "Epoch 2927/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0785 - g_loss: 22.4804\n",
      "Epoch 2928/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.1008 - g_loss: 23.2408\n",
      "Epoch 2929/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0789 - g_loss: 22.6250\n",
      "Epoch 2930/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: -0.0590 - g_loss: 22.3297\n",
      "Epoch 2931/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: -0.0201 - g_loss: 21.6008\n",
      "Epoch 2932/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: -0.0596 - g_loss: 22.2865\n",
      "Epoch 2933/3000\n",
      "104/104 [==============================] - 12s 116ms/step - d_loss: -0.1047 - g_loss: 23.2335\n",
      "Epoch 2934/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: -0.0997 - g_loss: 23.4784\n",
      "Epoch 2935/3000\n",
      "104/104 [==============================] - 11s 107ms/step - d_loss: -0.0937 - g_loss: 23.5330\n",
      "Epoch 2936/3000\n",
      "104/104 [==============================] - 11s 108ms/step - d_loss: -0.0428 - g_loss: 22.3730\n",
      "Epoch 2937/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.1044 - g_loss: 23.1745\n",
      "Epoch 2938/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0834 - g_loss: 23.1288\n",
      "Epoch 2939/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0632 - g_loss: 23.0021\n",
      "Epoch 2940/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0760 - g_loss: 22.7067\n",
      "Epoch 2941/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0412 - g_loss: 22.1348\n",
      "Epoch 2942/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: -0.0378 - g_loss: 22.7803\n",
      "Epoch 2943/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0784 - g_loss: 22.9940\n",
      "Epoch 2944/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: -0.0807 - g_loss: 23.0295\n",
      "Epoch 2945/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.1045 - g_loss: 23.2931\n",
      "Epoch 2946/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: -0.1115 - g_loss: 23.4677\n",
      "Epoch 2947/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: -0.1004 - g_loss: 23.4967\n",
      "Epoch 2948/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: -0.0879 - g_loss: 23.6340\n",
      "Epoch 2949/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0659 - g_loss: 23.4105\n",
      "Epoch 2950/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: -0.0416 - g_loss: 22.0514\n",
      "Epoch 2951/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: -0.0119 - g_loss: 22.1482\n",
      "Epoch 2952/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0708 - g_loss: 23.2231\n",
      "Epoch 2953/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0511 - g_loss: 22.7851\n",
      "Epoch 2954/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0257 - g_loss: 22.2500\n",
      "Epoch 2955/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0116 - g_loss: 22.0008\n",
      "Epoch 2956/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: -0.0587 - g_loss: 23.0917\n",
      "Epoch 2957/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: -0.0921 - g_loss: 23.2089\n",
      "Epoch 2958/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0719 - g_loss: 22.8675\n",
      "Epoch 2959/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0831 - g_loss: 23.5359\n",
      "Epoch 2960/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0795 - g_loss: 23.0264\n",
      "Epoch 2961/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0818 - g_loss: 23.6957\n",
      "Epoch 2962/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.1065 - g_loss: 23.7924\n",
      "Epoch 2963/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.1000 - g_loss: 23.4787\n",
      "Epoch 2964/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: -0.1138 - g_loss: 23.9179\n",
      "Epoch 2965/3000\n",
      "104/104 [==============================] - 12s 108ms/step - d_loss: -0.0428 - g_loss: 22.6623\n",
      "Epoch 2966/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0794 - g_loss: 23.0056\n",
      "Epoch 2967/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0685 - g_loss: 23.6378\n",
      "Epoch 2968/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0371 - g_loss: 22.4977\n",
      "Epoch 2969/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0582 - g_loss: 23.2304\n",
      "Epoch 2970/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: -0.1024 - g_loss: 23.8193\n",
      "Epoch 2971/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: -0.0806 - g_loss: 23.4692\n",
      "Epoch 2972/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0306 - g_loss: 23.0916\n",
      "Epoch 2973/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: -0.0310 - g_loss: 22.3216\n",
      "Epoch 2974/3000\n",
      "104/104 [==============================] - 11s 108ms/step - d_loss: -0.0185 - g_loss: 22.5406\n",
      "Epoch 2975/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0808 - g_loss: 23.3864\n",
      "Epoch 2976/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0693 - g_loss: 22.8675\n",
      "Epoch 2977/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: -0.0759 - g_loss: 23.1045\n",
      "Epoch 2978/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0655 - g_loss: 23.0462\n",
      "Epoch 2979/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0744 - g_loss: 23.6792\n",
      "Epoch 2980/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: -0.0939 - g_loss: 23.3950\n",
      "Epoch 2981/3000\n",
      "104/104 [==============================] - 12s 115ms/step - d_loss: -0.1248 - g_loss: 24.2932\n",
      "Epoch 2982/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: -0.0587 - g_loss: 23.4523\n",
      "Epoch 2983/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: -0.0883 - g_loss: 24.1710\n",
      "Epoch 2984/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.1061 - g_loss: 24.3989\n",
      "Epoch 2985/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.1027 - g_loss: 23.7693\n",
      "Epoch 2986/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: -0.1046 - g_loss: 24.0830\n",
      "Epoch 2987/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0228 - g_loss: 22.6868\n",
      "Epoch 2988/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: 0.0871 - g_loss: 21.4165\n",
      "Epoch 2989/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0846 - g_loss: 23.4538\n",
      "Epoch 2990/3000\n",
      "104/104 [==============================] - 12s 109ms/step - d_loss: -0.0923 - g_loss: 23.7772\n",
      "Epoch 2991/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: -0.0896 - g_loss: 23.8147\n",
      "Epoch 2992/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: -0.1282 - g_loss: 24.3865\n",
      "Epoch 2993/3000\n",
      "104/104 [==============================] - 12s 110ms/step - d_loss: -0.0809 - g_loss: 23.4759\n",
      "Epoch 2994/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: -0.1138 - g_loss: 24.0644\n",
      "Epoch 2995/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: -0.1009 - g_loss: 24.1923\n",
      "Epoch 2996/3000\n",
      "104/104 [==============================] - 12s 113ms/step - d_loss: -0.0279 - g_loss: 23.1253\n",
      "Epoch 2997/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0382 - g_loss: 22.9575\n",
      "Epoch 2998/3000\n",
      "104/104 [==============================] - 12s 112ms/step - d_loss: -0.0886 - g_loss: 23.9290\n",
      "Epoch 2999/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0880 - g_loss: 24.0351\n",
      "Epoch 3000/3000\n",
      "104/104 [==============================] - 12s 111ms/step - d_loss: -0.0840 - g_loss: 23.9630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x235cd932c10>"
      ]
     },
     "execution_count": 739,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAGxCAYAAAB4AFyyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAACBu0lEQVR4nO3deVhU1RsH8O+wzLCDyK6AIoob7kpoqSXllmulqZVmaYum5pplaqvllktmVr+0xdQyM81dE/c9UVREQBQVUVMBkZ15f39MjIxsAwwMA9/P88wzc88999x37gx3Xs49916FiAiIiIiITJCZsQMgIiIiKi0mMkRERGSymMgQERGRyWIiQ0RERCaLiQwRERGZLCYyREREZLKYyBAREZHJYiJDREREJsvC2AGUN7Vajfj4eNjb20OhUBg7HCIiItKDiODevXvw8vKCmVnh/S5VPpGJj4+Ht7e3scMgIiKiUrhy5Qpq165d6Pwqn8jY29sD0GwIBwcHI0dDRERE+khOToa3t7f2d7wwVT6RyT2c5ODgwESGiIjIxBQ3LISDfYmIiMhkGTWRmTVrFtq2bQt7e3u4ubmhb9++iIyM1KnTuXNnKBQKncfrr79upIiJiIioMjFqIrNnzx6MGjUKhw8fxo4dO5CVlYWnnnoK9+/f16k3YsQIXL9+XfuYPXu2kSImIiKiysSoY2S2bt2qM71ixQq4ubnhxIkT6Nixo7bcxsYGHh4e5RpLTk4OsrKyynUdRFQ5WVpawtzc3NhhEFEpVKrBvklJSQAAZ2dnnfKVK1fi559/hoeHB3r16oX3338fNjY2BlmniCAhIQGJiYkGaY+ITJOTkxM8PDx4vSkiE1NpEhm1Wo1x48ahQ4cOaNq0qbZ88ODB8PX1hZeXF06fPo0pU6YgMjIS69atK7CdjIwMZGRkaKeTk5OLXG9uEuPm5gYbGxvuxIiqGRFBamoqbt68CQDw9PQ0ckREVBKVJpEZNWoUzpw5g/379+uUjxw5Uvs6MDAQnp6e6NKlC2JiYlCvXr187cyaNQsffPCBXuvMycnRJjE1a9Ys2xsgIpNlbW0NALh58ybc3Nx4mInIhFSK069Hjx6Nv/76C7t37y7y6n0AEBQUBACIjo4ucP7UqVORlJSkfVy5cqXQtnLHxBjqMBURma7c/QDHyhGZFqP2yIgI3nrrLfzxxx8IDQ1F3bp1i10mLCwMQOHdvyqVCiqVqkRx8HASEXE/QGSajJrIjBo1Cr/88gv+/PNP2NvbIyEhAQDg6OgIa2trxMTE4JdffkGPHj1Qs2ZNnD59Gm+//TY6duyIZs2aGTN0IiIiqgSMemhp6dKlSEpKQufOneHp6al9rFmzBgCgVCqxc+dOPPXUU2jYsCEmTJiAZ555Bhs3bjRm2FVSnTp1sGDBAr3rh4aGQqFQGOVsrxUrVsDJyUmvujNnzkSLFi3KNZ6ifPPNN/D29oaZmVmJtm9lcOnSJSgUCm0vqCkx9udORBXH6IeWiuLt7Y09e/ZUUDSmobju7xkzZmDmzJklbvfYsWOwtbXVu3779u1x/fp1ODo6lnhd1UVycjJGjx6N+fPn45lnnuG2IiIqB5XmrCXSz/Xr17Wv16xZg+nTp+vc1sHOzk77WkSQk5MDC4viP2ZXV9cSxaFUKsv9IoWmLi4uDllZWejZs2eZTunNysqCpaWlASMjIiqjewmAuRJQ2QPmxt0/VYqzlkh/Hh4e2oejoyMUCoV2+vz587C3t8eWLVvQunVrqFQq7N+/HzExMejTpw/c3d1hZ2eHtm3bYufOnTrtPnxoSaFQ4LvvvkO/fv1gY2OD+vXrY8OGDdr5Dx9ayj3cs23bNjRq1Ah2dnbo1q2bTuKVnZ2NMWPGwMnJCTVr1sSUKVMwdOhQ9O3bt8j3vGLFCvj4+MDGxgb9+vXD7du3S7391Go1PvzwQ9SuXRsqlQotWrTQucJ0ZmYmRo8eDU9PT1hZWcHX1xezZs0CoEkMZ86cCR8fH6hUKnh5eWHMmDGFxhwYGAgA8PPzg0KhwKVLlwBoDqnWq1cPSqUSAQEB+Omnn3SWVSgUWLp0KXr37g1bW1t88sknBa4jIyMDEydORK1atWBra4ugoCCEhoZq59++fRuDBg1CrVq1YGNjg8DAQKxatSrf9pg9ezb8/f2hUqng4+OTb30XL17E448/DhsbGzRv3hyHDh0qchsnJibi1VdfhaurKxwcHPDEE0/g1KlT2vm5h32WLVsGb29v2NjYYMCAAdoLYubGVdTnBABXr17FoEGD4OzsDFtbW7Rp0wZHjhzRqfPTTz+hTp06cHR0xPPPP4979+4VGTsR6SHjHjAvAJhdF5jtB6TdNW48UsUlJSUJAElKSso3Ly0tTc6dOydpaWkiIqJWq+V+RpZRHmq1usTvbfny5eLo6Kid3r17twCQZs2ayfbt2yU6Olpu374tYWFh8vXXX0t4eLhcuHBBpk2bJlZWVnL58mXtsr6+vvLFF19opwFI7dq15ZdffpGoqCgZM2aM2NnZye3bt3XWdffuXW0slpaWEhISIseOHZMTJ05Io0aNZPDgwdo2P/74Y3F2dpZ169ZJRESEvP766+Lg4CB9+vQp9D0ePnxYzMzM5PPPP5fIyEhZuHChODk56bzvosyYMUOaN2+unZ4/f744ODjIqlWr5Pz58zJ58mSxtLSUCxcuiIjInDlzxNvbW/bu3SuXLl2Sffv2yS+//CIiIr/99ps4ODjI5s2b5fLly3LkyBH55ptvClxvamqq7Ny5UwDI0aNH5fr165KdnS3r1q0TS0tLWbJkiURGRsq8efPE3Nxc/v77b51t7+bmJt9//73ExMTofE55vfrqq9K+fXvZu3evREdHy5w5c0SlUmnfy9WrV2XOnDly8uRJiYmJkUWLFom5ubkcOXJE28bkyZOlRo0asmLFComOjpZ9+/bJt99+KyIisbGxAkAaNmwof/31l0RGRsqzzz4rvr6+kpWVVeg2DwkJkV69esmxY8fkwoULMmHCBKlZs6b2uzNjxgyxtbWVJ554Qk6ePCl79uwRf39/ne9KcZ/TvXv3xM/PTx577DHZt2+fREVFyZo1a+TgwYPaddjZ2Un//v0lPDxc9u7dKx4eHvLuu+8WGvfD+wMiKsQ/P4vMcHjwOPFDuaymqN/vvJjI5Nlx3c/IEt8pfxnlcT+j8B+GwhSWyKxfv77YZZs0aSKLFy/WTheUyEybNk07nZKSIgBky5YtOuvKm8gAkOjoaO0yS5YsEXd3d+20u7u7zJkzRzudnZ0tPj4+RSYygwYNkh49euiUDRw4sNSJjJeXl3zyySc6ddq2bStvvvmmiIi89dZb8sQTTxSYWM6bN08aNGggmZmZeq375MmTAkBiY2O1Ze3bt5cRI0bo1Hvuued03iMAGTduXJFtX758WczNzeXatWs65V26dJGpU6cWulzPnj1lwoQJIiKSnJwsKpVKm7g8LDeR+e6777RlZ8+eFQASERFR4DL79u0TBwcHSU9P1ymvV6+eLFu2TEQ0n4m5ublcvXpVO3/Lli1iZmYm169fF5HiP6dly5aJvb29Njl62IwZM8TGxkaSk5O1ZZMmTZKgoKAC64swkSHSW94kZoaDyP6F5bIafRMZHlqqgtq0aaMznZKSgokTJ6JRo0ZwcnKCnZ0dIiIiEBcXV2Q7eU9xt7W1hYODg/Yy7gWxsbHRudqyp6entn5SUhJu3LiBdu3aaeebm5ujdevWRcYQERGhvQhiruDg4CKXKUxycjLi4+PRoUMHnfIOHTogIiICADBs2DCEhYUhICAAY8aMwfbt27X1nnvuOaSlpcHPzw8jRozAH3/8gezs7BLFEBERUeT6cz38GT4sPDwcOTk5aNCgAezs7LSPPXv2ICYmBoDmytUfffQRAgMD4ezsDDs7O2zbtk37uUdERCAjIwNdunQpcl15vwe5Y30K+x6cOnUKKSkpqFmzpk5csbGx2rgAwMfHB7Vq1dJOBwcHQ61WIzIyUq/PKSwsDC1btsx3X7a86tSpA3t7e53Yi/r+ElEp7XjfqKvnYN88rC3Nce7DrkZbt6E8fPbRxIkTsWPHDsydOxf+/v6wtrbGs88+i8zMzCLbeXiAqUKhgFqtLlF9KebMtMqmVatWiI2NxZYtW7Bz504MGDAAISEhWLt2Lby9vREZGYmdO3dix44dePPNNzFnzhzs2bPH4INxizuDLCUlBebm5jhx4kS+y+nnDvieM2cOFi5ciAULFiAwMBC2trYYN26c9nPPvSx/cfK+t9yz5gr7HqSkpMDT01NnrE4ufU+Z14c+sZf0+0tEpok9MnkoFArYKC2M8ijPq4oeOHAAw4YNQ79+/RAYGAgPDw/twNOK4ujoCHd3dxw7dkxblpOTg3/++afI5Ro1apRvAOfhw4dLFYODgwO8vLxw4MABnfIDBw6gcePGOvUGDhyIb7/9FmvWrMHvv/+OO3fuAND8gPbq1QuLFi1CaGgoDh06hPDwcL1jaNSoUbHr10fLli2Rk5ODmzdvwt/fX+eRezbZgQMH0KdPH7zwwgto3rw5/Pz8cOHCBW0b9evXh7W1NXbt2lWidRelVatWSEhIgIWFRb64XFxctPXi4uIQHx+vnT58+DDMzMwQEBCg1+fUrFkzhIWFaT8XIjKy66eNtmr2yFQD9evXx7p169CrVy8oFAq8//77RvnP9K233sKsWbPg7++Phg0bYvHixbh7926RSdyYMWPQoUMHzJ07F3369MG2bdvynb1SEpMmTcKMGTNQr149tGjRAsuXL0dYWBhWrlwJAJg/fz48PT3RsmVLmJmZ4bfffoOHhwecnJywYsUK5OTkICgoCDY2Nvj5559hbW0NX1/fEq1/wIABaNmyJUJCQrBx40asW7cu31lkxWnQoAGGDBmCl156CfPmzUPLli1x69Yt7Nq1C82aNUPPnj1Rv359rF27FgcPHkSNGjUwf/583LhxQ5sMWFlZYcqUKZg8eTKUSiU6dOiAW7du4ezZs3jllVdKFE+ukJAQBAcHo2/fvpg9ezYaNGiA+Ph4bNq0Cf369dMeMrOyssLQoUMxd+5cJCcnY8yYMRgwYIA2CSvucxo0aBA+/fRT9O3bF7NmzYKnpydOnjwJLy+vUh96JKJiHFwMWBdyOPf0GsDTOFfcZyJTDcyfPx/Dhw9H+/bt4eLigilTpiA5ObnC45gyZQoSEhLw0ksvwdzcHCNHjkTXrl2LvNPwI488gm+//RYzZszA9OnTERISgmnTpuGjjz4qVQxjxoxBUlISJkyYgJs3b6Jx48bYsGED6tevDwCwt7fH7NmzERUVBXNzc7Rt2xabN2+GmZkZnJyc8Nlnn2H8+PHIyclBYGAgNm7cWKI7p/ft2xcLFy7E3LlzMXbsWNStWxfLly9H586dS/xeli9fjo8//hgTJkzAtWvX4OLigkceeQRPP/00AGDatGm4ePEiunbtChsbG4wcORJ9+/bVOc35/fffh4WFBaZPn474+Hh4enri9ddfL3EsuRQKBTZv3oz33nsPL7/8Mm7dugUPDw907NgR7u7u2nr+/v7o378/evTogTt37uDpp5/GV199pZ1f3OekVCqxfft2TJgwAT169EB2djYaN26MJUuWlDp2IirC7Rhg+7TC5zt6V1wsD1GIqQ1iKKHk5GQ4OjoiKSkJDg4OOvPS09MRGxuLunXrwsrKykgRVl9qtRqNGjXCgAEDSp2YkOmZOXMm1q9fX+lufcD9AVERTq4E/nyz8PmTYgBbl8Lnl0JRv995sUeGKszly5exfft2dOrUCRkZGfjyyy8RGxuLwYMHGzs0IiIqSlFJDAAojDfkloN9qcKYmZlhxYoVaNu2LTp06IDw8HDs3LkTjRo1KnWbTZo00TnNN+8jdzwFERHpoaADNP9GAauHFL+sERMZHlpiV7JJu3z5MrKysgqc5+7urnMdEaKicH9A1drFUOD3EUCvhUDDHkBOFhC1A9g4Frivx/WXpl7V3HfJgHhoiaqFkpwxREREhfixj+Z59SBgZhKwYzpw+Kuil8lLYbhroZUUDy0RERGRrpIkMQBgxkSGiIiIjEGdU/Y22CNDREREFe7ECmDWQ9eAyUoveTtG7JHhGBkiIqLqauPY/GVbp5S8nXK8zU5x2CNDRERED5xYYewISoSJDAEA6tSpgwULFuhdPzQ0FAqFAomJieUWkyHMnDkTLVq0MNr6v/nmG3h7e8PMzKxE27cyuHTpEhQKRaW7Aq8+jP25E1HF4aElE1PcXbJnzJiBmTNnlrjdY8eOwdbWVu/67du3x/Xr1+Ho6FjidVUXycnJGD16NObPn49nnnmG24qIqBwwkTEx169f175es2YNpk+fjsjISG2ZnZ2d9rWIICcnBxYWxX/Mrq6uJYpDqVRq71RMBYuLi0NWVhZ69uwJT0/PUreTlZUFS0tLA0ZGRFR18NCSifHw8NA+HB0doVAotNPnz5+Hvb09tmzZgtatW0OlUmH//v2IiYlBnz594O7uDjs7O7Rt2xY7d+7UaffhQ0sKhQLfffcd+vXrBxsbG9SvXx8bNmzQzn/40NKKFSvg5OSEbdu2oVGjRrCzs0O3bt10Eq/s7GyMGTMGTk5OqFmzJqZMmYKhQ4eib9++Rb7nb7/9Ft7e3rCxsUG/fv0wf/58ODk5lWr7qdVqfPjhh6hduzZUKhVatGiBrVu3audnZmZi9OjR8PT0hJWVFXx9fTFr1iwAmsRw5syZ8PHxgUqlgpeXF8aMGVPgelasWIHAwEAAgJ+fHxQKBS5dugQAWLp0KerVqwelUomAgAD89NNPOssqFAosXboUvXv3hq2tLT755JMC15GRkYGJEyeiVq1asLW1RVBQEEJDQ7Xzb9++jUGDBqFWrVqwsbFBYGAgVq1alW97zJ49G/7+/lCpVPDx8cm3vosXL+Lxxx+HjY0NmjdvjkOHDhW5jRMTE/Hqq6/C1dUVDg4OeOKJJ3Dq1Cnt/NzDPsuWLdN+rgMGDNC5K3dxnxMAXL16FYMGDYKzszNsbW3Rpk0bHDlyRKfOTz/9hDp16sDR0RHPP/887t27V2TsRFQKL6wz6uqZyOQlAmTeN87DgHeKeOedd/DZZ58hIiICzZo1Q0pKCnr06IFdu3bh5MmT6NatG3r16oW4uLgi2/nggw8wYMAAnD59Gj169MCQIUNw586dQuunpqZi7ty5+Omnn7B3717ExcVh4sSJ2vmff/45Vq5cieXLl+PAgQNITk7G+vXri4zhwIEDeP311zF27FiEhYXhySefLPSHXR8LFy7EvHnzMHfuXJw+fRpdu3ZF7969ERUVBQBYtGgRNmzYgF9//RWRkZFYuXIl6tSpAwD4/fff8cUXX2DZsmWIiorC+vXrtcnKwwYOHKhNFo8ePYrr16/D29sbf/zxB8aOHYsJEybgzJkzeO211/Dyyy9j9+7dOsvPnDkT/fr1Q3h4OIYPH17gOkaPHo1Dhw5h9erVOH36NJ577jl069ZN+17S09PRunVrbNq0CWfOnMHIkSPx4osv4ujRo9o2pk6dis8++wzvv/8+zp07h19++QXu7u4663nvvfcwceJEhIWFoUGDBhg0aBCys7ML3cbPPfccbt68iS1btuDEiRNo1aoVunTpovPdiY6Oxq+//oqNGzdi69atOHnyJN5888FN6Yr7nFJSUtCpUydcu3YNGzZswKlTpzB58mSo1WptGzExMVi/fj3++usv/PXXX9izZw8+++yzQuMmolLy72Lc9UsVl5SUJAAkKSkp37y0tDQ5d+6cpKWlaQoyUkRmOBjnkZFS4ve2fPlycXR01E7v3r1bAMj69euLXbZJkyayePFi7bSvr6988cUX2mkAMm3aNO10SkqKAJAtW7borOvu3bvaWABIdHS0dpklS5aIu7u7dtrd3V3mzJmjnc7OzhYfHx/p06dPoXEOHDhQevbsqVM2ZMgQnfddlBkzZkjz5s21015eXvLJJ5/o1Gnbtq28+eabIiLy1ltvyRNPPCFqtTpfW/PmzZMGDRpIZmamXus+efKkAJDY2FhtWfv27WXEiBE69Z577jnp0aOHdhqAjBs3rsi2L1++LObm5nLt2jWd8i5dusjUqVMLXa5nz54yYcIEERFJTk4WlUol3377bYF1Y2NjBYB899132rKzZ88KAImIiChwmX379omDg4Okp6frlNerV0+WLVsmIprPxNzcXK5evaqdv2XLFjEzM5Pr16+LSPGf07Jly8Te3l5u375dYBwzZswQGxsbSU5O1pZNmjRJgoKCCqwvUsD+gKiqu3XBML9f5aSo3++82CNTBbVp00ZnOiUlBRMnTkSjRo3g5OQEOzs7REREFNsj06xZM+1rW1tbODg44ObNwm8eZmNjg3r16mmnPT09tfWTkpJw48YNtGvXTjvf3NwcrVu3LjKGyMhInWUA5JvWV3JyMuLj49GhQwed8g4dOiAiIgIAMGzYMISFhSEgIABjxozB9u3btfWee+45pKWlwc/PDyNGjMAff/xRZM9EQSIiIopcf66HP8OHhYeHIycnBw0aNNC54/eePXsQExMDAMjJycFHH32EwMBAODs7w87ODtu2bdN+7hEREcjIyECXLkX/N5X3e5A71qew78GpU6eQkpKCmjVr6sQVGxurjQsAfHx8UKtWLe10cHAw1Go1IiMj9fqcwsLC0LJlSzg7Oxcad506dXRuGpr3+0hEAFY+Z+wIDIKDffOytAHejTfeug3k4bOPJk6ciB07dmDu3Lnw9/eHtbU1nn32WWRmZhYd0kMDTBUKhU7XvT71xcRurt6qVSvExsZiy5Yt2LlzJwYMGICQkBCsXbsW3t7eiIyMxM6dO7Fjxw68+eabmDNnDvbs2WPwwbjFnUGWkpICc3NznDhxAubmulfUzB3wPWfOHCxcuBALFixAYGAgbG1tMW7cOO3nbm1trVcsed9b7llzhX0PUlJS4OnpqTNWJ1dpxzUVRJ/YS/r9Jap27sYaOwKDYI9MXgoFoLQ1zqMcr4p44MABDBs2DP369UNgYCA8PDy0A08riqOjI9zd3XHs2DFtWU5ODv75558ilwsICNBZBkC+aX05ODjAy8sLBw4c0Ck/cOAAGjdurFNv4MCB+Pbbb7FmzRr8/vvv2vEd1tbW6NWrFxYtWoTQ0FAcOnQI4eHhesfQqFGjYtevj5YtWyInJwc3b96Ev7+/ziP3bLIDBw6gT58+eOGFF9C8eXP4+fnhwoUL2jbq168Pa2tr7Nq1q0TrLkqrVq2QkJAACwuLfHG5uLho68XFxSE+/sE/DYcPH4aZmRkCAgL0+pyaNWuGsLCwIsdsEdFDrp8CQj8DstKMHYlBsUemGqhfvz7WrVuHXr16QaFQ4P333zfKf6ZvvfUWZs2aBX9/fzRs2BCLFy/G3bt3i7w2zltvvYWOHTti/vz56NWrF/7++29s2bKl2OvpFGbSpEmYMWMG6tWrhxYtWmD58uUICwvDypUrAQDz58+Hp6cnWrZsCTMzM/z222/w8PCAk5MTVqxYgZycHAQFBcHGxgY///wzrK2t4evrW6L1DxgwAC1btkRISAg2btyIdevW5TuLrDgNGjTAkCFD8NJLL2HevHlo2bIlbt26hV27dqFZs2bo2bMn6tevj7Vr1+LgwYOoUaMG5s+fjxs3bmiTASsrK0yZMgWTJ0+GUqlEhw4dcOvWLZw9exavvPJKieLJFRISguDgYPTt2xezZ89GgwYNEB8fj02bNqFfv37aQ2ZWVlYYOnQo5s6di+TkZIwZMwYDBgzQJmHFfU6DBg3Cp59+ir59+2LWrFnw9PTEyZMn4eXlheDg4FLFTlSlbZ364I7WWWlGvTeSoTGRqQbmz5+P4cOHo3379nBxccGUKVOQnJxc4XFMmTIFCQkJeOmll2Bubo6RI0eia9eu+Q6N5NWhQwd8/fXX+OCDDzBt2jR07doVb7/9Nr788stSxTBmzBgkJSVhwoQJuHnzJho3bowNGzagfv36AAB7e3vMnj0bUVFRMDc3R9u2bbF582aYmZnByckJn332GcaPH4+cnBwEBgZi48aNqFmzpt7r79u3LxYuXIi5c+di7NixqFu3LpYvX47OnTuX+L0sX74cH3/8MSZMmIBr167BxcUFjzzyCJ5++mkAwLRp03Dx4kV07doVNjY2GDlyJPr27atzmvP7778PCwsLTJ8+HfHx8fD09MTrr79e4lhyKRQKbN68Ge+99x5efvll3Lp1Cx4eHujYsaPO2VD+/v7o378/evTogTt37uDpp5/GV199pZ1f3OekVCqxfft2TJgwAT169EB2djYaN26MJUuWlDp2oirr7uUHSQwAHFhgtFDKg0JMbRBDCSUnJ8PR0RFJSUlwcHDQmZeeno7Y2FjUrVsXVlZWRoqw+lKr1WjUqBEGDBiAjz76SO/lRowYgfPnz2Pfvn3lGB2Vl5kzZ2L9+vWV7tYH3B9QlXX3ErCwuWHa8g4CruherwkzkwquW0ZF/X7nxR4ZqjCXL1/G9u3b0alTJ2RkZODLL79EbGwsBg8eXORyc+fOxZNPPglbW1ts2bIFP/zwg85/70REVARD9le8tEGTGH0VZLg2y4iDfanCmJmZYcWKFWjbti06dOiA8PBw7Ny5E40aNSpyuaNHj+LJJ59EYGAgvv76ayxatAivvvoqAKBJkyY6p/nmfeSOpyAiqtbUJbtMRJEsrQC3hoZrzwDYI0MVxtvbO9+ZKPr49ddfC523efNmZGVlFTjv4SvUUuUwc+bMUt3YlIhKKafgfWRVwUSGTFpJzhgiIqqS1Dmah4WykPllSGTePPLgMJKich7EqZxRVbAqPt6ZiPTA/QCZrO+7AR+7ApmpuuURfwFfPwoknCl921YOwMQooN1rwOv7yxZnOanWiUzulT9TU1OLqUlEVV3ufsDQV2kmKndX/7sR7N8fPyi7GQGsGQIkhAN/vlnwcvowswTs3IAeswH3JmWLs5xU60NL5ubmcHJy0t5/xcbGptQXWiMi0yQiSE1Nxc2bN+Hk5FTkdY2IKrXDS4BunwJJ14CvHjFMmyZw4bxqncgA0F5JlDeTI6renJyctPsDIpPx8CHRhDNAsgHvGWheWA+lAkDlOBxb7RMZhUIBT09PuLm5FXr2CxFVbZaWluyJIdOkztGdTggHbPS/2nixKukA37yqfSKTy9zcnDsyIiIyHcnxgOVDd4K/HQXYuhRcv6SsHAGLQu40r1AY9kJ7ZVD5Uy0iIiLSdTsGmN8IWPDQrQf2zYPmsE8puQQ8eD0xCjArLE2oPONJ2SNDRERkSq4eB77ronmdUcB9jm6eLV27tdsCQ/8CzvwO1HsCsFAVXrdWa83ZUqrC74FUUar1TSOJiIhMzkzH8mn3lR2Adzv96ibHA/u/ANqOAFwblEs4vGkkERER6c+8kCsDF8TBC+gxp/xiKQGOkSEiIiKTOEOpIKYZNRERERmWCVz8riBMZIiIiKqb+l3zl7FHhoiIiExCk775yxTskSEiIiJT8PAVgQEeWiIiIiITIer8ZSZ602QmMkRERFWZvVf+soISmUp0td6SYCJDRERUlXX7VHe6Rp1CEhnTxESGiIjIVOz6sBQLPdTTMmQtkJNVQDX2yBAREZGhZGcCcUeAnGzNdNLV/24KWUJ5ExR7T8ClPtC0P+DkA7R7zTCxGhFvUUBERFTZiAB/jQPCVmqmB60BatYrZWOK/K/t3IBx4UDmfeDosgLqmQ4mMkRERJWJOgf4pjOQcPpB2aqBQJvhpWsvb4+MVTndcNKIeGiJiIioMvn3gm4Sk+v496VsUAEMXAm4NQae/V8R1UyzR8aoicysWbPQtm1b2Nvbw83NDX379kVkZKROnfT0dIwaNQo1a9aEnZ0dnnnmGdy4ccNIERMREZkYhQJo9DTw5iHAvYnuPEsboHZbwD0QcKhtnPjKyKiJzJ49ezBq1CgcPnwYO3bsQFZWFp566incv39fW+ftt9/Gxo0b8dtvv2HPnj2Ij49H//79jRg1ERFReTJ0z0gR7SkUwCs7gNf2AmameZDGqGNktm7dqjO9YsUKuLm54cSJE+jYsSOSkpLwv//9D7/88gueeOIJAMDy5cvRqFEjHD58GI888ogxwiYiIqrcmg8GTv2ieV3cISOFwmQPKwGVbIxMUlISAMDZ2RkAcOLECWRlZSEkJERbp2HDhvDx8cGhQ4cKbCMjIwPJyck6DyIiomrFtmaeCdNNUvRRaRIZtVqNcePGoUOHDmjatCkAICEhAUqlEk5OTjp13d3dkZCQUGA7s2bNgqOjo/bh7e1d3qETERGV3aUDwKpBQGJc2dt6dPyD1ybc26KPSnP69ahRo3DmzBns37+/TO1MnToV48c/+ACTk5OZzBARUeW0cSxwYgUQPBo49KWmLHZf2du1cc4zwUSm3I0ePRp//fUX9u7di9q1H4ya9vDwQGZmJhITE3V6ZW7cuAEPD48C21KpVFCpVOUdMhERUdmdWKF5zk1iACDznmHXUcV7ZIx6aElEMHr0aPzxxx/4+++/UbduXZ35rVu3hqWlJXbt2qUti4yMRFxcHIKDgys6XCIiIqpkjNojM2rUKPzyyy/4888/YW9vrx334ujoCGtrazg6OuKVV17B+PHj4ezsDAcHB7z11lsIDg7mGUtERET6sHUxdgTlyqiJzNKlSwEAnTt31ilfvnw5hg0bBgD44osvYGZmhmeeeQYZGRno2rUrvvrqqwqOlIiIyICidgK3owzfbs/5QK1WmtfPfq8ZOOzV0vDrqUQUIiLGDqI8JScnw9HREUlJSXBwcDB2OERERMDMcrrn0cyk8mnXCPT9/a40p18TERERlRQTGSIiIjJZTGSIiIgq0vVTxo6gSmEiQ0REVFFO/AAs61iyZXx4uZGiMJEhIiKqKBvHlHwZ+4IvAIuJ0WWLpYqoFFf2JSIiqpJysoD9C4CUBM1tCAzJzlV3OnCAYds3EUxkiIiIysvRb4HdH2teH/uudG3YFdIjk9cT7wOPTShd+yaOh5aIiIjKS/zJsrfReQrQ8Gndsud+0J1WOVT5eyoVhokMERGRIanVwPo3gSPLABjgmrPWNYDnVz6YrukPNOn70Dqzy74eE8VDS0RERIYgAmwYDfwbBVw5AoStBAKfK1ub5sr8ZXbuD163GAJEbQdaDCrbekwYExkiIiJDuHwAOPmzbllGSunbGxcOWDk9mH7+F+DAQqDPkgdlfb8C1DmAmXnp12PimMgQERGV1saxgKiB3ouBewn551/YUvq2nXx0pxv21DweVo2TGIBjZIiIiEon7S5wYgXwz4/A/dvGjqbaYiJDRERUGuqcB69FDZhbGi+WaoyJDBERUWmI+qFpA5yhRCXGRIaIiKg08p7yLDnV+hRoY2IiQ0REVBrJ8Q9ep90Ffn/FeLFUYzxriYiIqDS+6/Lg9bqRhmu3+2ze8boEmMgQERGVxL0bwLUTumUJpw3XftBrhmurGuChJSIiIn1lpACLWwGry3gl3cffK7i8QfeytVsNsUeGiIhIH5mpwKxahmmrdtuCywf+XHA5FYo9MkRERPq4HWW4thLj8pc51ALM2b9QUkxkiIiIipKZCsQd1r0AXlkpHvr59Q4CBv9quParEaZ+RERERVn1PBC7B2j6rOHazE5/8NqrFfDKdsO1Xc2wR4aIiKgosXs0z2fWGq5NhzxjbRQKw7VbDTGRISIiKi8dJ+UvC/kACMhzdtLDh5moRLj1iIiIysPQv4DOUzWHjvJ6dJxuLwwTmTLh1iMiIioPXi0BM/PCB/HWqKN5bty3oiKqkpjIEBERlQez/86nsXMFeszVvFY5Ppg/YrcmyeGVfMuEZy0RERHlyrwPXDkK1HkUMLcEzq4vfVtm5g9et34ZsHUBvB95UGbjDDToWvr2CQATGSIiogd+fxWI3Aw0fUbTo3J6TenbUuRJZMwtgCb9yh4f5cNEhoiIKFfkZs3zmd/L3pYZR29UBG5lIiIiMllMZIiIiABAxNgRUCkwkSEiIooPA+bUM3YUVApMZIiIiNaNAFJvGzsKKgUmMkREVLWFrQKuHCt8fnaG5rTr0npxfemXpTLjWUtERFR1xR0G1r+ueT0zSXde2l3gzDpg0/iyrcNCVbblqUyYyBARUdX1b1Th89a8CFzaV/Z1mDORMSYmMkREVHUVdENGEeDuJcMkMQCgsjdMO1QqHCNDRERVV967TOc6sABY1KL0bfb5SnfapT7QZjjQfgwQ8kHp26VSYSJDRERVU2IcsGN6/vKdM8vWbsshutMKBfD0F8BTHz24USRVGG5xIiKqmn7qD9y/9WBaBIjYWL7rtLQq3/YpH/bIEBFR1ZFyE0i6qnl9+6GBvuc3Ab++WLb2mw/WPLcaqnnuvVh3foshgE97oEsBPUFULhQiVfuazMnJyXB0dERSUhIcHByMHQ4REZUHEeDIMmDrFM301KvArNqGX897CYCltWZ9qXcA25qGXwcB0P/3mz0yRERk+mL+fpDEAED0zvJZj6W15lmhYBJTSTCRISIi03fnou70b8PK1l77MYClbdnaoArBRIaIiEyfoUdJ1G4LvBcPuAcatl0yOCYyRERUBRg4kRF1/rJXdhh2HWQQTGSIiMj0GbpHxtYlf5l3O8OugwyCiQwREZm2uCNA7F7DtunbwbDtUblhIkNERKZLrQa+fwqI3FT2tvw6P3ide2uDx6dqnlsMyVedKgde2ZeIiEyXOtsw7dR5DHColb+8YU9gQiRg526Y9ZDBMZEhIiLTlBAOrH+j7O2MOgrUqAtk3NM8Wr2kO9/eo+zroHLDRIaIiExLzG7A2gn4prNh2nMN0Dxb1AQG/mSYNqnCMJEhIiLTceUo8FNfY0dBlQgH+xIRkem4csTYEVAlY9REZu/evejVqxe8vLygUCiwfv16nfnDhg2DQqHQeXTr1s04wRIRkfFV7fscUykYNZG5f/8+mjdvjiVLlhRap1u3brh+/br2sWrVqgqMkIiIKpWCrrhbEi4BQNDrhomFKgWjjpHp3r07unfvXmQdlUoFDw+OGCciIpQ9kRl9VPP8z09A1v2yx0NGV+nHyISGhsLNzQ0BAQF44403cPv2bWOHRERE5e2fn4A1LwIXtgF/vAGk3gF+HwEc+tJAK+AhqqqiUp+11K1bN/Tv3x9169ZFTEwM3n33XXTv3h2HDh2Cubl5gctkZGQgIyNDO52cnFxR4RIRkaFsGK15jtigeb68H0iMK1ubzQY+eO3kA9w6X7b2qFKo1InM888/r30dGBiIZs2aoV69eggNDUWXLl0KXGbWrFn44IMPKipEIiKqCGVNYgCg79IHrwf+DGx9B+g4qeztklFV+kNLefn5+cHFxQXR0dGF1pk6dSqSkpK0jytXrlRghEREVCnVqAuY5enJd6kPvPA74POI8WIig6jUPTIPu3r1Km7fvg1PT89C66hUKqhUqgqMioiIDCor3fBtlnWQMFVaRk1kUlJSdHpXYmNjERYWBmdnZzg7O+ODDz7AM888Aw8PD8TExGDy5Mnw9/dH165djRg1ERGVq71zyqFRDu6tqox6aOn48eNo2bIlWrZsCQAYP348WrZsienTp8Pc3BynT59G79690aBBA7zyyito3bo19u3bxx4XIqKq7PxfZVve0hZ4ZSegcnxQ5lyvbG1SpWXUHpnOnTtDirhK47Zt2yowGiIiMjp1DnD3ctnb8W4LTI0DrhwDji4Dnvyw7G1SpWRSY2SIiKiK2z8fyE4zXHvebTUPqrKYyBARkfGlJwOXDwB/f2yAxjgepjphIkNERMb3mXfZlm83Evg3Cri4m/dSqmaYyBARkekLeh1w8AKunQC8eW2Y6sSkLohHREQmLmoHcPC/+yWJAOc3A0lXy9Zm36+BmvUAS2ugzqOAOf9Hr074aRMRUcVZ+azmuVYr4N51YO1wAIqytVmnQ5nDItPFRIaIiCre8u55JvQcnOvSAPj3Qv5ypZ1BQiLTxENLRERUfkSAda8BG8eVva1eCwsuV9mXvW0yWeyRISKi8pMcD5xerXl9YnnZ2vJtX3C5uWXZ2iWTxkSGiIjKR1oisLybYdscFw5kpgJuDYGLoYCVY7GLUNXGRIaIiAxPrQY+9zV8u04+D177dTZ8+2RyOEaGiIgMb80QY0dA1QQTGSIiMrzIzWVbvt83utMv/F629qjKYiJDRESVT5O+D14P+AnwDzFaKFS5MZEhIqLKR8GfJ9IPvylERGRY2RllbyNvIqMo45V/qUpjIkNERIZ1apX+dTtPLbicPTKkJ35TiIjIsDZP0r9u53cKLtfphWGPDBWOiQwREZVOcjxwaX/+8pzMsrVb57GyLU/VCi+IR0REpTO/kebZPwR45E1A5QDUblP8ch3GAjfOAQHddcsdagODVwM16xs+VqqymMgQEVHZRO/UPABAYV58fUtb4IW1+csVCsAjsOByokKU6tDSlStXcPXqVe300aNHMW7cOHzzzTdFLEVERFWe5BRfx0yPZIdIT6VKZAYPHozdu3cDABISEvDkk0/i6NGjeO+99/Dhhx8aNEAiIqpiLKyMHQFVIaVKZM6cOYN27doBAH799Vc0bdoUBw8exMqVK7FixQpDxkdERFWBZ4sHry1UhVTiISQquVIlMllZWVCpNF/EnTt3onfv3gCAhg0b4vr164aLjoiIKg+1Gvj9VWDvHCAnq2TL1nviwetCE5nCMMGhwpUqkWnSpAm+/vpr7Nu3Dzt27EC3bt0AAPHx8ahZs6ZBAyQiokoi7iAQ/hvw98dAVlrJls1MefDapoS/EzXqlKw+VSulSmQ+//xzLFu2DJ07d8agQYPQvHlzAMCGDRu0h5yIiKiKOPot8MvzQMa9B2Uxu0rYxjdA/a6ASwOgXpeC6zzc8fLKTmDAj4B745Kti6qVUp1+3blzZ/z7779ITk5GjRo1tOUjR46EjY2NwYIjIqJKYPNEzXPi5Qdlvw0reTuD1wAigJme/0N7ty35OqjaKVWPTFpaGjIyMrRJzOXLl7FgwQJERkbCzc3NoAESEVElcfNcyep3n607rVAUnMT4ddY8txleqrCoeitVItOnTx/8+OOPAIDExEQEBQVh3rx56Nu3L5YuXWrQAImIyAjC1wJ/jS/9nawtrIB2Ix9MWzkVXvf5VcDLW4H2Y0q3LqrWSpXI/PPPP3jsMc29MNauXQt3d3dcvnwZP/74IxYtWmTQAImIyAh+fwU4/j9gWafSLe/bQfeKvD3nFV5XaQP4BvNCeVQqpRojk5qaCnt7ewDA9u3b0b9/f5iZmeGRRx7B5cuXi1maiIhMxq2Ioud3fhewtAbavgJ86vWgvHFv3Xr2HoaPjQil7JHx9/fH+vXrceXKFWzbtg1PPfUUAODmzZtwcHAwaIBERFSBEs4A+xfoX7/zFKDDGEBpC7j/d5+kDmOBli/p1qtR12AhEuVVqh6Z6dOnY/DgwXj77bfxxBNPIDg4GICmd6Zly5YGDZCIiMrRuT8BJx/AqyVw4yzwdYfSt/XqDiDpGuDi/6DsjYNAehLgWKvssRIVQCEiUpoFExIScP36dTRv3hxm/41CP3r0KBwcHNCwYUODBlkWycnJcHR0RFJSEnuLiIjyij8JfNNZ83rCBWBeg5It71ALGF/CM5mI9KTv73epemQAwMPDAx4eHtq7YNeuXZsXwyMiMiU38iQhJU1iiCqJUo2RUavV+PDDD+Ho6AhfX1/4+vrCyckJH330EdRqtaFjJCKi8pBTylOrW76oeX78XcPFQlRKpeqRee+99/C///0Pn332GTp00BxP3b9/P2bOnIn09HR88sknBg2SiIjKQUlv/Jir1yLgsfGAs59h4yEqhVIlMj/88AO+++477V2vAaBZs2aoVasW3nzzTSYyRESmIDGudMuZmTGJoUqjVIeW7ty5U+CA3oYNG+LOnTtlDoqIiMpJehKwaaLmyr2Hviy8XvNBBZcP+b184iIqpVIlMs2bN8eXX+b/A/jyyy/RrFmzMgdFRETlZPUQ4Ni3miv3FuWpjwsuN7c0fExEZVCqQ0uzZ89Gz549sXPnTu01ZA4dOoQrV65g8+bNBg2QiIjKKDkeSE8GXAOAK0eLr+/oA9i6FDyvdhvDxkZURqXqkenUqRMuXLiAfv36ITExEYmJiejfvz/Onj2Ln376ydAxEhFRWcxvBHwVBCxqqd+ZSl4tdKfrdfnv+QnNFXyJKpFSXxCvIKdOnUKrVq2Qk5NjqCbLjBfEI6JqKeMeYGYJSI7uPZD0MekiYFsTmOmomW4zXHOoydJG90aQROVI39/vUvXIEBFRJZaVBsz2AxYEAvf/LfnytjV1pxVmmp4YJjFUCTGRISKqam7HADmZwP2bQMqNsrenMC97G0TlhIkMEVFVY5bnPI5VhZxGXaL2mMhQ5VWis5b69+9f5PzExMSyxEJERIZw99KD16mlOLSUq+mzwJm1QLsRZQ6JqLyUKJFxdHQsdv5LL71UpoCIiKiERICkK4CTj+b1qoElW775IMDWFTi4CGgx5EH5M98BvRcDShvDxktkQAY9a6ky4llLRFTlbZkCHPla87peFyBml/7LegcBr2zXvM68zzOTqNLgWUtERNVFbhID6J/EPPKm5mykrp8+KOOZSWSCSnVlXyIiqiQyUkq3XNdPgS4zAEsrw8ZDVMGYyBARmZrUO8CWyZrxLOf/KtmyZpbA4DWanhcmMVQFMJEhIjI1O6YD4b9pHiU1vQxnMRFVQkxkiIhMhQhwfhNw5YixIyGqNJjIEBGZilOrgPVvGDsKokqFiQwRUWWXdBU4+TMQtaP0bdRuB7R52XAxEVUSTGSIiCq7H3oBdy6WfLlarYFrJzSvXy1DEkRUiRn1OjJ79+5Fr1694OXlBYVCgfXr1+vMFxFMnz4dnp6esLa2RkhICKKioowTLBFRRTq4GFg1GMjJKl0SAwAvbQBG7AbGhBk0NKLKxKiJzP3799G8eXMsWbKkwPmzZ8/GokWL8PXXX+PIkSOwtbVF165dkZ6eXsGREhFVsO3TgMhNwIkVpVu+/7eAyg6o1QpwrmvQ0IgqE6MeWurevTu6d+9e4DwRwYIFCzBt2jT06dMHAPDjjz/C3d0d69evx/PPP1+RoRIRGcfmiaVbrmrffYZIq9LeoiA2NhYJCQkICQnRljk6OiIoKAiHDh0qdLmMjAwkJyfrPIiITIohkhDXBmVvg8gEVNrBvgkJCQAAd3d3nXJ3d3ftvILMmjULH3zwQbnGRkRkcCLArg8AzxZA2C+lb6fPEkDlAHi1NFhoRJVZpe2RKa2pU6ciKSlJ+7hy5YqxQyIiKl7M38D+L4DfhgJR20q27BPTHrz2agk07m3Y2IgqsUqbyHh4eAAAbty4oVN+48YN7byCqFQqODg46DyIiCq9tLulX7btqw9eK8zLHguRCam0iUzdunXh4eGBXbse3JI+OTkZR44cQXBwsBEjIyIysIi/gN9f0a+uozfw4nrdMisnwK8z4NUKcKlv4OCIKjejjpFJSUlBdHS0djo2NhZhYWFwdnaGj48Pxo0bh48//hj169dH3bp18f7778PLywt9+/Y1XtBERIa2Zoj+dc3MgXqP65YpFA+SG4XCYGERmQKjJjLHjx/H448/+IMcP348AGDo0KFYsWIFJk+ejPv372PkyJFITEzEo48+iq1bt8LKireeJyITlnRNc+dqOzcg837JljX7b7cdOAAI//VBORMYqqYUIlX7YgPJyclwdHREUlISx8sQUeXw9aNAQnjplnVtBIw6DBxYCOyYrimbmWS42IgqCX1/vyvt6ddERFVS0tXSJzEA0Gmy5jnoDSArHfAPKbo+URXHRIaIqCLsnQPE7AYuHyjd8v2/BXyCASdvzbSFEug8xXDxEZkoJjJERBXh749LVt/CGnh8KnBkGTBkLeDeuHziIjJxTGSIiCqj1/ZqbjPQYayxIyGq1CrtdWSIiKo13iuJSC9MZIiIytvx5caOgKjK4qElIqLykpMFZNwD/hpXsuXcOB6GSF9MZIiIDOmv8YCVA+D7KPDri0CjUtzA8fky3P2aqJphIkNEZCgpt4Dj/9O83v+F5vn06oLrBr2huct1Tjbw7H/LHF4KPPUx4Fir/GMlqiKYyBARGUpOpv51bZyB0ccBhdmD2wt4tyufuIiqMCYyRESGcuw7/etaOWluAElEZcJEhoioNDJTAUtrIPkasHWqZlzMyZ/1XFgB1HuiXMMjqi6YyBARldTlQ8DybqVffnwE4OBpuHiIqjFeR4aIqKS2TdW/7uPTAEdvwKvlgzImMUQGwx4ZIqKSyEgB4k/qX7/TJM0j6ZrmfkuPvF5+sRFVQ0xkiIhKYmFz/es6eud5XQvot9Tw8RBVc0xkiIj0lZ4MpP5bfL1hm4G7lwD/LuUeElF1x0SGiEgf6UnAnPr61fVtD9TpUL7xEBEADvYlItLPxVAgJ6P4ejYuDy5wR0Tljj0yRETFSbwCZKUXPv+JaYB7U811ZHovrri4iIiJDBFRobIzNYN778UXXa/jJM1zQPfyj4mIdPDQEhFRYfbNLTqJcW8KvLy14uIhonzYI0NEVJjoXUXPf3UXYGlVMbEQUYHYI0NEVJhrx4ueb6GqmDiIqFDskSEietjpX4GwlcXX49lJREbHRIaIKK+oHcC6EUXX6TkPaPpMxcRDREViIkNElOvgl8D29wqf37gP0O0zwMGr4mIioiIxkSGi6k2dA/zzA3BxD3BufdF1bVyYxBBVMkxkiKj6Kq4HBgBe2wvcOAv88xPQeWrFxEVEemMiQ0TVk0jxSQwAeDbXPFoMLv+YiKjEePo1EVVPOVnF1xm0uvzjIKIyYY8MEVUvaYnAzQhgebei6z27nLccIDIBTGSIqHpZ0g5IuaFbZuMCpP6rW9a4b4WFRESlx0SGiKqH7Axg79z8SQwATIrWHGq6FQFkpQG12wJmPPJOZAqYyBBR1Xb5IHDuT+DI14XXUSgAC6VmUC8RmRQmMkRUdWWmAsuLGefi6FMxsRBRuWDfKRFVPeoczenVaXeKr/vKtvKPh4jKDXtkiKhqSUsElgQBfp2A6J1F152RyBs/Epk49sgQUdVyeg2QkqB5Tr1dcJ2gN4D3EpjEEFUBTGSIqOrISAG2TC6+XqfJgKV1+cdDROWOh5aIyPRlpACXDwC/DCi8TssXgVuRQJN+gI1zxcVGROWKiQwRmb5VzwOX9hVdp8+XFRMLEVUoJjJEZLriw4AfegEZyUXXGxlaEdEQkRFwjAwRma4/Xis+iQEAr5blHwsRGQUTGSIyXYWdlZTXdD2uJUNEJouJDBGZpmv/APdv5S93CQDsPR9Mm5lXXExEVOGYyBCR6RABji8HzvwOfPt4wXWG/ArUbqN5ba6suNiIyCg42JeITEf0LuCvcQXPc2sMvHlI8/rphUCNOppTromoSmMiQ0SmQQTY9UHB8xo+DQz46cG0bU3gqY8rJi4iMiomMkRU+SXGAQsCC5434QJg716x8RBRpcExMkRUue2bX3gS02sRkxiiao6JDBFVXtdPFXw4ycoJ6LMEaD20wkMiosqFh5aIqPJa1rHg8ncuV2wcRFRpsUeGiCqfK0eBmY75y5sPAt65UvHxEFGlxR4ZIqpcstKA/z2Zv9zJF3h6AWBpVeEhEVHlxUSGiCqHrDRgWSfg38j88xp0AwavqfiYiKjSYyJDRMZ3OwZY3Krw+X2XVlwsRGRSKvUYmZkzZ0KhUOg8GjZsaOywiMjQCkti/EOAQasBG+eKjYeITEal75Fp0qQJdu7cqZ22sKj0IRORvk78AGwcU/C8mUkVGwsRmaRKnxVYWFjAw8PD2GEQkaFtmgAc+y5/+Wt7AfemFR8PEZmkSn1oCQCioqLg5eUFPz8/DBkyBHFxccYOiYjKKier4CQGADyaAWbmFRsPEZmsSt0jExQUhBUrViAgIADXr1/HBx98gMceewxnzpyBvb19gctkZGQgIyNDO52cnFxR4RKRPgq7b1KPuUCDroBCUfExEZHJUoiIGDsIfSUmJsLX1xfz58/HK6+8UmCdmTNn4oMP8l/SPCkpCQ4ODuUdIhEVJi0R2P8FcGBB/nkcD0NED0lOToajo2Oxv9+V/tBSXk5OTmjQoAGio6MLrTN16lQkJSVpH1eu8CqgRJXC574FJzFBb1R4KERUdZhUIpOSkoKYmBh4enoWWkelUsHBwUHnQURG9mOfgsvbvAJ0mV6xsRBRlVKpx8hMnDgRvXr1gq+vL+Lj4zFjxgyYm5tj0KBBxg6NiPRR2HgYAHg3HlDaVmw8RFTlVOpE5urVqxg0aBBu374NV1dXPProozh8+DBcXV2NHRoRFSc7s+Ak5o2DgGNtJjFEZBCVOpFZvXq1sUMgotIQAb5snb+89TDAvUmFh0NEVVelTmSIyATdvQQsbJ6/vO0IoOfcCg+HiKo2JjJEZDgptwpOYnot1PTGEBEZGBMZIjKMtLvAXP/85VMuA9ZOFR4OEVUPTGSIqOzWjQROr9EtGxcOOPkYJx4iqjaYyBBR6aXe0SQx0Tt0y80smMQQUYVgIkNEpRMfBnzTKX+5hRXwDm/uSkQVw6Su7EtElcTeuQUnMR0nA9NuABaqio+JiKol9sgQkf6yMzQXuUu5kX/eq7uA2m0qPiYiqtaYyBCRfu5cBBa1zF/+9AKgzcsVHg4REcBEhoj0EXcE+P6p/OX9vwOaPVfx8RAR/YeJDBEVbf8XwM6Z+cun3wXMOMyOiIyLeyEiKlx6UsFJzLvxTGKIqFJgjwwRFWymY8Hl7/8LmFtWbCxERIXgv1RElN/29/OXNR8MTLjAJIaIKhX2yBDRA0nXgK87aO6blFfHScDj7wEKhXHiIiIqBBMZItJQ5wBfNNYte/oLoM1w48RDRKQHJjJE1V1GCrBtKvDPj7rlfb4CWg4xTkxERHriGBmi6m7njPxJzOPvMYkhIpPAHhmi6irtLvB5nfzlL/0J+HWu6GiIiEqFiQxRdZR0Lf94mNrtgFd3GCceIqJS4qEloupm+7T8SQzAJIaITBJ7ZIiqi+wM4GO3/OV9lgABPSo+HiIiA2AiQ1TVqdXA4a+A7e/plptZAhPOA7YuxomLiMgAmMgQVWWZqcCnnvnL6zwGDPur4uMhIjIwJjJEVZEIkBAOLHss/7w+SzSJDBFRFcBEhqgqEQFOrQbWv55/Xq9FQKuXeJsBIqpSmMiUxflNgEcg4ORj7EiINKdUH/4KOPSlbnmLF4CuHwPWNYwTFxFROWIiU1rRu4DVgwGFGTDjbvH1icrLkW+ALZMKnvf0AqDNyxUaDhFRRWIiU1oxf2ueRW3cOKh6i9pRcBLT9Bmg3zeAOf/Eiahq416utHIyjR0BVXcrBwBR2/KXvxMHWDlWfDxEREbARKbUOGCSjGTXR8C+ufnLp90CLJQVHw8RkRExkSktBe/uQBXs3g1gXoOC5025xCSGiKolJjKllfcUVrUaMGNiQ+Xol4HAha35y1sNBXot5CnVRFRtMZEptTw/HJID3n+TDC47A0i9A6x8DrgRrjuvRl1gbJhRwiIiqkyYyJSWTo9MNmBuabxYqOrZMxvY/Un+8vpPAY+8AfgEV3xMRESVEBMZQ1BnGzsCqiqSrgE/9wdunc8/77kfgCZ9KzwkIqLKjIlMaeUd7FteiYwIxz5UB6l3gLPrgE0TCp7vHQT0mAN4Nq/YuIiITAATmdJ6eLCvoR1ZBoTOAoZu1NwGgaqe5Oua3peb5/LPs7ACGnQFnvoEcPKu+NiIiEwEE5nSEnnwujx6ZLZM1jxvHAeM2GX49sk4onYAlw8A+78ovE6HscCTH1ZcTEREJoyJTGnlvTVBuY6RkeKrUOV3/19g80Tg7B+F1+k4GXh0HKC0rbCwiIhMHROZ0qqoREbKKZG5sA2o6Q/UrFc+7RdEnQNAUT2uuSMCZKUBa4Y8uC9XQbrOAloPZfJCRFRKTGRKS52T53UlP2tp67tA3EHg5S2ApTVw6QDwywDNvJlJZWs7OwOI3ALU7QjYOBdeT50DfPWIZv0j91TOQcwiwM6ZgFtjwKsF4OQLWFrlr3f3EpCTDdi5ad6TmTnw6t+aZOR2FLCsY/Hr6jEXaDfCwG+AiKj6YSJTWnl7ZEpyB+xrJ4CDi4GQmYCFNbCiB9DyRc0hBX3EnwTSkwG/TgXPT4wDHL01icLdS0B2JnB4iWbe+U1A4LPAteMP6qtzgJwsIHqHJhkp6c0GQ2dpxnt4tgBe21N4vaQrwL8XNK+z0gClTcnWAwD75mnO8OlawPVViiICRO8CXPyBGnU00xn3gP3zgfpdgdvRmrtF3zgDHFjwYLkadYCxpx5Mxx0Gvu9a8Drm+usXy5TLgLVTyeInIqJCMZEpLcnTI7N6MBDyAdCwR8F1897C4NsnNM+JcUCt1pof0Z0z9E9kvumseX5sAhC+Fui3DFjeTVMWMlPTo9DuNaD758DCh07Xjd6pORvKvcmDsg+dAdeGmuuW1O0EDN1Q+LrVak2CpFAAh5dqDk9dD9PMy33OKyFckzD4ttctz8kEciyBlJuAg5emvTsXgX3zNe/LuW7+tmL3Abv+GwDb8kXArWHhcT7s7Dpg7XDAqxVg66q5Y3StNpqELnfQ7aV9QMsXdJe7e6nwC9Ppq3ZbzXfDvYkmSayMPVFERCaMiUxp5T209O8FYPUg4NVdQO02utd/uRkBfN8NePRt3WTldoxuQnHtH2DP54BLA828guTkOYS1b57mOTeJATRJDAAcXVbwWS+nVmmerx7VLc+9+Fpsnh6Vy4eAY98Cdh6aJKXNcGD3p8CdGM24jm1T87d/7wYQswto0E1zmOnrRzXlb5/T3V7ZGcC2d4GwlUCnd4CLoZpDMqm3gZM/AZNjNVdKVtkDN84BZ9Y+eL8AsGO65rBM/Sf/2y5Zmt6mW5FA0GvA574FbDwA8f88eJ23VwoATq/RPB5WmiRmQqTmvShtNb06RERUbhQi5TWatHJITk6Go6MjkpKS4ODgYLiGLx/STSJy2XsC2elA2l3NWShXj2p+qAHNeJSZ/x26sXbWHMo5t774ddVqoxmzEXck/z13KqsplwtPKOzcgZQbhS/r2gi4FVE+cRlK3Y6aBOrZ7zW9SkREZFD6/n6zR6a0fAu518296w9e752tGTuS69eXHrxOu6NfEgNoeg8e7kGo7MJWFj6vqCQGqBxJjHUNTc/TvXig2UBN4mlmDliojB0ZERHlwUSmvOUdO3LuT6OFUeG2vWvsCDTqPAYkXtaMScrV/zsgPVEzJignA3D20yRXzn5GC5OIiEqHiQxVDbauwOPvagbUhq3SjJWp10X3mjVZaZp7ZBXUq8IkhojIJDGRKYuXNgA/9jZ2FEWzcgR8OwCRmx+UNe6juY6JleODAcIdJ2kGpx7+CvBpD/gEPRjPAwC12wHP/g84+KVmMHFeAT102y+Mcz3A5xHg7mXNWUctX9CcheXaCHBrpGln+zTAXAk0elpzVte+eZp7EXWZoRkwfe+6ZjB03ceAzPvAka81h34caz9YT9NnCl6/pbU+W4yIiEwIB/uWUfbVf2Dx3eOlb+CNg5qegn+jgPWva8qa9NecMpyrXheo78Qiy8EHqsuh2mJ1474wC+iuOb1Z1IC5SvPjnp4E1Gqlc6pvesIFIHITrIJfK/AaLtk5aggAS3MzqNUCtQgs4o9rko5mz+lWTr4OqLM0p38nXQW6zQKWddKMbRkTBjj5AAmnNVcONldpzn66FQl0focDY4mISC/6/n4zkSmDyIR76LpgL2orbqKVIgr+ZtcwxmI9AOCK2hWTs0dilVJz+m5IxmzcEGfUVtzCRItf8U320zgijfK16YIk/AtH+Nll48X0lVif0wHRlgG4n/ng9OWaSEIns1PYpH4EGVBiyeBW2HEuAevD4vFUY3fM6N0E0TdTcDLuLrycrGGmUGDib5oLu83qH4hmtR2x/uQ1XEtMg7OtEgHu9nj/z7MAgP1THkffJQeRkZWDFcPbITktCzeS0+HuaIVH6tZEQnI6Tl9NxJbwBGw9m4BJXQPQ2rcGXGzM8cvBaCiUNrh7PxPjQhrAzUGF45fuoqGnPZxtlHj+28OwVZrj+2FtkZmjRnJaNizNFfh230X0a1kbFmYK1LBVwtHaMv/nmJ6FFQcuoVdzL9R14eX8iYiqOiYy/ynPRKbOO5sKKBWYQWAONbJggWHmW3FTnLBZ/YhB100a5mYKvPiIL5p7O8JMoYCrnQoqSzM0r+2E9Gw1Lt5KgYeDFVztVVAoFLh7PxM2KnOoLMzxb0oGLM3M4GiTP3EiIiLj4unX5azw/E8BNRRQQzPIdEVOAdeaIYPJUQtWHLxUpjZc7VW4dS9DOx3SyA2372ciPjEN03o2ho+zDWxV5rCyNIedygKO1pZQ8Aq9RESVAhOZUvonLjFf2fKX20JlbgY/Vzt4OD642WBKRjZsleZQKBQQEUTdTMGGsHi0qVMDOyNu4OfDcajlZI3b9zNQ380eQ9vXwZU7qegU4IqW3k5YuCsKYVcSEZ+Yhgs3UmCmAM580BU/HbqM60npWHnkMtzsrbBoUEtsPBVf5h92Q7FRmiM1zyGxyipvEgMAOyNual+/teqkXm009LCHp6MVbqVkoHtTTwTXqwkHKwvUrmEDCzMFLMyrwR2/iYiMgIeWSqnu1E3I3XJRn3RHcloWatqZxsXS1GrB2fhkWCvNUc/VFmoBMrPVUCgAK0tzAJoep4J6HbJy1IW+1xy1wNxMgewctfaHOyEpHY7WlkjLykFaVg48HaxgZqYodB25bTws6sY9xN1JhbuDFfzd7HA3NRM3kjOQkZWD+KQ01LBRwtPRGsnpWVh/8hoOxtxG7L/3y7ytDMnDwQoNPOxx9loSGnraI9ivJhp6OKCRlwNqOfGMKiKivDhG5j/llci8+L8j2Bf1LwDg0mc9DdYuGY9aLVAogMTULM20CGxVFrhyJxV/nb6OmFspuJeejT0XblVYTJ0DXPHKo3Vhb2UJZxsl3BxU2mSTiKgqYyLzn/JKZM7GJ6Hnov0AmMjQAyKCbLXmT+ra3TQcvXQHh2Nu415GNnycbfDLkTikZRn2cFv/lrVgozKH0twcjzd0RY5aYG9lCVc7FXxq2uBmcjpc7FTanjAiIlNQpRKZJUuWYM6cOUhISEDz5s2xePFitGvXTq9ly/OspT9OXoW7vRXa+7sYtF2qHkQEd+5n4n5GDm7fz8D3By5h46l4o8RS01aJmnZK/JuSiTv3MzGwjTe6BXrA09EKZ68lo3ugB6wtzZGRrYZaBDZKzfC6HLUgRy1QWnAMEJVNVo4alg+NJdtz4Rau3k3FkKBCbkBLVVqVSWTWrFmDl156CV9//TWCgoKwYMEC/Pbbb4iMjISbm1uxy5f3BfGIypuI4Pb9TKRl5uBaYhp2RdxA+LUkZOcIzl1PRvPaTjh08TbsVRa4l5Ft7HCL5Odqi4u3HoxdmvBkA0TfSoGN0hxNvBwhANzsVbhyJxW3UjJw6d/7GBLkC7UIWng74V56NmyU5vg3JRN2VhZwt1chWy2ITLiHBu72iLxxD3Vq2uD01SR89Nc5vPpYXQxs6wO1WrAp/DqC6jqjhq0SFmYK5Kgl3yDslIxs7DiXgBo2SnQOeLB/uZ6Uhmt309Dc2wmRCfcAAPZWFvCt+eCaRmq1QADtGK/cH+asHE3yBwC7Im6iqZcjlBZm2hMCklKzEPNvClp6OyE5LVvncgBZOWrcvZ8JK6U57FUWOmPKEpLScTLuLro19dCeSCACvXve7t7PxNW7aQis7VhonZv30nHx1n084ldTrzYLkpWjxr30bDjbKrHtbAJup2RicJCPTp0VB2Ixa8t5/PRKENrVddaW517iYtOYR9HEq/A4yTjiE9Pg6WhVbmdxVplEJigoCG3btsWXX34JAFCr1fD29sZbb72Fd955p9jlmchQdaRWCxLTsnA7JQM5Ijhx+S7sVBbYE3kLZ+KTcOFGirFDrNLsVBZI+S+pdLCyQHJ6/gSzjW8NHL98Vzvt7WyNK3fStNMdG7hibwHjsZ5tXRtrT1zVKQtp5IadETfhYGUBO5UF4pPS8URDN9iqLLS9fF0auuHK3VRcuJGCiU81wNztFwAALX2coBbg4s0UWCnN0cjTAR/2boJ76dno9aXm8Pm7PRri083nAQCf9gvE3dRMnItPRq/mXlBZmuHWvQy08nFCRrYax2LvwMlGiRq2Svg622DId0dw614G1r4RjN5fHgAArHw1CLH/3kfPQE/YqMwRMG2r9r0sfL4FvJysUcvJGu0/+xsA0K6uMxY+3wI2Sgv8ePASzifcw8V/78PPxRZpWTlo4uWA2/cz8ai/C8wUQJdG7sjIVmP0L/+gkacD2tapgdTMHLSr64zktGz8ff4G4u6kai7U2c4Hno5WWLgrCjVslFh1NA5vPVEfPQI9cPzyXdgqLZCenYOFO6OgsjDD4sEtobIwx4Hof7HyyGV80LspElMzsTvyJi7euo+h7evgnXXh6FTfBeOfCtC+LxHBljMJaONbA24OmiT235QMnLh8F218ayDi+j34u9mhpp1S2zOVma2GpblCmyjkqAXxiWlQWZrBzd4KOWpBxPVk2Kos8MPBS3i6mSfa1HmQCCalZSE1MxuejtZIy8zBuevJqOdqCycbJa7cSYWN0hzOtkokJKcjRy2oXcMGZ64l4UZyOh6t7wKVReHj8X45Eod3/wjHhCcb4K0u9QutVxZVIpHJzMyEjY0N1q5di759+2rLhw4disTERPz5Z/67SWdkZCAj48HptMnJyfD29mYiQ1RCKRnZsDBTIDUzBxf/G+j87b6LOHMtCWO61EdmjhpHY+/g2t00RN1kYkRUWVmaK5CVU/xP/Ud9m+L99We0043/SwJ3nb+Jq3fTMPGpBvhydzQC3O1x6mqStt5Pr7RDh3ouBh+HVyUSmfj4eNSqVQsHDx5EcHCwtnzy5MnYs2cPjhw5km+ZmTNn4oMPPshXzkSGqHLJUQsysnNgaW4GCzPNf5330rOgFuB+RjbsrCwgaiAxTTOO6G5qJizMFIi7kwo3ByvUqWmD9SfjYWdlgbjb9+FgbYmoGynYejYBABBYyxHXEtNw536mdp0eDlZITNNMp2epjfK+iaqi74e1wRMN3Q3aZrW9su/UqVMxfvx47XRujwwRVS7mZgrtoOFc9laa8SF577f18C0kgvKM1xgbUj5d2mWRma1GVo4atqoH7y3v+JXbKRlQiyaR83C0gvq/s9zupGYiNSMHTraWsFdZ4MqdNKRmZaOhhwNuJqcj7k4qWvvWQNydVFhZmuPO/UzUdbFFWmYOTl9Lwr/3MuBobYnGXg7IUQsu3b4PN3vNdZd+OHgJiamZ6N+qNmrYKnHk4m3kqAX13e2x5lgc7K0sUcPGEvFJ6Xg8wA1Wlma4mZwBZzslom+kYNWxONgqLTC5WwB2nLsBBytLBNeribg7qVhx8BIaezrgfobm0gRD29fBwZh/YaZQ4M79TJyNT0ZNWyVSMzXXkrJRmkNlYQafmrao72aHqBv3EJFwD4/6u+Dv8zfROcAV9zOyceyS5rBbQw97nP9vXBJVXmeuJRs8kdFXpe6RKc2hpYdxjAwRUfVwPyMbSgsznbOfctQCtYi2108farXoHCbJvcaUQqFASkY2cnIE6dk5cLVT4VpiGjKy1fB3s8PNe+m49V9CaWWpSdjsVBYQARQKQC2awc+ZOWqkZ+UgOS0bahHE3U5Fs9qOqGGrREa2GnYqC5yMu4uYW/dhp7JAB/+asFVaQKEAYm6lIOpGCtwcrJCRlQN/NzusPnYFPx2+jB5NPTAoyAciwLazCahdwwY3ktPRI9ATvx6/Ag8HK8TcSkHTWo5Iz8rBvymZWLQrCgDwWkc/HL10B409HVDTToUVB2LR3NsJrX1rwFZpgVa+Thi3Jgx1XezQqYErPvrrnHb7LB3SCk80cityTE1pVIlDS4BmsG+7du2wePFiAJrBvj4+Phg9ejQH+xIREVVRVebQ0vjx4zF06FC0adMG7dq1w4IFC3D//n28/PLLxg6NiIiIjKzSJzIDBw7ErVu3MH36dCQkJKBFixbYunUr3N2NcyyOiIiIKo9Kf2iprHhoiYiIyPTo+/vN64oTERGRyWIiQ0RERCaLiQwRERGZLCYyREREZLKYyBAREZHJYiJDREREJouJDBEREZksJjJERERkspjIEBERkcliIkNEREQmi4kMERERmaxKf9PIssq9lVRycrKRIyEiIiJ95f5uF3dLyCqfyNy7dw8A4O3tbeRIiIiIqKTu3bsHR0fHQudX+btfq9VqxMfHw97eHgqFwmDtJicnw9vbG1euXOFdtfXA7aU/biv9cVvpj9tKf9xWJVNe20tEcO/ePXh5ecHMrPCRMFW+R8bMzAy1a9cut/YdHBz4RS8Bbi/9cVvpj9tKf9xW+uO2Kpny2F5F9cTk4mBfIiIiMllMZIiIiMhkMZEpJZVKhRkzZkClUhk7FJPA7aU/biv9cVvpj9tKf9xWJWPs7VXlB/sSERFR1cUeGSIiIjJZTGSIiIjIZDGRISIiIpPFRKaUlixZgjp16sDKygpBQUE4evSosUOqcDNnzoRCodB5NGzYUDs/PT0do0aNQs2aNWFnZ4dnnnkGN27c0GkjLi4OPXv2hI2NDdzc3DBp0iRkZ2dX9FsxuL1796JXr17w8vKCQqHA+vXrdeaLCKZPnw5PT09YW1sjJCQEUVFROnXu3LmDIUOGwMHBAU5OTnjllVeQkpKiU+f06dN47LHHYGVlBW9vb8yePbu835rBFbethg0blu971q1bN5061WVbzZo1C23btoW9vT3c3NzQt29fREZG6tQx1N9daGgoWrVqBZVKBX9/f6xYsaK8355B6bOtOnfunO+79frrr+vUqQ7baunSpWjWrJn2OjDBwcHYsmWLdn6l/04Jldjq1atFqVTK999/L2fPnpURI0aIk5OT3Lhxw9ihVagZM2ZIkyZN5Pr169rHrVu3tPNff/118fb2ll27dsnx48flkUcekfbt22vnZ2dnS9OmTSUkJEROnjwpmzdvFhcXF5k6daox3o5Bbd68Wd577z1Zt26dAJA//vhDZ/5nn30mjo6Osn79ejl16pT07t1b6tatK2lpado63bp1k+bNm8vhw4dl37594u/vL4MGDdLOT0pKEnd3dxkyZIicOXNGVq1aJdbW1rJs2bKKepsGUdy2Gjp0qHTr1k3ne3bnzh2dOtVlW3Xt2lWWL18uZ86ckbCwMOnRo4f4+PhISkqKto4h/u4uXrwoNjY2Mn78eDl37pwsXrxYzM3NZevWrRX6fstCn23VqVMnGTFihM53KykpSTu/umyrDRs2yKZNm+TChQsSGRkp7777rlhaWsqZM2dEpPJ/p5jIlEK7du1k1KhR2umcnBzx8vKSWbNmGTGqijdjxgxp3rx5gfMSExPF0tJSfvvtN21ZRESEAJBDhw6JiOYHzMzMTBISErR1li5dKg4ODpKRkVGusVekh3+c1Wq1eHh4yJw5c7RliYmJolKpZNWqVSIicu7cOQEgx44d09bZsmWLKBQKuXbtmoiIfPXVV1KjRg2dbTVlyhQJCAgo53dUfgpLZPr06VPoMtV1W4mI3Lx5UwDInj17RMRwf3eTJ0+WJk2a6Kxr4MCB0rVr1/J+S+Xm4W0loklkxo4dW+gy1XVbiYjUqFFDvvvuO5P4TvHQUgllZmbixIkTCAkJ0ZaZmZkhJCQEhw4dMmJkxhEVFQUvLy/4+flhyJAhiIuLAwCcOHECWVlZOtupYcOG8PHx0W6nQ4cOITAwEO7u7to6Xbt2RXJyMs6ePVuxb6QCxcbGIiEhQWfbODo6IigoSGfbODk5oU2bNto6ISEhMDMzw5EjR7R1OnbsCKVSqa3TtWtXREZG4u7duxX0bipGaGgo3NzcEBAQgDfeeAO3b9/WzqvO2yopKQkA4OzsDMBwf3eHDh3SaSO3jinv4x7eVrlWrlwJFxcXNG3aFFOnTkVqaqp2XnXcVjk5OVi9ejXu37+P4OBgk/hOVfl7LRnav//+i5ycHJ0PDADc3d1x/vx5I0VlHEFBQVixYgUCAgJw/fp1fPDBB3jsscdw5swZJCQkQKlUwsnJSWcZd3d3JCQkAAASEhIK3I6586qq3PdW0HvPu23c3Nx05ltYWMDZ2VmnTt26dfO1kTuvRo0a5RJ/RevWrRv69++PunXrIiYmBu+++y66d++OQ4cOwdzcvNpuK7VajXHjxqFDhw5o2rQpABjs766wOsnJyUhLS4O1tXV5vKVyU9C2AoDBgwfD19cXXl5eOH36NKZMmYLIyEisW7cOQPXaVuHh4QgODkZ6ejrs7Ozwxx9/oHHjxggLC6v03ykmMlRq3bt3175u1qwZgoKC4Ovri19//dVk/nip8nv++ee1rwMDA9GsWTPUq1cPoaGh6NKlixEjM65Ro0bhzJkz2L9/v7FDqfQK21YjR47Uvg4MDISnpye6dOmCmJgY1KtXr6LDNKqAgACEhYUhKSkJa9euxdChQ7Fnzx5jh6UXHloqIRcXF5ibm+cbsX3jxg14eHgYKarKwcnJCQ0aNEB0dDQ8PDyQmZmJxMREnTp5t5OHh0eB2zF3XlWV+96K+g55eHjg5s2bOvOzs7Nx586dar/9/Pz84OLigujoaADVc1uNHj0af/31F3bv3o3atWtryw31d1dYHQcHB5P7J6WwbVWQoKAgAND5blWXbaVUKuHv74/WrVtj1qxZaN68ORYuXGgS3ykmMiWkVCrRunVr7Nq1S1umVquxa9cuBAcHGzEy40tJSUFMTAw8PT3RunVrWFpa6mynyMhIxMXFabdTcHAwwsPDdX6EduzYAQcHBzRu3LjC468odevWhYeHh862SU5OxpEjR3S2TWJiIk6cOKGt8/fff0OtVmt3tsHBwdi7dy+ysrK0dXbs2IGAgACTPFSir6tXr+L27dvw9PQEUL22lYhg9OjR+OOPP/D333/nO1xmqL+74OBgnTZy65jSPq64bVWQsLAwAND5blWHbVUQtVqNjIwM0/hOlXm4cDW0evVqUalUsmLFCjl37pyMHDlSnJycdEZsVwcTJkyQ0NBQiY2NlQMHDkhISIi4uLjIzZs3RURzyp6Pj4/8/fffcvz4cQkODpbg4GDt8rmn7D311FMSFhYmW7duFVdX1ypx+vW9e/fk5MmTcvLkSQEg8+fPl5MnT8rly5dFRHP6tZOTk/z5559y+vRp6dOnT4GnX7ds2VKOHDki+/fvl/r16+ucUpyYmCju7u7y4osvypkzZ2T16tViY2NjcqcUF7Wt7t27JxMnTpRDhw5JbGys7Ny5U1q1aiX169eX9PR0bRvVZVu98cYb4ujoKKGhoTqnDKempmrrGOLvLvdU2UmTJklERIQsWbLE5E4pLm5bRUdHy4cffijHjx+X2NhY+fPPP8XPz086duyobaO6bKt33nlH9uzZI7GxsXL69Gl55513RKFQyPbt20Wk8n+nmMiU0uLFi8XHx0eUSqW0a9dODh8+bOyQKtzAgQPF09NTlEql1KpVSwYOHCjR0dHa+WlpafLmm29KjRo1xMbGRvr16yfXr1/XaePSpUvSvXt3sba2FhcXF5kwYYJkZWVV9FsxuN27dwuAfI+hQ4eKiOYU7Pfff1/c3d1FpVJJly5dJDIyUqeN27dvy6BBg8TOzk4cHBzk5Zdflnv37unUOXXqlDz66KOiUqmkVq1a8tlnn1XUWzSYorZVamqqPPXUU+Lq6iqWlpbi6+srI0aMyPdPQ3XZVgVtJwCyfPlybR1D/d3t3r1bWrRoIUqlUvz8/HTWYQqK21ZxcXHSsWNHcXZ2FpVKJf7+/jJp0iSd68iIVI9tNXz4cPH19RWlUimurq7SpUsXbRIjUvm/U7z7NREREZksjpEhIiIik8VEhoiIiEwWExkiIiIyWUxkiIiIyGQxkSEiIiKTxUSGiIiITBYTGSIiIjJZTGSIiIjIZDGRMbDQ0FAoFIp8N9gqzM6dO9G4cWMolUqsWLGiROvq3Lkzxo0bp1fdOnXqYMGCBSVqn4gq3qVLl6BQKLT3/SGqjkJDQ2FhYYG6deviu+++K7IuExkjmzlzJmrXro2IiAgMHDhQp3zYsGHGC6yUcnfChhAaGopWrVpBpVLB399fr0Tv9OnTeOyxx2BlZQVvb2/Mnj07X50FCxYgICAA1tbW8Pb2xttvv4309HTt/KVLl6JZs2ZwcHCAg4MDgoODsWXLFp02YmJi0K9fP7i6usLBwQEDBgzQubNrbkJb0OPYsWPaOn369IGnpydsbW3RokULrFy5Ml+8iYmJGDVqFDw9PaFSqdCgQQNs3rxZp86SJUtQp04dWFlZISgoCEePHtWZ/9prr6FevXqwtraGq6sr+vTpg/Pnz+vUiYuLQ8+ePWFjYwM3NzdMmjQJ2dnZOnVWrlyJ5s2bw8bGBp6enhg+fDhu376tnf/tt9/iscceQ40aNVCjRg2EhITkiwUAIiIi0Lt3bzg6OsLW1hZt27ZFXFycdn7nzp3zbbfXX389XzsrVqxAs2bNYGVlBTc3N4waNUpn/rZt2/DII4/A3t4erq6ueOaZZ3Dp0iWdOhkZGXjvvffg6+sLlUqFOnXq4Pvvv8+3rqJ07ty5xP+IVAYrVqxA586dS7SMPp/xzJkz0bBhQ9ja2mrrHDlypMh27927h3HjxsHX1xfW1tZo37699m8lr+K+O4b6ruc6cOAALCws0KJFC53y4vYTd+7cwVtvvaXd1/j4+GDMmDFISkrSaWfMmDFo3bo1VCpVvnUA+u8nituv6bN9RQTTp0+Hp6cnrK2tERISgqioqHzr2rRpE4KCgmBtbY0aNWqgb9++2nmnTp3CoEGD4O3tDWtrazRq1AgLFy7M954K2jcmJCRo67Rv3x4xMTHo3r07JkyYgCJvQmCQGx2QVu59Y+7evatX/bp168qcOXPylc+YMUN7X57CdOrUScaOHavXenx9feWLL77Qq25ZxMbGiiG+Vrk3GBs/frycO3dOFi9eXOwNxpKSksTd3V2GDBkiZ86ckVWrVom1tbXOjQFXrlwpKpVKVq5cKbGxsbJt2zbx9PSUt99+W1tnw4YNsmnTJrlw4YJERkbKu+++K5aWlnLmzBkREUlJSRE/Pz/p16+fnD59WnvTx7Zt20pOTo6IiGRkZOjcqO769evy6quvSt26dUWtVouIyCeffCLTpk2TAwcOSHR0tCxYsEDMzMxk48aN2lgyMjKkTZs20qNHD9m/f7/ExsZKaGiohIWFaeusXr1alEqlfP/993L27FkZMWKEODk5yY0bN7R1li1bpr0p3IkTJ6RXr17i7e0t2dnZIvLgpm8hISFy8uRJ2bx5s7i4uOjc9G3//v1iZmYmCxculIsXL8q+ffukSZMm0q9fP22dwYMHy5IlS+TkyZMSEREhw4YNE0dHR7l69aq2TnR0tDg7O8ukSZPkn3/+kejoaPnzzz914u3UqZOMGDFCZ/s9fA+cefPmiZeXl6xcuVKio6Pl1KlT8ueff+p8h1QqlUydOlWio6PlxIkT0rFjR2nZsqVOO71795agoCDZsWOHxMbGysGDB2X//v2Ffs8K0qlTJ4PdNyb3b+jkyZMGaa8oy5cvl06dOpVoGX0+45UrV8qOHTskJiZGzpw5I6+88oo4ODhobyhbkAEDBkjjxo1lz549EhUVJTNmzBAHB4cSf3cM8V3PdffuXfHz85OnnnpKmjdvrjOvuP1EeHi49O/fXzZs2CDR0dGya9cuqV+/vjzzzDM67bz11lvy5ZdfyosvvphvHSL67Sf02a/ps30/++wzcXR0lPXr18upU6ekd+/e+W5mu3btWqlRo4YsXbpUIiMj5ezZs7JmzRrt/P/9738yZswYCQ0NlZiYGPnpp5/E2tpaFi9erK2T+zsZGRmp8zeeu//Ma/v27QJAkpOT883LVaUSmZycHPn000+lTp06YmVlJc2aNZPffvtNOz934/31118SGBgoKpVKgoKCJDw8XKedtWvXSuPGjUWpVIqvr6/MnTtXZ356erpMnjxZateuLUqlUurVqyffffedzjp27twprVu3FmtrawkODpbz588XGHNhCcbDiUxKSoq8+OKLYmtrKx4eHjJ37twyJTKXL1+W3r17i62trdjb28tzzz2ncyO+sLAw6dy5s9jZ2Ym9vb20atVKjh07JiKam4M9/fTT4uTkJDY2NtK4cWPZtGmTiBgukZk8ebI0adJEp2zgwIHStWvXQpf56quvpEaNGpKRkaEtmzJligQEBGinR40aJU888YTOcuPHj5cOHToUGU+NGjW0n/G2bdvEzMxM54c1MTFRFAqF7Nixo8DlMzMzxdXVVT788MMi19OjRw95+eWXtdNLly4VPz8/yczMLHSZdu3ayahRo7TTOTk54uXlJbNmzSp0mVOnTgkA7U0+N2/eLGZmZjrfgaVLl4qDg4N2e86ZM0f8/Px02lm0aJHUqlWr0PVkZ2eLvb29/PDDD9qygQMHygsvvFDoMiLFJ+l37twRa2tr2blzZ6F1fvvtN7GwsNDZOW7YsEEUCoV2e27ZskUcHR3l9u3bRcZTnIcTmYiICOnQoYOoVCpp1KiR7NixQwDIH3/8UWxbBSUyoaGh0rZtW1EqleLh4SFTpkzRuSHfb7/9Jk2bNhUrKytxdnaWLl26SEpKioho9klt27YVGxsbcXR0lPbt28ulS5dEpHSJzMMK+owflpSUpN0vFiQ1NVXMzc3lr7/+0ilv1aqVvPfee9ppfb47DyvNdz3v+qZNmyYzZswoMMl4WN79REF+/fVXUSqVBd4YV991iOTfTxS3X9Nn+6rVavHw8ND5xzoxMVFUKpWsWrVKRESysrKkVq1aRb7Hgrz55pvy+OOPa6dL8g+/PnWr1KGlWbNm4ccff8TXX3+Ns2fP4u2338YLL7yAPXv26NSbNGkS5s2bh2PHjsHV1RW9evVCVlYWAODEiRMYMGAAnn/+eYSHh2PmzJl4//33dbqNX3rpJaxatQqLFi1CREQEli1bBjs7O511vPfee5g3bx6OHz8OCwsLDB8+vMCY09PTYWlpWex7mzRpEvbs2YM///wT27dvR2hoKP75558SbiENtVqNPn364M6dO9izZw927NiBixcv6hzaGjJkCGrXro1jx47hxIkTeOedd7Rxjho1ChkZGdi7dy/Cw8Px+eef53v/eSkUihJ3ux86dAghISE6ZV27dsWhQ4eKXKZjx45QKpU6y0RGRuLu3bsANN2VJ06c0HaFX7x4EZs3b0aPHj0KbDMnJwerV6/G/fv3ERwcDEBzKEKhUEClUmnrWVlZwczMDPv37y+wnQ0bNuD27dt4+eWXi3zfSUlJcHZ21lkuODgYo0aNgru7O5o2bYpPP/0UOTk5AIDMzEycOHFCZ1uZmZkhJCSk0G11//59LF++HHXr1oW3t7d22wUGBsLd3V1n2yUnJ+Ps2bMAgODgYFy5cgWbN2+GiODGjRtYu3ZtodsOAFJTU5GVlaV9T2q1Gps2bUKDBg3QtWtXuLm5ISgoCOvXr8+37MqVK+Hi4oKmTZti6tSpSE1N1c7bsWMH1Go1rl27hkaNGqF27doYMGAArly5oq3TunVrmJmZYfny5cjJyUFSUhJ++uknhISEaL/LGzZsQJs2bTB79mzUqlULDRo0wMSJE5GWllboeypOTk4O+vbtCxsbGxw5cgTffPMN3nvvvVK3d+3aNfTo0QNt27bFqVOnsHTpUvzvf//Dxx9/DAC4fv06Bg0ahOHDhyMiIgKhoaHo378/RATZ2dno27cvOnXqhNOnT+PQoUMYOXJkoYd/c7v8Hz78VpSHP+OHZWZm4ptvvoGjoyOaN29eYJ3s7Gzk5OTAyspKp9za2lr7N1WS706u0n7XAWD58uW4ePEiZsyYUew2KGg/UZCkpCQ4ODjAwsKi2DaL8vB+orj9mj7bNzY2FgkJCTr7EkdHRwQFBWn3Jf/88w+uXbsGMzMztGzZEp6enujevTvOnDlTonhztWjRAp6ennjyySdx4MCBApfN/VvNyMgofAUlSqsqsfT0dLGxsZGDBw/qlL/yyisyaNAgEXmQ2a1evVo7//bt22Jtba3tGhs8eLA8+eSTOm1MmjRJGjduLCIikZGRAqDQ/7zz9sjk2rRpkwDQ6Z4TEe1/aUX9Vykicu/ePVEqlfLrr7/mi7s0PTLbt28Xc3NziYuL084/e/asAJCjR4+KiIi9vb2sWLGiwLYCAwNl5syZeq1XRCQgIEDWrVund30Rkfr168unn36qU5a7HVNTUwtc5sknn5SRI0fqlOW+r3PnzmnLFi5cKJaWlmJhYSEA5PXXX8/X1unTp8XW1lbMzc3F0dFR2+MkInLz5k1xcHCQsWPHyv379yUlJUVGjx4tAPKtP1f37t2le/fuRb7nNWvWiFKp1HZNi2i2nUqlkuHDh8vx48dl9erV4uzsrN3+165dEwD5vveTJk2Sdu3a6ZQtWbJEbG1tBYAEBARo/0MVERkxYoQ89dRTOvXv378vAGTz5s3asl9//VXs7Oy0265Xr15F9ha98cYb4ufnp/3uX79+XQCIjY2NzJ8/X06ePCmzZs0ShUIhoaGh2uWWLVsmW7duldOnT8vPP/8stWrV0jmENWvWLLG0tJSAgADZunWrHDp0SLp06SIBAQE6/1WHhoaKm5ubmJubCwAJDg7W+c+ua9euolKppGfPnnLkyBHZtGmT+Pr6yrBhwwp9T8XZsmWLWFhYyPXr17VlZemReffddyUgIEB7SFJE81na2dlJTk6OnDhxQgBoe1nyun37tgDQ2bZFOXLkiAQEBOgcbijOw59xro0bN4qtra0oFArx8vLS7lsKExwcLJ06dZJr165Jdna2/PTTT2JmZiYNGjQQEf2/OyJl/65fuHBB3NzcJDIyUkQK7y0paj/xsFu3bomPj4+8++67Bc7Xt0emoP2ESPH7teK274EDBwSAxMfH6yz33HPPyYABA0REZNWqVQJAfHx8ZO3atXL8+HEZNGiQ1KxZs9BezQMHDoiFhYVs27ZNW3b+/Hn5+uuv5fjx43LgwAF5+eWXxcLCQk6cOJFv+evXr2sPaef9G8iryiQyZ86cEQBia2ur87C0tNTu0HOTjMuXL+ss26JFC+0PQ8uWLfP9SK9fv14sLS0lOztb1qxZI+bm5oXuvHPXkfdY8D///JNvvSqVSgDIm2++Wex7CwsLKzTu0iQyCxculDp16uSr4+TkpO0enjFjhlhYWEiXLl1k1qxZOjuCb7/9ViwsLKR9+/Yyffp0OXXqlF4xFCbv5/Xaa6+JSPklMrt37xZ3d3f59ttv5fTp07Ju3Trx9vbOd8gnIyNDoqKi5Pjx4/LOO++Ii4uLnD17Vjt/27Zt4ufnJwqFQszNzeWFF16QVq1aFZgUXblyRczMzGTt2rWFboO///5bbGxs8nXP169fX+f4vohmbIiHh4eIlCyRSUxMlAsXLsiePXukV69e0qpVK+2Pjz4797Nnz4qnp6fMnj1bTp06JVu3bpXAwEAZPnx4ge9p1qxZUqNGDZ3vR268uf9c5OrVq5c8//zzhW6fXbt26Rwe+OSTTwSAzs7x5s2bYmZmph1Hdf36dalfv752PMWePXukU6dO0qVLF+0O8cknnxQrKytJTEzUtvP777+LQqEo9HtWnAULFkjdunV1ynIPrZQmkenXr1++xCrvPiE7O1u6dOki9vb28uyzz8o333wjd+7c0dYdNmyYqFQqefrpp2XBggX5fqjKoqDPOFdKSopERUXJoUOHZPjw4VKnTh2dsSwPi46Olo4dOwoAMTc3l7Zt28qQIUOkYcOGIlKy705ZvuvZ2dnSpk0bWbp0qXZ+YUlGcfuJXElJSdKuXTvp1q1bob8d+iQyhe0n9NmvFbd99UlkVq5cKQB0xh2mp6eLi4uLfP311/niDQ8PFxcXF/noo4+KfF8iIh07diz0sOFXX30lZmZmYmlpme93UKQKJTKHDx/W/ucRFRWl88jteTBEIrNhwwa9Epm8//WdPHlSAEhsbKy27Ny5czJv3jwxNzcvdlCfMRIZEU3v0/z58+XJJ58UpVKp06sSFxcnS5culX79+omlpaUsWrRIrzgKkvezyt3RPfbYY/ne2/fffy8ODg6FtvPiiy9Knz59dMr+/vtvAaDdsT/66KMyceJEnTq5g9EKGmiWq0uXLgX2tty6dUv7Wbu7u8vs2bPz1fnwww/F1dW10O9MaGio2Nra6uwccnXs2FG6dOmiU7Z582YBIBkZGZKRkSHm5ub5fiBfeukl6d27d6HvJyMjQ2xsbOSXX34REZH3338/30704sWLAkD++ecfERF54YUX5Nlnn9Wps2/fvgJ3fnPmzBFHR0ftuKq867WwsMi3Y5s8ebK0b9++0HhTUlIEgDZJ+f777wWAXLlyRaeem5ubfPPNNyIiMm3aNGnTpo3O/CtXrggAOXTokIhotlO9evV06pw7d04AyIULFwqNpygVnciIaMY37N+/X6ZPny6BgYHi6uoqFy9e1Nb/559/5NNPP5Xg4GCxs7PTvv+yKOwzLoy/v3++f04KkpKSov0+DRgwQHr06CEipf/ulPS7fvfuXe2Pfe5DoVBoy3bt2lXougraTyQnJ0twcLB06dIlX69VXsUlMkXtJ0qyXyts+8bExBQ4yLxjx44yZswYEXmwP923b59OnXbt2uXraTp79qy4ubkV2gP1sIkTJ8ojjzySrzwxMVEcHR1l1KhREh4eXuD4oiozRqZx48ZQqVSIi4uDv7+/ziP32Giuw4cPa1/fvXsXFy5cQKNGjQAAjRo1ynes7sCBA2jQoAHMzc0RGBgItVqdb9xNSTVq1Ajjx4+Ho6OjTjwFqVevHiwtLXVOX8yNu7TrvnLlis54gnPnziExMRGNGzfWljVo0ABvv/02tm/fjv79+2P58uXaed7e3nj99dexbt06TJgwAd9++22pYgGg81m5ubkB0IzH2LVrl069HTt2FHn8OTg4GHv37tWOd8pdJiAgADVq1ACgOZ5vZqb7tTc3NweAIk/vU6vVBR6jdXFxgZOTE/7++2/cvHkTvXv31pkvIli+fDleeumlAsdChYaGomfPnvj8888xcuTIfPM7dOiA6OhoqNVqbdmFCxfg6ekJpVIJpVKJ1q1b62wrtVqNXbt2FbmtRPNPjPY9BQcHIzw8HDdv3tTW2bFjBxwcHLTfCX233ezZs/HRRx9h69ataNOmjU59pVKJtm3bIjIyUqf8woUL8PX1LTTe3GuqeHp6arcLAJ127ty5g3///VfbTlHx5m7PDh06ID4+HikpKTqxmJmZoXbt2oXGU5SAgABcuXJF53T8gk4j1lejRo1w6NAhnW184MAB2Nvba2NUKBTo0KEDPvjgA5w8eRJKpRJ//PGHtn7Lli0xdepUHDx4EE2bNsUvv/xS6niAoj/jwhT2N/QwW1tbeHp64u7du9i2bRv69OkDoPTfnZJ+1x0cHBAeHo6wsDDt4/XXX0dAQADCwsIQFBSk93tMTk7GU089BaVSiQ0bNuQbo6Kv4vYTJdmvFbZ969atCw8PD519SXJyMo4cOaLdl+SeJp73M8jKysKlS5d0PoOzZ8/i8ccfx9ChQ/HJJ5/o9R7DwsK0f995nTt3DklJSXjnnXfQtGnTgscX6ZUqmYj33ntPatasKStWrNCebrlo0SLtWI/c3pImTZrIzp07JTw8XHr37i0+Pj7a4+onTpwQMzMz+fDDDyUyMlJWrFgh1tbWOmckDBs2TLy9veWPP/6Qixcvyu7du7VjbPTtkcml72nRr7/+uvj6+squXbu0cdvZ2ZWqR0atVkuLFi3ksccekxMnTsiRI0ekdevW2rMXUlNTZdSoUbJ79265dOmS7N+/X+rVqyeTJ08WEZGxY8fK1q1b5eLFi3LixAkJCgrSdj0WpDRjZHJPv540aZJERETIkiVL8p1+vXjxYp2R+omJieLu7i4vvviinDlzRlavXi02NjY6/8HMmDFD7O3tZdWqVXLx4kXZvn271KtXTyf+d955R3v65unTp+Wdd94RhUIh27dv19b5/vvv5dChQxIdHS0//fSTODs7y/jx4/O9j507dwoAiYiIyDcvt5t46tSpOqcg5j3WHBcXJ/b29jJ69GiJjIyUv/76S9zc3OTjjz/W1lm9erWoVCpZsWKFnDt3TkaOHClOTk7aszJiYmLk008/lePHj8vly5flwIED0qtXL3F2dtb2gOWekvrUU09JWFiYbN26VVxdXXVOSV2+fLlYWFjIV199JTExMbJ//35p06aNziGszz77TJRKpaxdu1bnPd27d09bZ926dWJpaSnffPONREVFaU+tz/0vLzo6Wj788EM5fvy4xMbGyp9//il+fn7SsWNHne3Xp08fadKkiRw4cEDCw8Pl6aeflsaNG2t7vnbt2iUKhUI++OADuXDhgpw4cUK6du0qvr6+2sNG9+7dk9q1a8uzzz4rZ8+elT179kj9+vXl1Vdfzfd56Ss7O1sCAgKka9eucurUKdm/f7888sgjAkDWr19f7PIP98hcvXpVbGxsZNSoURIRESHr168XFxcXmTFjhohoeqM/+eQTOXbsmFy+fFl7ZszmzZvl4sWL8s4778jBgwfl0qVLsm3bNqlZs6Z89dVXBa5bnzEyxX3GKSkpMnXqVDl06JBcunRJjh8/Li+//LKoVCqdcR1PPPGEzim5W7dulS1btmj/Lps3by5BQUE6PZnFfXcM9V1/WEG9JcXtJ5KSkiQoKEgCAwMlOjpaZ1vlPVQcFRUlJ0+elNdee00aNGggJ0+elJMnT2p/k/TZT+izX9Nn+3722Wfi5OQkf/75p/ayEg+ffj127FipVauWbNu2Tc6fPy+vvPKKuLm5aXu9w8PDxdXVVV544QWdePMOt/jiiy9k/fr1EhUVJeHh4TJ27FgxMzMrcLyoPmctValERq1Wy4IFCyQgIEAsLS3F1dVVunbtKnv27BGRBxtk48aN0qRJE1EqldKuXbt8x3dzT7+2tLQUHx+ffNd5SUtLk7fffls8PT1FqVSKv7+/fP/99zrr0DeR8fPzk3nz5hX73u7duycvvPCC2NjYaA9hlNfp1xkZGfL888+Lt7e3KJVK8fLyktGjR2u/zKNHj5Z69eqJSqUSV1dXefHFF+Xff/8tdN0ASnWNjd27d0uLFi1EqVSKn59fvjZmzJghvr6+OmWnTp2SRx99VFQqldSqVUs+++wznflZWVkyc+ZMqVevnlhZWYm3t7e8+eabOp/X8OHDxdfXV5RKpbi6ukqXLl10khgRzWnd7u7uYmlpKfXr15d58+YVOBBt0KBBhXZ7Dx06VADkezx8OuzBgwclKChIVCqV+Pn5ySeffKKzIxTRJHU+Pj7a7/Thw4e1865duybdu3cXNzc3sbS0lNq1a8vgwYPzXRLg0qVL0r17d7G2thYXFxeZMGFCvm7cRYsWSePGjcXa2lo8PT1lyJAhOj96vr6+Bb6n3B/dXP/73//E399frKyspHnz5jo/8HFxcdKxY0dxdnYWlUol/v7+MmnSpHzXkUlKSpLhw4eLk5OTODs7S79+/XQGsItoBie2bNlSbG1txdXVVXr37p0vqYyIiJCQkBCxtraW2rVry/jx43XGx+T+TRf091uY3NOvlUqlNGzYUDZu3KhzaKwoJT39+ty5c9K1a1dxdXUVlUolDRo00CYICQkJ0rdvX+2+ytfXV6ZPn17oYVR93mtxn3FaWpr069dPvLy8RKlUiqenp/Tu3TvfYF9fX1+d78WaNWvEz89P+x5HjRqlM3YpV1HfHUN+1/MqKJEpbj+Ruy0LeuTdvp06dSqyjj77CX32a/psX7VaLe+//764u7uLSqWSLl26aAc858rMzJQJEyaIm5ub2NvbS0hIiE6COmPGjALjzbuv/vzzz7WxOjs7S+fOneXvv/8ucNvn/jNY1HVkFCJFXS6vagkNDcXjjz+Ou3fvwsnJydjhANB0bfv4+ODnn3/WdgUSUeWxfPlyfPrppzh37pxel0ooyIEDB/Doo48iOjoa9erVM3CERFXXRx99hM8//1zn8O/DynYyO5XZW2+9heHDh0OlUuGHH37AkCFDjB0SEeWxefNmfPrppyVKYv744w/Y2dmhfv36iI6OxtixY9GhQwcmMUR62rdvH7p06QIRwfvvv19kXfbIVAKZmZlISEhAjRo1YG9vX+Ll9+3bh+7duxc6v6hMlogM78cff8THH3+MuLg4uLi4ICQkBPPmzUPNmjXx6aef4tNPPy1wucceeyzffb2IqqO0tDTcuHED7u7usLa2LrJutUpkqqq0tDRcu3at0Pn+/v4VGA0RFeXOnTu4c+dOgfOsra1Rq1atCo6IyLQxkSEiIiKTVWWuI0NERETVDxMZIiIiMllMZIiIiMhkMZEhIiIik8VEhoiIiEwWExkiIiIyWUxkiIiIyGQxkSEiIiKT9X9k2KInSHTQwAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 3000\n",
    "\n",
    "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
    "gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0002),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
    ")\n",
    "\n",
    "gan.fit(\n",
    "    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim)]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cfe1765d6decd95ab6a6c11415363372b28f9df3b40303f49f18aac197e75d0a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
